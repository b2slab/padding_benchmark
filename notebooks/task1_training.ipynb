{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela/padding_EBI/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "#from src.Target import Target\n",
    "\n",
    "np.random.seed(8)\n",
    "random.seed(8)\n",
    "\n",
    "from src.preprocessing import *\n",
    "from src.model_architecture import *\n",
    "from src.training_model import *\n",
    "from src.postprocessing import *\n",
    "from src.comparing_results import *\n",
    "#from src.callbacks import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paddings = [\n",
    "    'post_padding', 'pre_padding', \n",
    "    'mid_padding', \n",
    "                 'strf_padding', 'ext_padding', \n",
    "                 'rnd_padding', 'aug_padding', \n",
    "    \"zoom_padding\"]\n",
    "#list_paddings = ['post_padding', 'pre_padding', 'mid_padding', 'strf_padding', 'ext_padding', \n",
    "#                 'rnd_padding']\n",
    "#list_paddings = [\"zoom_padding\"]\n",
    "#hierarchy of folders: annotation/dataset/architecture/n_neurs/task/padding\n",
    "folder = 'EC_number/archaea/stack_conv/10filts_sizeJurtz/'\n",
    "#'EC_number/archaea/rnn_conv/256rnn/'\n",
    "#'EC_number/archaea/1conv/64filts_size5/'#'EC_number/archaea/3denses/bio_neurons/'\n",
    "column = \"EC number\"\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "dicti = creating_dict()\n",
    "\n",
    "max_lenn = 1000\n",
    "\n",
    "n_class = 2 #number of classes to output\n",
    "drop_per = 0.2 #Input dropout \n",
    "n_neur = [314,77, 8]\n",
    "drop_hid = 0.5\n",
    "dict_size = len(dicti)\n",
    "final_act = \"softmax\"\n",
    "n_filt = 10 #64 #None\n",
    "kernel_size = [1,3,5,9,15]#[5] #None\n",
    "pool_size = 10 #None\n",
    "n_hid = 256 #None\n",
    "\n",
    "batch_size = 54\n",
    "epochss = 200\n",
    "\n",
    "callbacks_list = [None, None, None, None, False, False, False, False]\n",
    "task = \"task1/\"\n",
    "#architecture = \"only_denses\"\n",
    "#architecture = \"conv_dense\"\n",
    "#architecture = \"rnn_conv\"\n",
    "architecture = \"stack_conv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0001\n",
    "optimizer = Adam(lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_idcs_aug = os.path.join(absPath, 'data/', folder, 'idcs_aug_split.pickle')\n",
    "\n",
    "with open(file_idcs_aug, \"rb\") as input_file:\n",
    "    k_aug_indices = pickle.load(input_file)\n",
    "    \n",
    "file_idcs = os.path.join(absPath, 'data/', folder, 'idcs_split.pickle')\n",
    "\n",
    "with open(file_idcs, \"rb\") as input_file:\n",
    "    splitting_sets = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Deep Learning model  - Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1000, 26)     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1000, 10)     270         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1000, 10)     790         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 1000, 10)     1310        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 1000, 10)     2350        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1000, 10)     3910        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5000, 10)     0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 500, 10)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500, 314)     3454        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 314)     0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500, 77)      24255       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 77)      0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500, 8)       624         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 8)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 4000)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            8002        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#model = building_3dense_model_task1(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, 'softmax', folder)\n",
    "#model = building_1convdense_model_task1(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, n_filt, kernel_size, final_act, folder)\n",
    "#model = building_convrnn_model_task1(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, \n",
    "#                                 n_filt, kernel_size, pool_size, n_hid, final_act, folder, optimizer)\n",
    "model = building_stackconv_model_task1(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, n_filt, \n",
    "                                       kernel_size, pool_size, final_act, folder, optimizer)\n",
    "generators_dict = {} \n",
    "for model_type in list_paddings:\n",
    "    generators_dict[model_type] = trainval_generators(splitting_sets, k_aug_indices, model_type, \n",
    "                                                      folder, batch_size, 'labels_task1', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1000, 26)     0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1000, 10)     270         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1000, 10)     790         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1000, 10)     1310        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1000, 10)     2350        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 1000, 10)     3910        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5000, 10)     0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 500, 10)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 500, 314)     3454        max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 500, 314)     0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500, 77)      24255       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 500, 77)      0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 500, 8)       624         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 500, 8)       0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4000)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            8002        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 7s 28ms/step - loss: 0.6830 - acc: 0.5882 - val_loss: 0.6871 - val_acc: 0.7282\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72816, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-001-0.7282.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6722 - acc: 0.6011 - val_loss: 0.6760 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.72816\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6554 - acc: 0.6453 - val_loss: 0.6612 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.72816\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6401 - acc: 0.6795 - val_loss: 0.6449 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72816\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6308 - acc: 0.6853 - val_loss: 0.6316 - val_acc: 0.7177\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72816\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6255 - acc: 0.6904 - val_loss: 0.6261 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72816\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6241 - acc: 0.6919 - val_loss: 0.6228 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72816\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6215 - acc: 0.6926 - val_loss: 0.6203 - val_acc: 0.7124\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72816\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6189 - acc: 0.6974 - val_loss: 0.6136 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72816\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6186 - acc: 0.6954 - val_loss: 0.6143 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72816\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6184 - acc: 0.6940 - val_loss: 0.6120 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.72816\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6177 - acc: 0.6968 - val_loss: 0.6108 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72816\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6158 - acc: 0.6968 - val_loss: 0.6084 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.72816\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6139 - acc: 0.6985 - val_loss: 0.6054 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.72816\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6139 - acc: 0.7007 - val_loss: 0.6054 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72816\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6148 - acc: 0.6959 - val_loss: 0.6034 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.72816\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6122 - acc: 0.6994 - val_loss: 0.6013 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.72816\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6096 - acc: 0.6994 - val_loss: 0.5995 - val_acc: 0.7254\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72816\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6082 - acc: 0.7042 - val_loss: 0.5977 - val_acc: 0.7264\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72816\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6079 - acc: 0.7024 - val_loss: 0.5954 - val_acc: 0.7282\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72816\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6073 - acc: 0.7014 - val_loss: 0.5934 - val_acc: 0.7299\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.72816 to 0.72991, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-021-0.7299.hdf5\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6072 - acc: 0.7044 - val_loss: 0.5939 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.72991 to 0.73131, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-022-0.7313.hdf5\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6059 - acc: 0.7071 - val_loss: 0.5918 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.73131 to 0.73235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-023-0.7324.hdf5\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6029 - acc: 0.7050 - val_loss: 0.5894 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.73235 to 0.73585, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-024-0.7358.hdf5\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6009 - acc: 0.7086 - val_loss: 0.5856 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.73585 to 0.73934, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-025-0.7393.hdf5\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5973 - acc: 0.7072 - val_loss: 0.5820 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.73934 to 0.74458, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-026-0.7446.hdf5\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5977 - acc: 0.7103 - val_loss: 0.5815 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.74458\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5957 - acc: 0.7077 - val_loss: 0.5790 - val_acc: 0.7481\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.74458 to 0.74808, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-028-0.7481.hdf5\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5904 - acc: 0.7137 - val_loss: 0.5763 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.74808 to 0.74948, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-029-0.7495.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5901 - acc: 0.7120 - val_loss: 0.5732 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.74948 to 0.75017, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-030-0.7502.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5896 - acc: 0.7114 - val_loss: 0.5720 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.75017 to 0.75332, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-031-0.7533.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5841 - acc: 0.7185 - val_loss: 0.5686 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.75332 to 0.75891, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-032-0.7589.hdf5\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5813 - acc: 0.7188 - val_loss: 0.5629 - val_acc: 0.7621\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.75891 to 0.76205, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-033-0.7621.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5783 - acc: 0.7222 - val_loss: 0.5575 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.76205 to 0.76520, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-034-0.7652.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5729 - acc: 0.7225 - val_loss: 0.5533 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.76520 to 0.76730, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-035-0.7673.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5712 - acc: 0.7250 - val_loss: 0.5520 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.76730 to 0.77114, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-036-0.7711.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5676 - acc: 0.7277 - val_loss: 0.5439 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.77114 to 0.77987, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-037-0.7799.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5647 - acc: 0.7266 - val_loss: 0.5358 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.77987 to 0.78826, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-038-0.7883.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5634 - acc: 0.7296 - val_loss: 0.5348 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.78826\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5624 - acc: 0.7312 - val_loss: 0.5289 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.78826 to 0.79420, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-040-0.7942.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5589 - acc: 0.7295 - val_loss: 0.5208 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.79420 to 0.79839, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-041-0.7984.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5518 - acc: 0.7372 - val_loss: 0.5107 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.79839 to 0.80259, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-042-0.8026.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5532 - acc: 0.7383 - val_loss: 0.5111 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.80259 to 0.80853, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-043-0.8085.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5478 - acc: 0.7402 - val_loss: 0.5091 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.80853 to 0.81097, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-044-0.8110.hdf5\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5452 - acc: 0.7410 - val_loss: 0.4990 - val_acc: 0.8183\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.81097 to 0.81831, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-045-0.8183.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5434 - acc: 0.7433 - val_loss: 0.5070 - val_acc: 0.8215\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.81831 to 0.82145, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-046-0.8215.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5369 - acc: 0.7461 - val_loss: 0.4958 - val_acc: 0.8249\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.82145 to 0.82495, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-047-0.8249.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5352 - acc: 0.7469 - val_loss: 0.4868 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82495 to 0.83194, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-048-0.8319.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5299 - acc: 0.7508 - val_loss: 0.4807 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.83194 to 0.83683, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-049-0.8368.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5331 - acc: 0.7478 - val_loss: 0.4786 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83683 to 0.83857, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-050-0.8386.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5329 - acc: 0.7470 - val_loss: 0.4779 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.83857 to 0.84347, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-051-0.8435.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5284 - acc: 0.7517 - val_loss: 0.4809 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.84347 to 0.84766, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-052-0.8477.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5217 - acc: 0.7524 - val_loss: 0.4779 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84766 to 0.84871, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-053-0.8487.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5182 - acc: 0.7571 - val_loss: 0.4747 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.84871 to 0.85080, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-054-0.8508.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5201 - acc: 0.7544 - val_loss: 0.4770 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85080 to 0.85150, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-055-0.8515.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5193 - acc: 0.7531 - val_loss: 0.4802 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.85150 to 0.85325, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-056-0.8532.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5154 - acc: 0.7574 - val_loss: 0.4818 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.85325 to 0.85709, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-057-0.8571.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5094 - acc: 0.7596 - val_loss: 0.4671 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.85709 to 0.86129, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-058-0.8613.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5078 - acc: 0.7612 - val_loss: 0.4689 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.86129 to 0.86408, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-059-0.8641.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5055 - acc: 0.7649 - val_loss: 0.4575 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.86408 to 0.86723, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-060-0.8672.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5036 - acc: 0.7666 - val_loss: 0.4576 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.86723 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-061-0.8693.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5007 - acc: 0.7656 - val_loss: 0.4523 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.86932 to 0.87142, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-062-0.8714.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5012 - acc: 0.7671 - val_loss: 0.4541 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87142 to 0.87421, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-063-0.8742.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4956 - acc: 0.7715 - val_loss: 0.4461 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.87421 to 0.87945, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-064-0.8795.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4971 - acc: 0.7680 - val_loss: 0.4486 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.87945 to 0.88190, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-065-0.8819.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4971 - acc: 0.7703 - val_loss: 0.4378 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.88190\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4933 - acc: 0.7725 - val_loss: 0.4380 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.88190 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-067-0.8861.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4876 - acc: 0.7752 - val_loss: 0.4282 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.88609\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4856 - acc: 0.7753 - val_loss: 0.4220 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.88609 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-069-0.8878.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4855 - acc: 0.7735 - val_loss: 0.4266 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.88784 to 0.88924, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-070-0.8892.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4861 - acc: 0.7765 - val_loss: 0.4247 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.88924 to 0.89099, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-071-0.8910.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4770 - acc: 0.7788 - val_loss: 0.4148 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.89099\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4747 - acc: 0.7787 - val_loss: 0.4093 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.89099 to 0.89273, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-073-0.8927.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4712 - acc: 0.7810 - val_loss: 0.4030 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.89273 to 0.89518, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-074-0.8952.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4741 - acc: 0.7817 - val_loss: 0.4067 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.89518 to 0.89623, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-075-0.8962.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4714 - acc: 0.7813 - val_loss: 0.4011 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.89623\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4644 - acc: 0.7866 - val_loss: 0.3890 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.89623 to 0.89797, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-077-0.8980.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4661 - acc: 0.7849 - val_loss: 0.3959 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.89797 to 0.89972, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-078-0.8997.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4633 - acc: 0.7900 - val_loss: 0.3986 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89972 to 0.90182, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-079-0.9018.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4560 - acc: 0.7925 - val_loss: 0.3925 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.90182\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4582 - acc: 0.7914 - val_loss: 0.3894 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.90182 to 0.90217, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-081-0.9022.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4607 - acc: 0.7919 - val_loss: 0.3909 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.90217\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4509 - acc: 0.7917 - val_loss: 0.3849 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.90217 to 0.90356, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-083-0.9036.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4503 - acc: 0.7947 - val_loss: 0.3908 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.90356 to 0.90671, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-084-0.9067.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4550 - acc: 0.7907 - val_loss: 0.3871 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.90671 to 0.90985, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-085-0.9099.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4517 - acc: 0.7964 - val_loss: 0.3776 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.90985 to 0.91440, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-086-0.9144.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4497 - acc: 0.7943 - val_loss: 0.3816 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.91440\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4431 - acc: 0.7981 - val_loss: 0.3778 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.91440 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-088-0.9151.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4429 - acc: 0.7974 - val_loss: 0.3657 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.91509\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4389 - acc: 0.7998 - val_loss: 0.3638 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.91509\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4428 - acc: 0.7964 - val_loss: 0.3685 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.91509\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4342 - acc: 0.8011 - val_loss: 0.3566 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.91509 to 0.91614, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-092-0.9161.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4381 - acc: 0.8032 - val_loss: 0.3566 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.91614 to 0.91649, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-093-0.9165.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4326 - acc: 0.8086 - val_loss: 0.3541 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.91649 to 0.91684, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-094-0.9168.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4309 - acc: 0.8068 - val_loss: 0.3497 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.91684 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-095-0.9200.hdf5\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4288 - acc: 0.8040 - val_loss: 0.3403 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.91999 to 0.92173, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-096-0.9217.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4302 - acc: 0.8057 - val_loss: 0.3413 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.92173 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-097-0.9231.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4297 - acc: 0.8051 - val_loss: 0.3432 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.92313\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4265 - acc: 0.8073 - val_loss: 0.3466 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.92313\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4254 - acc: 0.8091 - val_loss: 0.3483 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.92313 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-100-0.9235.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4225 - acc: 0.8118 - val_loss: 0.3409 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.92348 to 0.92593, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-101-0.9259.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4237 - acc: 0.8073 - val_loss: 0.3328 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.92593\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4168 - acc: 0.8139 - val_loss: 0.3320 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.92593\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4146 - acc: 0.8162 - val_loss: 0.3272 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.92593\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4185 - acc: 0.8130 - val_loss: 0.3360 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.92593\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4136 - acc: 0.8133 - val_loss: 0.3232 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.92593 to 0.92732, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-106-0.9273.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4118 - acc: 0.8198 - val_loss: 0.3229 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.92732 to 0.92767, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-107-0.9277.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4089 - acc: 0.8172 - val_loss: 0.3229 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.92767\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4079 - acc: 0.8176 - val_loss: 0.3190 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.92767\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4056 - acc: 0.8203 - val_loss: 0.3143 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.92767 to 0.93047, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-110-0.9305.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4079 - acc: 0.8165 - val_loss: 0.3205 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.93047 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-111-0.9322.hdf5\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4030 - acc: 0.8212 - val_loss: 0.3143 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.93222\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3987 - acc: 0.8220 - val_loss: 0.3117 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.93222\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3987 - acc: 0.8251 - val_loss: 0.3102 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.93222\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3994 - acc: 0.8254 - val_loss: 0.3082 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.93222\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4020 - acc: 0.8206 - val_loss: 0.3111 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93222\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3929 - acc: 0.8279 - val_loss: 0.3031 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.93222\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3958 - acc: 0.8213 - val_loss: 0.3013 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.93222 to 0.93326, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-118-0.9333.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3939 - acc: 0.8286 - val_loss: 0.3053 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93326\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3916 - acc: 0.8265 - val_loss: 0.2982 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93326\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3886 - acc: 0.8290 - val_loss: 0.2880 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93326\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3840 - acc: 0.8332 - val_loss: 0.2912 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93326\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3873 - acc: 0.8271 - val_loss: 0.2907 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.93326\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3907 - acc: 0.8273 - val_loss: 0.2981 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93326\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3859 - acc: 0.8327 - val_loss: 0.2901 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.93326\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3782 - acc: 0.8336 - val_loss: 0.2803 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.93326\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3856 - acc: 0.8313 - val_loss: 0.2881 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.93326 to 0.93431, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-127-0.9343.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3817 - acc: 0.8338 - val_loss: 0.2838 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.93431\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3775 - acc: 0.8356 - val_loss: 0.2772 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.93431\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3851 - acc: 0.8324 - val_loss: 0.2848 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.93431 to 0.93781, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-130-0.9378.hdf5\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3803 - acc: 0.8314 - val_loss: 0.2772 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.93781 to 0.93920, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-131-0.9392.hdf5\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3689 - acc: 0.8383 - val_loss: 0.2679 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.93920 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-132-0.9406.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3759 - acc: 0.8330 - val_loss: 0.2778 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94060\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3700 - acc: 0.8379 - val_loss: 0.2726 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.94060\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3757 - acc: 0.8362 - val_loss: 0.2736 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.94060\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3754 - acc: 0.8347 - val_loss: 0.2738 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.94060\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3709 - acc: 0.8347 - val_loss: 0.2669 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.94060\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3700 - acc: 0.8360 - val_loss: 0.2706 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.94060 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-138-0.9416.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3686 - acc: 0.8380 - val_loss: 0.2599 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.94165\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3636 - acc: 0.8402 - val_loss: 0.2616 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.94165\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3624 - acc: 0.8416 - val_loss: 0.2668 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.94165\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3703 - acc: 0.8385 - val_loss: 0.2719 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.94165 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-142-0.9420.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3683 - acc: 0.8420 - val_loss: 0.2643 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.94200\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3666 - acc: 0.8427 - val_loss: 0.2591 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.94200\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3750 - acc: 0.8382 - val_loss: 0.2692 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.94200\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3643 - acc: 0.8421 - val_loss: 0.2595 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.94200\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3596 - acc: 0.8439 - val_loss: 0.2589 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.94200\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3560 - acc: 0.8449 - val_loss: 0.2521 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.94200\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3563 - acc: 0.8457 - val_loss: 0.2466 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.94200\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3567 - acc: 0.8472 - val_loss: 0.2505 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.94200\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3558 - acc: 0.8429 - val_loss: 0.2490 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.94200\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3541 - acc: 0.8478 - val_loss: 0.2460 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.94200\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3504 - acc: 0.8469 - val_loss: 0.2500 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.94200\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3592 - acc: 0.8459 - val_loss: 0.2510 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.94200 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-154-0.9455.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3580 - acc: 0.8428 - val_loss: 0.2473 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.94549\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3502 - acc: 0.8501 - val_loss: 0.2439 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.94549\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3532 - acc: 0.8468 - val_loss: 0.2471 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.94549\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3530 - acc: 0.8440 - val_loss: 0.2422 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.94549\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3487 - acc: 0.8502 - val_loss: 0.2419 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.94549\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3528 - acc: 0.8447 - val_loss: 0.2410 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.94549 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-160-0.9458.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3455 - acc: 0.8490 - val_loss: 0.2357 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.94584\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3526 - acc: 0.8450 - val_loss: 0.2430 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.94584\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3458 - acc: 0.8496 - val_loss: 0.2399 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.94584 to 0.94759, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-163-0.9476.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3426 - acc: 0.8521 - val_loss: 0.2291 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.94759 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-164-0.9490.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3474 - acc: 0.8488 - val_loss: 0.2313 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.94899 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-165-0.9490.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3470 - acc: 0.8496 - val_loss: 0.2320 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.94899 to 0.95143, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-166-0.9514.hdf5\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3488 - acc: 0.8493 - val_loss: 0.2260 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95143\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3442 - acc: 0.8500 - val_loss: 0.2334 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95143\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3439 - acc: 0.8516 - val_loss: 0.2300 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95143\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3482 - acc: 0.8499 - val_loss: 0.2347 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95143\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3436 - acc: 0.8482 - val_loss: 0.2315 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.95143 to 0.95283, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-171-0.9528.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3411 - acc: 0.8498 - val_loss: 0.2294 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.95283\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3316 - acc: 0.8564 - val_loss: 0.2204 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.95283\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3387 - acc: 0.8552 - val_loss: 0.2271 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.95283\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3369 - acc: 0.8546 - val_loss: 0.2180 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.95283\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3341 - acc: 0.8563 - val_loss: 0.2173 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.95283 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-176-0.9532.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3428 - acc: 0.8508 - val_loss: 0.2238 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.95318\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3369 - acc: 0.8535 - val_loss: 0.2280 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.95318\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3368 - acc: 0.8558 - val_loss: 0.2256 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.95318\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3337 - acc: 0.8565 - val_loss: 0.2207 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.95318\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3309 - acc: 0.8580 - val_loss: 0.2211 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.95318 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-181-0.9532.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3355 - acc: 0.8582 - val_loss: 0.2196 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.95318\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3358 - acc: 0.8559 - val_loss: 0.2170 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.95318 to 0.95737, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-183-0.9574.hdf5\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3306 - acc: 0.8569 - val_loss: 0.2137 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.95737\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3273 - acc: 0.8611 - val_loss: 0.2159 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.95737\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3332 - acc: 0.8580 - val_loss: 0.2191 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.95737\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3388 - acc: 0.8571 - val_loss: 0.2205 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.95737\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3243 - acc: 0.8614 - val_loss: 0.2059 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.95737\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3328 - acc: 0.8574 - val_loss: 0.2163 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.95737\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3311 - acc: 0.8574 - val_loss: 0.2093 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.95737\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3280 - acc: 0.8600 - val_loss: 0.2120 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.95737\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3330 - acc: 0.8572 - val_loss: 0.2069 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.95737\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3275 - acc: 0.8595 - val_loss: 0.2080 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.95737\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3219 - acc: 0.8626 - val_loss: 0.2037 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.95737\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3281 - acc: 0.8547 - val_loss: 0.2036 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.95737\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3288 - acc: 0.8584 - val_loss: 0.2139 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.95737\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3274 - acc: 0.8604 - val_loss: 0.2084 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95737\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3216 - acc: 0.8617 - val_loss: 0.1988 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.95737\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3207 - acc: 0.8643 - val_loss: 0.2029 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.95737\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3224 - acc: 0.8617 - val_loss: 0.2061 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.95737 to 0.96296, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/0/weights-improvement-200-0.9630.hdf5\n",
      "It has been  0:18:44.261401\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1000, 26)     0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1000, 10)     270         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1000, 10)     790         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1000, 10)     1310        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1000, 10)     2350        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 1000, 10)     3910        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 5000, 10)     0           conv1d_11[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "                                                                 conv1d_14[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 500, 10)      0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 500, 314)     3454        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 500, 314)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 500, 77)      24255       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 500, 77)      0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 500, 8)       624         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 500, 8)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4000)         0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            8002        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6784 - acc: 0.6185 - val_loss: 0.6890 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75472, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-001-0.7547.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6640 - acc: 0.6243 - val_loss: 0.6767 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.75472\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6462 - acc: 0.6701 - val_loss: 0.6567 - val_acc: 0.7285\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75472\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6362 - acc: 0.6856 - val_loss: 0.6414 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75472\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6279 - acc: 0.6948 - val_loss: 0.6311 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75472\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6239 - acc: 0.6954 - val_loss: 0.6250 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75472\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6224 - acc: 0.6983 - val_loss: 0.6221 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75472\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6203 - acc: 0.6974 - val_loss: 0.6187 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75472\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6176 - acc: 0.6962 - val_loss: 0.6135 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75472\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6164 - acc: 0.6971 - val_loss: 0.6102 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75472\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6167 - acc: 0.6978 - val_loss: 0.6097 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75472\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6150 - acc: 0.6989 - val_loss: 0.6066 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75472\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6133 - acc: 0.6990 - val_loss: 0.6050 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75472\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6119 - acc: 0.7002 - val_loss: 0.6000 - val_acc: 0.7292\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75472\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6090 - acc: 0.6976 - val_loss: 0.5975 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75472\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6097 - acc: 0.7019 - val_loss: 0.5977 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75472\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6061 - acc: 0.6994 - val_loss: 0.5925 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75472\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6048 - acc: 0.7027 - val_loss: 0.5882 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75472\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6040 - acc: 0.7049 - val_loss: 0.5864 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75472\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6020 - acc: 0.7050 - val_loss: 0.5842 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75472\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5983 - acc: 0.7095 - val_loss: 0.5759 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75472\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5946 - acc: 0.7110 - val_loss: 0.5718 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75472\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5928 - acc: 0.7103 - val_loss: 0.5679 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75472\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5905 - acc: 0.7127 - val_loss: 0.5646 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75472\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5838 - acc: 0.7188 - val_loss: 0.5605 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.75472 to 0.75856, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-025-0.7586.hdf5\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5791 - acc: 0.7219 - val_loss: 0.5512 - val_acc: 0.7659\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.75856 to 0.76590, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-026-0.7659.hdf5\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5731 - acc: 0.7262 - val_loss: 0.5456 - val_acc: 0.7781\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.76590 to 0.77813, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-027-0.7781.hdf5\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5706 - acc: 0.7247 - val_loss: 0.5409 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.77813 to 0.78931, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-028-0.7893.hdf5\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5655 - acc: 0.7306 - val_loss: 0.5298 - val_acc: 0.8022\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.78931 to 0.80224, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-029-0.8022.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5623 - acc: 0.7314 - val_loss: 0.5312 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.80224 to 0.80922, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-030-0.8092.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5584 - acc: 0.7310 - val_loss: 0.5264 - val_acc: 0.8183\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.80922 to 0.81831, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-031-0.8183.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5538 - acc: 0.7377 - val_loss: 0.5208 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81831\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5481 - acc: 0.7407 - val_loss: 0.5115 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.81831 to 0.82215, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-033-0.8222.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5448 - acc: 0.7452 - val_loss: 0.5004 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.82215 to 0.82774, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-034-0.8277.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5396 - acc: 0.7414 - val_loss: 0.4853 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.82774 to 0.83508, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-035-0.8351.hdf5\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5380 - acc: 0.7432 - val_loss: 0.4789 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.83508 to 0.83823, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-036-0.8382.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5340 - acc: 0.7465 - val_loss: 0.4757 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.83823 to 0.84382, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-037-0.8438.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5305 - acc: 0.7537 - val_loss: 0.4690 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.84382 to 0.85150, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-038-0.8515.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5244 - acc: 0.7534 - val_loss: 0.4621 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.85150 to 0.85709, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-039-0.8571.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5221 - acc: 0.7549 - val_loss: 0.4592 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.85709 to 0.86233, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-040-0.8623.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5121 - acc: 0.7615 - val_loss: 0.4515 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.86233 to 0.86548, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-041-0.8655.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5117 - acc: 0.7603 - val_loss: 0.4423 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.86548 to 0.86827, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-042-0.8683.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5095 - acc: 0.7587 - val_loss: 0.4387 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.86827 to 0.87212, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-043-0.8721.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5094 - acc: 0.7601 - val_loss: 0.4412 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.87212 to 0.87491, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-044-0.8749.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5012 - acc: 0.7694 - val_loss: 0.4256 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.87491 to 0.87876, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-045-0.8788.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4994 - acc: 0.7677 - val_loss: 0.4215 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.87876 to 0.88155, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-046-0.8816.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4947 - acc: 0.7739 - val_loss: 0.4140 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.88155 to 0.88330, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-047-0.8833.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4904 - acc: 0.7743 - val_loss: 0.4065 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.88330 to 0.88365, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-048-0.8836.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4914 - acc: 0.7705 - val_loss: 0.4105 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.88365 to 0.88679, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-049-0.8868.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4860 - acc: 0.7749 - val_loss: 0.4040 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.88679\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4808 - acc: 0.7763 - val_loss: 0.3949 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.88679 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-051-0.8878.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4822 - acc: 0.7765 - val_loss: 0.3810 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.88784 to 0.89064, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-052-0.8906.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4776 - acc: 0.7775 - val_loss: 0.3902 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.89064 to 0.89378, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-053-0.8938.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4763 - acc: 0.7785 - val_loss: 0.3802 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.89378\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4710 - acc: 0.7824 - val_loss: 0.3756 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.89378 to 0.89483, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-055-0.8948.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4674 - acc: 0.7874 - val_loss: 0.3763 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.89483 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-056-0.8969.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4649 - acc: 0.7883 - val_loss: 0.3738 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.89693 to 0.89902, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-057-0.8990.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4603 - acc: 0.7882 - val_loss: 0.3740 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.89902 to 0.90077, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-058-0.9008.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4606 - acc: 0.7878 - val_loss: 0.3602 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.90077\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4586 - acc: 0.7898 - val_loss: 0.3595 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.90077 to 0.90217, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-060-0.9022.hdf5\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4582 - acc: 0.7891 - val_loss: 0.3604 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.90217 to 0.90531, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-061-0.9053.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4535 - acc: 0.7953 - val_loss: 0.3613 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.90531 to 0.90741, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-062-0.9074.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4524 - acc: 0.7929 - val_loss: 0.3514 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.90741 to 0.90776, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-063-0.9078.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4491 - acc: 0.7956 - val_loss: 0.3557 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.90776 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-064-0.9095.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4492 - acc: 0.7939 - val_loss: 0.3617 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.90950\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4466 - acc: 0.7953 - val_loss: 0.3427 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.90950 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-066-0.9116.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4451 - acc: 0.7984 - val_loss: 0.3566 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.91160\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4405 - acc: 0.7995 - val_loss: 0.3408 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.91160 to 0.91195, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-068-0.9119.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4373 - acc: 0.7978 - val_loss: 0.3508 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.91195 to 0.91370, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-069-0.9137.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4312 - acc: 0.8067 - val_loss: 0.3310 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.91370\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4308 - acc: 0.8050 - val_loss: 0.3337 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.91370 to 0.91544, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-071-0.9154.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4375 - acc: 0.8058 - val_loss: 0.3397 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.91544 to 0.91929, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-072-0.9193.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4279 - acc: 0.8129 - val_loss: 0.3353 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.91929\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4279 - acc: 0.8068 - val_loss: 0.3284 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.91929 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-074-0.9200.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4289 - acc: 0.8064 - val_loss: 0.3367 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.91999\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4271 - acc: 0.8085 - val_loss: 0.3285 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.91999 to 0.92488, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-076-0.9249.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4162 - acc: 0.8160 - val_loss: 0.3101 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.92488\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4186 - acc: 0.8129 - val_loss: 0.3292 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.92488\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4197 - acc: 0.8106 - val_loss: 0.3193 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.92488 to 0.92837, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-079-0.9284.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4232 - acc: 0.8102 - val_loss: 0.3301 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.92837 to 0.93047, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-080-0.9305.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4135 - acc: 0.8167 - val_loss: 0.3275 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.93047\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4154 - acc: 0.8134 - val_loss: 0.3160 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.93047 to 0.93117, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-082-0.9312.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4066 - acc: 0.8188 - val_loss: 0.3125 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.93117\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4165 - acc: 0.8179 - val_loss: 0.3185 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.93117 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-084-0.9315.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4103 - acc: 0.8141 - val_loss: 0.3067 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.93152 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-085-0.9322.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4042 - acc: 0.8193 - val_loss: 0.3208 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.93222\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3972 - acc: 0.8244 - val_loss: 0.3011 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.93222 to 0.93256, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-087-0.9326.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4060 - acc: 0.8174 - val_loss: 0.2991 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.93256 to 0.93396, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-088-0.9340.hdf5\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3995 - acc: 0.8234 - val_loss: 0.3030 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.93396 to 0.93396, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-089-0.9340.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3991 - acc: 0.8223 - val_loss: 0.3011 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93396\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4018 - acc: 0.8182 - val_loss: 0.3014 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.93396 to 0.93536, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-091-0.9354.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3928 - acc: 0.8265 - val_loss: 0.2897 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.93536\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4018 - acc: 0.8209 - val_loss: 0.3068 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.93536 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-093-0.9371.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3918 - acc: 0.8281 - val_loss: 0.3052 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93711\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3901 - acc: 0.8299 - val_loss: 0.2926 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93711\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3896 - acc: 0.8290 - val_loss: 0.2956 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.93711 to 0.93746, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-096-0.9375.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3938 - acc: 0.8258 - val_loss: 0.3070 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93746\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3858 - acc: 0.8280 - val_loss: 0.2808 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.93746 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-098-0.9396.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3891 - acc: 0.8279 - val_loss: 0.2929 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93955\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3825 - acc: 0.8285 - val_loss: 0.2868 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.93955 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-100-0.9406.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3823 - acc: 0.8317 - val_loss: 0.2850 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.94060 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-101-0.9420.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3805 - acc: 0.8323 - val_loss: 0.2749 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.94200 to 0.94375, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-102-0.9437.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3787 - acc: 0.8339 - val_loss: 0.2796 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.94375\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3788 - acc: 0.8347 - val_loss: 0.2766 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.94375 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-104-0.9455.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3741 - acc: 0.8368 - val_loss: 0.2719 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.94549 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-105-0.9458.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3789 - acc: 0.8307 - val_loss: 0.2758 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.94584\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3734 - acc: 0.8313 - val_loss: 0.2624 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.94584 to 0.94654, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-107-0.9465.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3782 - acc: 0.8344 - val_loss: 0.2830 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.94654\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3682 - acc: 0.8412 - val_loss: 0.2674 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.94654 to 0.94689, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-109-0.9469.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3705 - acc: 0.8376 - val_loss: 0.2626 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.94689\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3757 - acc: 0.8359 - val_loss: 0.2732 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.94689\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3682 - acc: 0.8400 - val_loss: 0.2671 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.94689\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3704 - acc: 0.8347 - val_loss: 0.2645 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.94689\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3696 - acc: 0.8347 - val_loss: 0.2760 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.94689\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3616 - acc: 0.8438 - val_loss: 0.2634 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.94689\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3651 - acc: 0.8413 - val_loss: 0.2616 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.94689\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3646 - acc: 0.8435 - val_loss: 0.2685 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.94689\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3621 - acc: 0.8466 - val_loss: 0.2564 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.94689\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3619 - acc: 0.8446 - val_loss: 0.2502 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.94689 to 0.94864, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-119-0.9486.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3575 - acc: 0.8420 - val_loss: 0.2621 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.94864\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3521 - acc: 0.8466 - val_loss: 0.2485 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.94864\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3488 - acc: 0.8501 - val_loss: 0.2491 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.94864\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3528 - acc: 0.8465 - val_loss: 0.2503 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.94864\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3531 - acc: 0.8462 - val_loss: 0.2539 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.94864\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3482 - acc: 0.8499 - val_loss: 0.2460 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.94864\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3530 - acc: 0.8437 - val_loss: 0.2464 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.94864\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3507 - acc: 0.8471 - val_loss: 0.2485 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.94864\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3416 - acc: 0.8546 - val_loss: 0.2369 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.94864\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3505 - acc: 0.8485 - val_loss: 0.2535 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.94864\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3358 - acc: 0.8577 - val_loss: 0.2332 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.94864\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3451 - acc: 0.8535 - val_loss: 0.2374 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.94864 to 0.95003, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-131-0.9500.hdf5\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3381 - acc: 0.8543 - val_loss: 0.2296 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95003\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3453 - acc: 0.8522 - val_loss: 0.2329 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95003\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3398 - acc: 0.8524 - val_loss: 0.2414 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95003\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3439 - acc: 0.8528 - val_loss: 0.2339 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.95003 to 0.95213, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-135-0.9521.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3397 - acc: 0.8529 - val_loss: 0.2352 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.95213\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3452 - acc: 0.8473 - val_loss: 0.2322 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.95213 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-137-0.9532.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3369 - acc: 0.8562 - val_loss: 0.2307 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95318\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3370 - acc: 0.8547 - val_loss: 0.2273 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95318\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3367 - acc: 0.8534 - val_loss: 0.2331 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95318\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3358 - acc: 0.8545 - val_loss: 0.2363 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.95318\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3393 - acc: 0.8571 - val_loss: 0.2345 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.95318\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3424 - acc: 0.8502 - val_loss: 0.2363 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95318\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3336 - acc: 0.8575 - val_loss: 0.2237 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95318\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3420 - acc: 0.8555 - val_loss: 0.2321 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95318\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3280 - acc: 0.8606 - val_loss: 0.2256 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95318\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3313 - acc: 0.8566 - val_loss: 0.2189 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.95318 to 0.95528, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-147-0.9553.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3302 - acc: 0.8609 - val_loss: 0.2214 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95528\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3293 - acc: 0.8604 - val_loss: 0.2177 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.95528\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3283 - acc: 0.8616 - val_loss: 0.2211 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95528\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3349 - acc: 0.8559 - val_loss: 0.2252 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95528\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3236 - acc: 0.8602 - val_loss: 0.2136 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.95528 to 0.95667, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-152-0.9567.hdf5\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3274 - acc: 0.8614 - val_loss: 0.2219 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95667\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3243 - acc: 0.8615 - val_loss: 0.2153 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95667\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3290 - acc: 0.8567 - val_loss: 0.2274 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95667\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3204 - acc: 0.8631 - val_loss: 0.2077 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.95667 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-156-0.9595.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3221 - acc: 0.8624 - val_loss: 0.2151 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.95947\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3228 - acc: 0.8628 - val_loss: 0.2172 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95947\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3167 - acc: 0.8636 - val_loss: 0.2029 - val_acc: 0.9577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95947\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3211 - acc: 0.8637 - val_loss: 0.2100 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.95947\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3159 - acc: 0.8705 - val_loss: 0.2090 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95947\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3122 - acc: 0.8689 - val_loss: 0.2149 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.95947\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3222 - acc: 0.8605 - val_loss: 0.2283 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95947\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3253 - acc: 0.8594 - val_loss: 0.2079 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.95947 to 0.96226, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-164-0.9623.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3155 - acc: 0.8655 - val_loss: 0.2094 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.96226\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3178 - acc: 0.8614 - val_loss: 0.2085 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.96226\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3136 - acc: 0.8663 - val_loss: 0.2060 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.96226\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3119 - acc: 0.8673 - val_loss: 0.1984 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.96226\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3121 - acc: 0.8700 - val_loss: 0.1994 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.96226\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3119 - acc: 0.8671 - val_loss: 0.2038 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.96226\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3092 - acc: 0.8704 - val_loss: 0.2005 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.96226\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3125 - acc: 0.8645 - val_loss: 0.2053 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.96226\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3021 - acc: 0.8721 - val_loss: 0.1981 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.96226\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3068 - acc: 0.8700 - val_loss: 0.2081 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.96226\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3063 - acc: 0.8705 - val_loss: 0.2026 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.96226\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3085 - acc: 0.8682 - val_loss: 0.1998 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.96226\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3070 - acc: 0.8696 - val_loss: 0.1932 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.96226\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3091 - acc: 0.8655 - val_loss: 0.2040 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96226\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3001 - acc: 0.8740 - val_loss: 0.1998 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96226\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3115 - acc: 0.8651 - val_loss: 0.1984 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96226\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3066 - acc: 0.8707 - val_loss: 0.2019 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96226\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3110 - acc: 0.8670 - val_loss: 0.2029 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96226\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3049 - acc: 0.8707 - val_loss: 0.2005 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96226\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2974 - acc: 0.8732 - val_loss: 0.1930 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96226\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3003 - acc: 0.8741 - val_loss: 0.2049 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.96226\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3016 - acc: 0.8736 - val_loss: 0.2092 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96226\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3025 - acc: 0.8731 - val_loss: 0.2040 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.96226\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3009 - acc: 0.8714 - val_loss: 0.1891 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.96226\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3058 - acc: 0.8694 - val_loss: 0.2077 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.96226\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2981 - acc: 0.8740 - val_loss: 0.2039 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.96226\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2980 - acc: 0.8761 - val_loss: 0.2019 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96226\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3000 - acc: 0.8721 - val_loss: 0.1966 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.96226\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3002 - acc: 0.8756 - val_loss: 0.1980 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.96226\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3002 - acc: 0.8733 - val_loss: 0.1846 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.96226 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-194-0.9626.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3034 - acc: 0.8724 - val_loss: 0.1862 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.96261\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3037 - acc: 0.8730 - val_loss: 0.1881 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.96261\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2956 - acc: 0.8739 - val_loss: 0.1822 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.96261\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2932 - acc: 0.8769 - val_loss: 0.1789 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.96261 to 0.96401, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/1/weights-improvement-198-0.9640.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.2941 - acc: 0.8752 - val_loss: 0.1851 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.96401\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2961 - acc: 0.8746 - val_loss: 0.1830 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.96401\n",
      "It has been  0:18:31.192545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000, 26)     0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 1000, 10)     270         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 1000, 10)     790         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 1000, 10)     1310        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 1000, 10)     2350        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1000, 10)     3910        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5000, 10)     0           conv1d_16[0][0]                  \n",
      "                                                                 conv1d_17[0][0]                  \n",
      "                                                                 conv1d_18[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 500, 10)      0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 500, 314)     3454        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 500, 314)     0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 500, 77)      24255       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 500, 77)      0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 500, 8)       624         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 500, 8)       0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 4000)         0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            8002        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6774 - acc: 0.6201 - val_loss: 0.6781 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71593, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-001-0.7159.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6605 - acc: 0.6233 - val_loss: 0.6719 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71593 to 0.78896, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-002-0.7890.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6450 - acc: 0.6659 - val_loss: 0.6470 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.78896\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6307 - acc: 0.6877 - val_loss: 0.6293 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78896\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6233 - acc: 0.6919 - val_loss: 0.6180 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78896\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6208 - acc: 0.6944 - val_loss: 0.6126 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78896\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6178 - acc: 0.6984 - val_loss: 0.6090 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78896\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6164 - acc: 0.6964 - val_loss: 0.6045 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78896\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6157 - acc: 0.6974 - val_loss: 0.6032 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78896\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6162 - acc: 0.6974 - val_loss: 0.6033 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78896\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6143 - acc: 0.6980 - val_loss: 0.6004 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78896\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6121 - acc: 0.7005 - val_loss: 0.5991 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78896\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6132 - acc: 0.6997 - val_loss: 0.5989 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78896\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6120 - acc: 0.6986 - val_loss: 0.5968 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78896\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6086 - acc: 0.7012 - val_loss: 0.5924 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78896\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6090 - acc: 0.7010 - val_loss: 0.5914 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78896\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6043 - acc: 0.7023 - val_loss: 0.5885 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78896\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6037 - acc: 0.7024 - val_loss: 0.5872 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78896\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6039 - acc: 0.7061 - val_loss: 0.5858 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78896\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5993 - acc: 0.7047 - val_loss: 0.5819 - val_acc: 0.7369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00020: val_acc did not improve from 0.78896\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5990 - acc: 0.7028 - val_loss: 0.5787 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.78896\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5951 - acc: 0.7061 - val_loss: 0.5758 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.78896\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5925 - acc: 0.7089 - val_loss: 0.5732 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.78896\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5904 - acc: 0.7107 - val_loss: 0.5669 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.78896\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5860 - acc: 0.7146 - val_loss: 0.5640 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78896\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5836 - acc: 0.7153 - val_loss: 0.5598 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.78896\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5792 - acc: 0.7179 - val_loss: 0.5539 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.78896\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5780 - acc: 0.7188 - val_loss: 0.5511 - val_acc: 0.7729\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.78896\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5737 - acc: 0.7201 - val_loss: 0.5438 - val_acc: 0.7774\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.78896\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5679 - acc: 0.7252 - val_loss: 0.5373 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.78896\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5670 - acc: 0.7256 - val_loss: 0.5305 - val_acc: 0.7841\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.78896\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5639 - acc: 0.7285 - val_loss: 0.5263 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.78896\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5576 - acc: 0.7309 - val_loss: 0.5185 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.78896 to 0.79280, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-033-0.7928.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5556 - acc: 0.7340 - val_loss: 0.5132 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.79280 to 0.79560, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-034-0.7956.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5502 - acc: 0.7343 - val_loss: 0.5083 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.79560 to 0.79979, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-035-0.7998.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5433 - acc: 0.7393 - val_loss: 0.5007 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.79979 to 0.80189, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-036-0.8019.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5424 - acc: 0.7382 - val_loss: 0.4930 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.80189 to 0.80398, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-037-0.8040.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5355 - acc: 0.7446 - val_loss: 0.4825 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.80398 to 0.80992, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-038-0.8099.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5332 - acc: 0.7458 - val_loss: 0.4809 - val_acc: 0.8148\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.80992 to 0.81481, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-039-0.8148.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5327 - acc: 0.7467 - val_loss: 0.4711 - val_acc: 0.8225\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.81481 to 0.82250, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-040-0.8225.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5213 - acc: 0.7568 - val_loss: 0.4634 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82250 to 0.83473, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-041-0.8347.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5203 - acc: 0.7555 - val_loss: 0.4466 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.83473 to 0.84556, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-042-0.8456.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5150 - acc: 0.7570 - val_loss: 0.4386 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.84556 to 0.84801, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-043-0.8480.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5088 - acc: 0.7598 - val_loss: 0.4317 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.84801 to 0.85500, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-044-0.8550.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5026 - acc: 0.7615 - val_loss: 0.4239 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.85500 to 0.85744, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-045-0.8574.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4992 - acc: 0.7712 - val_loss: 0.4160 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.85744 to 0.86164, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-046-0.8616.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4963 - acc: 0.7663 - val_loss: 0.3988 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.86164 to 0.86792, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-047-0.8679.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4900 - acc: 0.7673 - val_loss: 0.3951 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.86792 to 0.87072, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-048-0.8707.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4832 - acc: 0.7775 - val_loss: 0.3835 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.87072 to 0.87736, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-049-0.8774.hdf5\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4859 - acc: 0.7763 - val_loss: 0.3928 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.87736\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4789 - acc: 0.7776 - val_loss: 0.3782 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.87736 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-051-0.8829.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4761 - acc: 0.7782 - val_loss: 0.3679 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.88295 to 0.88854, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-052-0.8885.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4699 - acc: 0.7835 - val_loss: 0.3761 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.88854\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4711 - acc: 0.7828 - val_loss: 0.3674 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.88854 to 0.89273, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-054-0.8927.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4643 - acc: 0.7863 - val_loss: 0.3612 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.89273 to 0.89483, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-055-0.8948.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4565 - acc: 0.7940 - val_loss: 0.3481 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.89483 to 0.89623, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-056-0.8962.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4617 - acc: 0.7889 - val_loss: 0.3512 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.89623 to 0.89727, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-057-0.8973.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4522 - acc: 0.7909 - val_loss: 0.3321 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.89727 to 0.89972, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-058-0.8997.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4532 - acc: 0.7932 - val_loss: 0.3425 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.89972 to 0.90182, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-059-0.9018.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4465 - acc: 0.7971 - val_loss: 0.3182 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.90182\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4391 - acc: 0.8033 - val_loss: 0.3162 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.90182\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4436 - acc: 0.7976 - val_loss: 0.3123 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.90182 to 0.90391, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-062-0.9039.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4346 - acc: 0.8012 - val_loss: 0.3101 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.90391 to 0.90461, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-063-0.9046.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4391 - acc: 0.8063 - val_loss: 0.3105 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.90461 to 0.90741, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-064-0.9074.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4319 - acc: 0.8069 - val_loss: 0.3070 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.90741 to 0.91020, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-065-0.9102.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4328 - acc: 0.8054 - val_loss: 0.3119 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.91020 to 0.91265, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-066-0.9126.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4264 - acc: 0.8064 - val_loss: 0.2991 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.91265 to 0.91405, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-067-0.9140.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4214 - acc: 0.8103 - val_loss: 0.2914 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.91405 to 0.91684, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-068-0.9168.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4200 - acc: 0.8104 - val_loss: 0.2787 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.91684\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4179 - acc: 0.8118 - val_loss: 0.2812 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.91684 to 0.91684, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-070-0.9168.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4157 - acc: 0.8141 - val_loss: 0.2875 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.91684 to 0.92068, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-071-0.9207.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4195 - acc: 0.8132 - val_loss: 0.2785 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.92068 to 0.92068, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-072-0.9207.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4144 - acc: 0.8144 - val_loss: 0.2807 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.92068 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-073-0.9231.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4110 - acc: 0.8197 - val_loss: 0.2830 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.92313 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-074-0.9238.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4039 - acc: 0.8197 - val_loss: 0.2669 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.92383 to 0.92488, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-075-0.9249.hdf5\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4053 - acc: 0.8184 - val_loss: 0.2707 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.92488 to 0.92802, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-076-0.9280.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3990 - acc: 0.8208 - val_loss: 0.2557 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.92802\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4053 - acc: 0.8212 - val_loss: 0.2603 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.92802\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4035 - acc: 0.8190 - val_loss: 0.2542 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.92802 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-079-0.9287.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3943 - acc: 0.8261 - val_loss: 0.2504 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.92872\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3904 - acc: 0.8265 - val_loss: 0.2489 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.92872 to 0.92977, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-081-0.9298.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3956 - acc: 0.8226 - val_loss: 0.2532 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.92977 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-082-0.9301.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3916 - acc: 0.8274 - val_loss: 0.2463 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.93012 to 0.93082, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-083-0.9308.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3899 - acc: 0.8244 - val_loss: 0.2405 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.93082 to 0.93187, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-084-0.9319.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3811 - acc: 0.8330 - val_loss: 0.2356 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.93187\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3882 - acc: 0.8305 - val_loss: 0.2540 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.93187 to 0.93431, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-086-0.9343.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3831 - acc: 0.8301 - val_loss: 0.2434 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.93431\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3807 - acc: 0.8338 - val_loss: 0.2397 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.93431\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3776 - acc: 0.8333 - val_loss: 0.2187 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.93431\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3817 - acc: 0.8322 - val_loss: 0.2255 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93431\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3853 - acc: 0.8319 - val_loss: 0.2308 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.93431\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3763 - acc: 0.8361 - val_loss: 0.2307 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.93431 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-092-0.9357.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3738 - acc: 0.8358 - val_loss: 0.2231 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.93571 to 0.93606, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-093-0.9361.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3667 - acc: 0.8362 - val_loss: 0.2109 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93606\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3700 - acc: 0.8399 - val_loss: 0.2168 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93606\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3657 - acc: 0.8395 - val_loss: 0.2180 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.93606 to 0.93816, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-096-0.9382.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3716 - acc: 0.8360 - val_loss: 0.2172 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93816\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3684 - acc: 0.8390 - val_loss: 0.2104 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93816\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3626 - acc: 0.8432 - val_loss: 0.2056 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93816\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3656 - acc: 0.8448 - val_loss: 0.2089 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93816\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3622 - acc: 0.8419 - val_loss: 0.2195 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.93816 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-101-0.9403.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3561 - acc: 0.8429 - val_loss: 0.2059 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.94025\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3613 - acc: 0.8423 - val_loss: 0.2081 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.94025 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-103-0.9403.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3618 - acc: 0.8396 - val_loss: 0.2064 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.94025\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3554 - acc: 0.8421 - val_loss: 0.2094 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.94025\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3533 - acc: 0.8476 - val_loss: 0.2012 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.94025 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-106-0.9416.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3525 - acc: 0.8474 - val_loss: 0.2008 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.94165\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3634 - acc: 0.8423 - val_loss: 0.2086 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.94165 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-108-0.9420.hdf5\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3490 - acc: 0.8479 - val_loss: 0.1940 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.94200 to 0.94235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-109-0.9423.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3425 - acc: 0.8527 - val_loss: 0.1901 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.94235 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-110-0.9430.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3471 - acc: 0.8520 - val_loss: 0.1874 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.94305 to 0.94375, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-111-0.9437.hdf5\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3479 - acc: 0.8490 - val_loss: 0.1942 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.94375 to 0.94444, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-112-0.9444.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3432 - acc: 0.8507 - val_loss: 0.1956 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.94444 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-113-0.9455.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3474 - acc: 0.8464 - val_loss: 0.1989 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.94549 to 0.94759, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-114-0.9476.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3450 - acc: 0.8519 - val_loss: 0.1868 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.94759\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3441 - acc: 0.8495 - val_loss: 0.1891 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.94759 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-116-0.9479.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3423 - acc: 0.8471 - val_loss: 0.1905 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.94794 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-117-0.9490.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3418 - acc: 0.8525 - val_loss: 0.1883 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.94899\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3451 - acc: 0.8496 - val_loss: 0.1914 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.94899 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-119-0.9504.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3350 - acc: 0.8553 - val_loss: 0.1776 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.95038\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3394 - acc: 0.8553 - val_loss: 0.1842 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.95038 to 0.95213, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-121-0.9521.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3392 - acc: 0.8506 - val_loss: 0.1940 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.95213 to 0.95528, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-122-0.9553.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3277 - acc: 0.8585 - val_loss: 0.1758 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.95528\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3317 - acc: 0.8564 - val_loss: 0.1806 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.95528\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3299 - acc: 0.8564 - val_loss: 0.1806 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.95528\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3385 - acc: 0.8535 - val_loss: 0.1796 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.95528\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3337 - acc: 0.8561 - val_loss: 0.1753 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95528\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3252 - acc: 0.8585 - val_loss: 0.1704 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.95528 to 0.95702, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-128-0.9570.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3303 - acc: 0.8611 - val_loss: 0.1765 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.95702 to 0.95737, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-129-0.9574.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3208 - acc: 0.8626 - val_loss: 0.1689 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95737\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3272 - acc: 0.8578 - val_loss: 0.1758 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.95737 to 0.95772, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-131-0.9577.hdf5\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3268 - acc: 0.8578 - val_loss: 0.1784 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.95772 to 0.95912, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-132-0.9591.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3280 - acc: 0.8579 - val_loss: 0.1734 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.95912 to 0.95982, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-133-0.9598.hdf5\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3236 - acc: 0.8617 - val_loss: 0.1725 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95982\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3178 - acc: 0.8643 - val_loss: 0.1651 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.95982 to 0.96157, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-135-0.9616.hdf5\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3218 - acc: 0.8616 - val_loss: 0.1672 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.96157\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3197 - acc: 0.8640 - val_loss: 0.1770 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.96157\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3195 - acc: 0.8658 - val_loss: 0.1680 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.96157 to 0.96436, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-138-0.9644.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3238 - acc: 0.8628 - val_loss: 0.1704 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.96436\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3294 - acc: 0.8564 - val_loss: 0.1715 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.96436\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3215 - acc: 0.8633 - val_loss: 0.1730 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.96436\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3131 - acc: 0.8668 - val_loss: 0.1618 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.96436\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3222 - acc: 0.8623 - val_loss: 0.1713 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.96436 to 0.96471, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-143-0.9647.hdf5\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3224 - acc: 0.8615 - val_loss: 0.1716 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.96471 to 0.96541, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-144-0.9654.hdf5\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3184 - acc: 0.8660 - val_loss: 0.1607 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.96541\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3158 - acc: 0.8636 - val_loss: 0.1618 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.96541 to 0.96681, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-146-0.9668.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3144 - acc: 0.8661 - val_loss: 0.1609 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.96681\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3142 - acc: 0.8651 - val_loss: 0.1623 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.96681 to 0.96751, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-148-0.9675.hdf5\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3121 - acc: 0.8656 - val_loss: 0.1636 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.96751 to 0.96890, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-149-0.9689.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3102 - acc: 0.8693 - val_loss: 0.1608 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.96890 to 0.97030, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-150-0.9703.hdf5\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3051 - acc: 0.8710 - val_loss: 0.1602 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.97030\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3101 - acc: 0.8676 - val_loss: 0.1588 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.97030 to 0.97100, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-152-0.9710.hdf5\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3087 - acc: 0.8662 - val_loss: 0.1548 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.97100\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3058 - acc: 0.8682 - val_loss: 0.1644 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.97100 to 0.97135, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-154-0.9713.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3061 - acc: 0.8683 - val_loss: 0.1555 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.97135 to 0.97170, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-155-0.9717.hdf5\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3113 - acc: 0.8672 - val_loss: 0.1564 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.97170\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3097 - acc: 0.8674 - val_loss: 0.1513 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.97170\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3051 - acc: 0.8721 - val_loss: 0.1497 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.97170\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3001 - acc: 0.8734 - val_loss: 0.1458 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.97170\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2983 - acc: 0.8735 - val_loss: 0.1472 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.97170\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3058 - acc: 0.8689 - val_loss: 0.1514 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.97170\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3066 - acc: 0.8685 - val_loss: 0.1498 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.97170 to 0.97310, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-162-0.9731.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3100 - acc: 0.8689 - val_loss: 0.1601 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.97310 to 0.97554, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-163-0.9755.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3032 - acc: 0.8694 - val_loss: 0.1557 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.97554\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3058 - acc: 0.8701 - val_loss: 0.1623 - val_acc: 0.9755\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.97554\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2952 - acc: 0.8761 - val_loss: 0.1469 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.97554\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2996 - acc: 0.8751 - val_loss: 0.1441 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.97554\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2961 - acc: 0.8747 - val_loss: 0.1408 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.97554\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3005 - acc: 0.8746 - val_loss: 0.1501 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.97554\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3002 - acc: 0.8762 - val_loss: 0.1510 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.97554\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2984 - acc: 0.8730 - val_loss: 0.1445 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.97554\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2929 - acc: 0.8746 - val_loss: 0.1431 - val_acc: 0.9745\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.97554\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2986 - acc: 0.8693 - val_loss: 0.1416 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.97554\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2961 - acc: 0.8729 - val_loss: 0.1514 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.97554 to 0.97624, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-174-0.9762.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2910 - acc: 0.8788 - val_loss: 0.1438 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.97624\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2908 - acc: 0.8794 - val_loss: 0.1342 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.97624 to 0.97799, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-176-0.9780.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2906 - acc: 0.8802 - val_loss: 0.1363 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.97799\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2937 - acc: 0.8798 - val_loss: 0.1442 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.97799 to 0.97834, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-178-0.9783.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2938 - acc: 0.8749 - val_loss: 0.1367 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.97834\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2907 - acc: 0.8769 - val_loss: 0.1304 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.97834\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2944 - acc: 0.8767 - val_loss: 0.1386 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.97834\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2937 - acc: 0.8769 - val_loss: 0.1455 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.97834 to 0.97834, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-182-0.9783.hdf5\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2823 - acc: 0.8823 - val_loss: 0.1311 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.97834\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2967 - acc: 0.8763 - val_loss: 0.1328 - val_acc: 0.9762\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.97834\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2947 - acc: 0.8730 - val_loss: 0.1395 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.97834\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2841 - acc: 0.8778 - val_loss: 0.1302 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.97834\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2921 - acc: 0.8764 - val_loss: 0.1264 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.97834\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2852 - acc: 0.8803 - val_loss: 0.1333 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.97834\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2846 - acc: 0.8791 - val_loss: 0.1316 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.97834 to 0.97973, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-189-0.9797.hdf5\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2880 - acc: 0.8789 - val_loss: 0.1329 - val_acc: 0.9797\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.97973\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2890 - acc: 0.8784 - val_loss: 0.1331 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.97973 to 0.98183, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-191-0.9818.hdf5\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2786 - acc: 0.8818 - val_loss: 0.1225 - val_acc: 0.9801\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.98183\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2869 - acc: 0.8772 - val_loss: 0.1343 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.98183\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2841 - acc: 0.8803 - val_loss: 0.1265 - val_acc: 0.9808\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.98183\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2811 - acc: 0.8798 - val_loss: 0.1235 - val_acc: 0.9822\n",
      "\n",
      "Epoch 00195: val_acc improved from 0.98183 to 0.98218, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-195-0.9822.hdf5\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2850 - acc: 0.8769 - val_loss: 0.1313 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.98218\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2839 - acc: 0.8793 - val_loss: 0.1307 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.98218 to 0.98358, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-197-0.9836.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2855 - acc: 0.8811 - val_loss: 0.1361 - val_acc: 0.9825\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.98358\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2858 - acc: 0.8816 - val_loss: 0.1357 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.98358 to 0.98393, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/2/weights-improvement-199-0.9839.hdf5\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.2799 - acc: 0.8857 - val_loss: 0.1251 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.98393\n",
      "It has been  0:18:47.007643\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000, 26)     0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1000, 10)     270         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1000, 10)     790         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1000, 10)     1310        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1000, 10)     2350        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1000, 10)     3910        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5000, 10)     0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "                                                                 conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 500, 10)      0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 500, 314)     3454        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 500, 314)     0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 500, 77)      24255       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 500, 77)      0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 500, 8)       624         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 500, 8)       0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 4000)         0           dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            8002        flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6765 - acc: 0.6254 - val_loss: 0.6879 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73829, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-001-0.7383.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6573 - acc: 0.6332 - val_loss: 0.6755 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.73829 to 0.75926, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-002-0.7593.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6434 - acc: 0.6652 - val_loss: 0.6529 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75926\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6319 - acc: 0.6878 - val_loss: 0.6405 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75926\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6260 - acc: 0.6856 - val_loss: 0.6318 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75926\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6205 - acc: 0.6936 - val_loss: 0.6237 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75926\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6200 - acc: 0.6928 - val_loss: 0.6246 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75926\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6182 - acc: 0.6970 - val_loss: 0.6218 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75926\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6171 - acc: 0.6946 - val_loss: 0.6202 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75926\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6154 - acc: 0.6966 - val_loss: 0.6192 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75926\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6144 - acc: 0.6980 - val_loss: 0.6159 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75926\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6137 - acc: 0.6982 - val_loss: 0.6138 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75926\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6124 - acc: 0.6976 - val_loss: 0.6108 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75926\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6112 - acc: 0.6979 - val_loss: 0.6099 - val_acc: 0.7236\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75926\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6090 - acc: 0.6984 - val_loss: 0.6067 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75926\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6101 - acc: 0.6958 - val_loss: 0.6058 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75926\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6057 - acc: 0.7031 - val_loss: 0.6067 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75926\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6069 - acc: 0.7001 - val_loss: 0.6061 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75926\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6061 - acc: 0.7022 - val_loss: 0.6042 - val_acc: 0.7177\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75926\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6032 - acc: 0.7029 - val_loss: 0.6020 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75926\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6018 - acc: 0.7019 - val_loss: 0.6007 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75926\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6019 - acc: 0.7037 - val_loss: 0.6005 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75926\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5988 - acc: 0.7053 - val_loss: 0.5963 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75926\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5974 - acc: 0.7052 - val_loss: 0.5967 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75926\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5958 - acc: 0.7068 - val_loss: 0.5951 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75926\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5942 - acc: 0.7068 - val_loss: 0.5937 - val_acc: 0.7236\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75926\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5929 - acc: 0.7097 - val_loss: 0.5920 - val_acc: 0.7219\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.75926\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5914 - acc: 0.7086 - val_loss: 0.5900 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.75926\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5887 - acc: 0.7116 - val_loss: 0.5893 - val_acc: 0.7219\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.75926\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5874 - acc: 0.7115 - val_loss: 0.5894 - val_acc: 0.7194\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.75926\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5847 - acc: 0.7140 - val_loss: 0.5883 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.75926\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5810 - acc: 0.7171 - val_loss: 0.5849 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.75926\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5795 - acc: 0.7175 - val_loss: 0.5813 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.75926\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5778 - acc: 0.7167 - val_loss: 0.5803 - val_acc: 0.7285\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.75926\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5747 - acc: 0.7236 - val_loss: 0.5753 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.75926\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5710 - acc: 0.7263 - val_loss: 0.5648 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.75926\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5683 - acc: 0.7212 - val_loss: 0.5640 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.75926\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5665 - acc: 0.7278 - val_loss: 0.5625 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.75926\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5627 - acc: 0.7300 - val_loss: 0.5557 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.75926\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5600 - acc: 0.7292 - val_loss: 0.5465 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.75926 to 0.76031, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-040-0.7603.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5582 - acc: 0.7292 - val_loss: 0.5430 - val_acc: 0.7610\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.76031 to 0.76101, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-041-0.7610.hdf5\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5570 - acc: 0.7326 - val_loss: 0.5381 - val_acc: 0.7666\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.76101 to 0.76660, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-042-0.7666.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5470 - acc: 0.7411 - val_loss: 0.5361 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.76660 to 0.76695, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-043-0.7669.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5450 - acc: 0.7390 - val_loss: 0.5258 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.76695 to 0.78232, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-044-0.7823.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5397 - acc: 0.7452 - val_loss: 0.5200 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.78232 to 0.78686, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-045-0.7869.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5392 - acc: 0.7430 - val_loss: 0.5178 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.78686 to 0.79001, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-046-0.7900.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5347 - acc: 0.7458 - val_loss: 0.5176 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.79001 to 0.79665, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-047-0.7966.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5332 - acc: 0.7493 - val_loss: 0.5136 - val_acc: 0.7973\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.79665 to 0.79734, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-048-0.7973.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5291 - acc: 0.7506 - val_loss: 0.4998 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.79734 to 0.80713, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-049-0.8071.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5306 - acc: 0.7486 - val_loss: 0.5028 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.80713\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5251 - acc: 0.7538 - val_loss: 0.4875 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.80713 to 0.80957, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-051-0.8096.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5218 - acc: 0.7548 - val_loss: 0.4823 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.80957 to 0.81516, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-052-0.8152.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5204 - acc: 0.7561 - val_loss: 0.4719 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.81516 to 0.82460, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-053-0.8246.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5167 - acc: 0.7589 - val_loss: 0.4715 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.82460\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5115 - acc: 0.7626 - val_loss: 0.4623 - val_acc: 0.8333\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.82460 to 0.83333, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-055-0.8333.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5124 - acc: 0.7608 - val_loss: 0.4660 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.83333 to 0.83508, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-056-0.8351.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5088 - acc: 0.7624 - val_loss: 0.4518 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.83508 to 0.84626, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-057-0.8463.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5039 - acc: 0.7638 - val_loss: 0.4445 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.84626 to 0.85080, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-058-0.8508.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5036 - acc: 0.7628 - val_loss: 0.4396 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.85080 to 0.85290, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-059-0.8529.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5009 - acc: 0.7669 - val_loss: 0.4391 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.85290 to 0.85639, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-060-0.8564.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4953 - acc: 0.7697 - val_loss: 0.4485 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.85639\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4926 - acc: 0.7704 - val_loss: 0.4355 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.85639 to 0.86024, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-062-0.8602.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4917 - acc: 0.7722 - val_loss: 0.4249 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.86024 to 0.86059, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-063-0.8606.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4864 - acc: 0.7729 - val_loss: 0.4257 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.86059 to 0.86198, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-064-0.8620.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4882 - acc: 0.7725 - val_loss: 0.4299 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.86198 to 0.86443, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-065-0.8644.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4836 - acc: 0.7767 - val_loss: 0.4274 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.86443 to 0.87002, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-066-0.8700.hdf5\n",
      "Epoch 67/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4791 - acc: 0.7778 - val_loss: 0.4226 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87002\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4811 - acc: 0.7781 - val_loss: 0.4160 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.87002 to 0.87177, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-068-0.8718.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4791 - acc: 0.7782 - val_loss: 0.4144 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87177 to 0.87456, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-069-0.8746.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4766 - acc: 0.7807 - val_loss: 0.4112 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87456\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4701 - acc: 0.7846 - val_loss: 0.3997 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.87456 to 0.88155, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-071-0.8816.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4631 - acc: 0.7896 - val_loss: 0.4029 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88155\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4662 - acc: 0.7869 - val_loss: 0.4023 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.88155 to 0.88260, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-073-0.8826.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4618 - acc: 0.7880 - val_loss: 0.4001 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.88260 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-074-0.8850.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4607 - acc: 0.7885 - val_loss: 0.3943 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.88505\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4608 - acc: 0.7863 - val_loss: 0.3949 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.88505 to 0.88749, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-076-0.8875.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4538 - acc: 0.7939 - val_loss: 0.3774 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.88749 to 0.89308, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-077-0.8931.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4505 - acc: 0.7958 - val_loss: 0.3809 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.89308 to 0.89378, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-078-0.8938.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4518 - acc: 0.7920 - val_loss: 0.3819 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89378 to 0.89588, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-079-0.8959.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4493 - acc: 0.7992 - val_loss: 0.3778 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.89588 to 0.89797, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-080-0.8980.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4465 - acc: 0.7939 - val_loss: 0.3758 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.89797\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4398 - acc: 0.7996 - val_loss: 0.3731 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.89797\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4443 - acc: 0.7969 - val_loss: 0.3755 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.89797 to 0.89797, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-083-0.8980.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4406 - acc: 0.7978 - val_loss: 0.3627 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.89797 to 0.90042, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-084-0.9004.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4389 - acc: 0.8001 - val_loss: 0.3625 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.90042 to 0.90217, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-085-0.9022.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4381 - acc: 0.7990 - val_loss: 0.3652 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.90217 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-086-0.9043.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4324 - acc: 0.8051 - val_loss: 0.3543 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.90426\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4331 - acc: 0.8016 - val_loss: 0.3636 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90426 to 0.90776, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-088-0.9078.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4308 - acc: 0.8045 - val_loss: 0.3606 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.90776\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4259 - acc: 0.8104 - val_loss: 0.3369 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.90776\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4287 - acc: 0.8052 - val_loss: 0.3565 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.90776 to 0.90881, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-091-0.9088.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4274 - acc: 0.8074 - val_loss: 0.3575 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.90881\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4235 - acc: 0.8101 - val_loss: 0.3490 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.90881 to 0.90985, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-093-0.9099.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4197 - acc: 0.8120 - val_loss: 0.3412 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.90985\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4183 - acc: 0.8076 - val_loss: 0.3457 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.90985\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4181 - acc: 0.8144 - val_loss: 0.3376 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.90985 to 0.91405, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-096-0.9140.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4153 - acc: 0.8157 - val_loss: 0.3382 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.91405 to 0.91474, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-097-0.9147.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4119 - acc: 0.8175 - val_loss: 0.3326 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.91474\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4101 - acc: 0.8180 - val_loss: 0.3290 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.91474\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4041 - acc: 0.8175 - val_loss: 0.3352 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.91474 to 0.91789, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-100-0.9179.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4042 - acc: 0.8204 - val_loss: 0.3161 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.91789\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4027 - acc: 0.8218 - val_loss: 0.3305 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.91789 to 0.92243, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-102-0.9224.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4097 - acc: 0.8170 - val_loss: 0.3274 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.92243\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4032 - acc: 0.8197 - val_loss: 0.3225 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.92243\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3994 - acc: 0.8243 - val_loss: 0.3173 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.92243\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3968 - acc: 0.8241 - val_loss: 0.3180 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.92243 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-106-0.9235.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3969 - acc: 0.8234 - val_loss: 0.3020 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.92348 to 0.92697, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-107-0.9270.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3987 - acc: 0.8230 - val_loss: 0.3203 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.92697\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3954 - acc: 0.8252 - val_loss: 0.3025 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.92697 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-109-0.9301.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3846 - acc: 0.8285 - val_loss: 0.3016 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.93012 to 0.93117, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-110-0.9312.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3829 - acc: 0.8282 - val_loss: 0.2972 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.93117\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3887 - acc: 0.8248 - val_loss: 0.2940 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.93117 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-112-0.9322.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3868 - acc: 0.8284 - val_loss: 0.2922 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.93222 to 0.93291, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-113-0.9329.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3820 - acc: 0.8331 - val_loss: 0.2925 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.93291\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3799 - acc: 0.8315 - val_loss: 0.2967 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.93291 to 0.93466, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-115-0.9347.hdf5\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3809 - acc: 0.8316 - val_loss: 0.2919 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93466\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3781 - acc: 0.8324 - val_loss: 0.2976 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.93466 to 0.93641, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-117-0.9364.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3820 - acc: 0.8350 - val_loss: 0.2902 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.93641 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-118-0.9371.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3759 - acc: 0.8358 - val_loss: 0.2925 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93711\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3766 - acc: 0.8350 - val_loss: 0.2953 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93711\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3733 - acc: 0.8346 - val_loss: 0.2864 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.93711 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-121-0.9413.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3735 - acc: 0.8359 - val_loss: 0.2861 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.94130 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-122-0.9416.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3739 - acc: 0.8358 - val_loss: 0.2834 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.94165\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3711 - acc: 0.8375 - val_loss: 0.2865 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.94165 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-124-0.9416.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3704 - acc: 0.8397 - val_loss: 0.2811 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00125: val_acc improved from 0.94165 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-125-0.9420.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3632 - acc: 0.8414 - val_loss: 0.2761 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.94200 to 0.94340, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-126-0.9434.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3645 - acc: 0.8421 - val_loss: 0.2805 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.94340 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-127-0.9458.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3672 - acc: 0.8397 - val_loss: 0.2727 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.94584 to 0.94829, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-128-0.9483.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3677 - acc: 0.8344 - val_loss: 0.2811 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.94829\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3608 - acc: 0.8448 - val_loss: 0.2804 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.94829\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3568 - acc: 0.8429 - val_loss: 0.2734 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.94829\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3574 - acc: 0.8446 - val_loss: 0.2754 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.94829\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3578 - acc: 0.8441 - val_loss: 0.2763 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94829\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3563 - acc: 0.8417 - val_loss: 0.2805 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.94829\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3615 - acc: 0.8424 - val_loss: 0.2754 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.94829\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3572 - acc: 0.8443 - val_loss: 0.2734 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.94829\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3548 - acc: 0.8468 - val_loss: 0.2876 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.94829\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3568 - acc: 0.8465 - val_loss: 0.2733 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.94829 to 0.94864, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-138-0.9486.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3497 - acc: 0.8480 - val_loss: 0.2636 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.94864 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-139-0.9490.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3500 - acc: 0.8462 - val_loss: 0.2670 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.94899\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3542 - acc: 0.8505 - val_loss: 0.2620 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.94899 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-141-0.9490.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3478 - acc: 0.8482 - val_loss: 0.2598 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.94899 to 0.94969, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-142-0.9497.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3449 - acc: 0.8511 - val_loss: 0.2603 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.94969 to 0.95178, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-143-0.9518.hdf5\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3493 - acc: 0.8487 - val_loss: 0.2510 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95178\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3463 - acc: 0.8491 - val_loss: 0.2558 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95178\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3427 - acc: 0.8513 - val_loss: 0.2599 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95178\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3380 - acc: 0.8539 - val_loss: 0.2555 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.95178 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-147-0.9532.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3416 - acc: 0.8490 - val_loss: 0.2560 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95318\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3438 - acc: 0.8493 - val_loss: 0.2566 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.95318\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3399 - acc: 0.8530 - val_loss: 0.2567 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95318\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3412 - acc: 0.8516 - val_loss: 0.2517 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95318\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3463 - acc: 0.8502 - val_loss: 0.2532 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.95318 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-152-0.9539.hdf5\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3391 - acc: 0.8555 - val_loss: 0.2527 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95388\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3396 - acc: 0.8546 - val_loss: 0.2501 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95388\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3356 - acc: 0.8563 - val_loss: 0.2562 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95388\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3301 - acc: 0.8606 - val_loss: 0.2366 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.95388\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3344 - acc: 0.8553 - val_loss: 0.2503 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.95388 to 0.95528, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-157-0.9553.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3295 - acc: 0.8594 - val_loss: 0.2489 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.95528 to 0.95702, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-158-0.9570.hdf5\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3387 - acc: 0.8552 - val_loss: 0.2627 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95702\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3400 - acc: 0.8510 - val_loss: 0.2530 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.95702\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3351 - acc: 0.8557 - val_loss: 0.2552 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95702\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3265 - acc: 0.8576 - val_loss: 0.2422 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.95702\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3285 - acc: 0.8579 - val_loss: 0.2318 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95702\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3337 - acc: 0.8557 - val_loss: 0.2522 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.95702\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3386 - acc: 0.8560 - val_loss: 0.2415 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.95702 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-165-0.9595.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3308 - acc: 0.8582 - val_loss: 0.2477 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.95947\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3243 - acc: 0.8612 - val_loss: 0.2321 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95947\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3288 - acc: 0.8537 - val_loss: 0.2381 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95947\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3274 - acc: 0.8597 - val_loss: 0.2427 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95947\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3276 - acc: 0.8580 - val_loss: 0.2323 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95947\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3272 - acc: 0.8592 - val_loss: 0.2384 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95947\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3300 - acc: 0.8555 - val_loss: 0.2310 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.95947 to 0.96226, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-172-0.9623.hdf5\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3205 - acc: 0.8628 - val_loss: 0.2297 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.96226\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3274 - acc: 0.8592 - val_loss: 0.2359 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.96226 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-174-0.9626.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3269 - acc: 0.8600 - val_loss: 0.2358 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.96261\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3179 - acc: 0.8631 - val_loss: 0.2327 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.96261\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3180 - acc: 0.8628 - val_loss: 0.2253 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.96261\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3219 - acc: 0.8621 - val_loss: 0.2337 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96261\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3257 - acc: 0.8590 - val_loss: 0.2311 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96261\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3204 - acc: 0.8659 - val_loss: 0.2352 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96261\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3194 - acc: 0.8628 - val_loss: 0.2293 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96261\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3221 - acc: 0.8624 - val_loss: 0.2289 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96261\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3149 - acc: 0.8668 - val_loss: 0.2271 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96261\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3218 - acc: 0.8626 - val_loss: 0.2239 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96261\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3167 - acc: 0.8655 - val_loss: 0.2215 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.96261\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3103 - acc: 0.8659 - val_loss: 0.2152 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96261\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3121 - acc: 0.8684 - val_loss: 0.2200 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00187: val_acc improved from 0.96261 to 0.96401, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-187-0.9640.hdf5\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3132 - acc: 0.8662 - val_loss: 0.2221 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.96401\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3149 - acc: 0.8658 - val_loss: 0.2083 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.96401 to 0.96471, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-189-0.9647.hdf5\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3175 - acc: 0.8645 - val_loss: 0.2073 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.96471\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3141 - acc: 0.8672 - val_loss: 0.2150 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96471\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3107 - acc: 0.8664 - val_loss: 0.2049 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.96471\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3074 - acc: 0.8671 - val_loss: 0.1978 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.96471\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3127 - acc: 0.8679 - val_loss: 0.2198 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.96471 to 0.96506, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-194-0.9651.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3052 - acc: 0.8713 - val_loss: 0.2073 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.96506\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3078 - acc: 0.8690 - val_loss: 0.2047 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.96506 to 0.96681, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-196-0.9668.hdf5\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3110 - acc: 0.8665 - val_loss: 0.2097 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.96681 to 0.96716, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/3/weights-improvement-197-0.9672.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3131 - acc: 0.8685 - val_loss: 0.2087 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.96716\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3112 - acc: 0.8681 - val_loss: 0.2090 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.96716\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3092 - acc: 0.8664 - val_loss: 0.2003 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.96716\n",
      "It has been  0:18:39.460038\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1000, 26)     0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1000, 10)     270         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1000, 10)     790         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1000, 10)     1310        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1000, 10)     2350        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1000, 10)     3910        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5000, 10)     0           conv1d_26[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "                                                                 conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 500, 10)      0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 500, 314)     3454        max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 500, 314)     0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 500, 77)      24255       dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 500, 77)      0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 500, 8)       624         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 500, 8)       0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 4000)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            8002        flatten_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6815 - acc: 0.6128 - val_loss: 0.6916 - val_acc: 0.7561\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75611, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-001-0.7561.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6859 - acc: 0.5877 - val_loss: 0.6844 - val_acc: 0.6852\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.75611\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6650 - acc: 0.6359 - val_loss: 0.6744 - val_acc: 0.6810\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75611\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6517 - acc: 0.6716 - val_loss: 0.6562 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75611\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6388 - acc: 0.6859 - val_loss: 0.6380 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75611\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6312 - acc: 0.6903 - val_loss: 0.6270 - val_acc: 0.7428\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75611\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6282 - acc: 0.6920 - val_loss: 0.6194 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75611\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6229 - acc: 0.6968 - val_loss: 0.6121 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75611\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6211 - acc: 0.6941 - val_loss: 0.6088 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75611\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6193 - acc: 0.6969 - val_loss: 0.6054 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75611\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6174 - acc: 0.6965 - val_loss: 0.6034 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75611\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6161 - acc: 0.7002 - val_loss: 0.6013 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75611\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6158 - acc: 0.6977 - val_loss: 0.5971 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75611\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6131 - acc: 0.6946 - val_loss: 0.5960 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75611\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6134 - acc: 0.6975 - val_loss: 0.5921 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75611\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6115 - acc: 0.6983 - val_loss: 0.5914 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75611\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6115 - acc: 0.6987 - val_loss: 0.5912 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75611\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6079 - acc: 0.7021 - val_loss: 0.5883 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75611\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6060 - acc: 0.7039 - val_loss: 0.5832 - val_acc: 0.7432\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75611\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6060 - acc: 0.7001 - val_loss: 0.5811 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75611\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6034 - acc: 0.7066 - val_loss: 0.5808 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75611\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6020 - acc: 0.7043 - val_loss: 0.5785 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75611\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5986 - acc: 0.7069 - val_loss: 0.5754 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75611\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5971 - acc: 0.7091 - val_loss: 0.5754 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75611\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5949 - acc: 0.7064 - val_loss: 0.5724 - val_acc: 0.7453\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75611\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5909 - acc: 0.7109 - val_loss: 0.5681 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75611\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5885 - acc: 0.7155 - val_loss: 0.5658 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.75611\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5851 - acc: 0.7153 - val_loss: 0.5595 - val_acc: 0.7607\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.75611 to 0.76066, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-028-0.7607.hdf5\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5806 - acc: 0.7172 - val_loss: 0.5561 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.76066 to 0.76136, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-029-0.7614.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5768 - acc: 0.7193 - val_loss: 0.5517 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.76136 to 0.76415, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-030-0.7642.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5748 - acc: 0.7225 - val_loss: 0.5443 - val_acc: 0.7718\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.76415 to 0.77184, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-031-0.7718.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5703 - acc: 0.7252 - val_loss: 0.5437 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.77184 to 0.77673, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-032-0.7767.hdf5\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5666 - acc: 0.7278 - val_loss: 0.5405 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.77673 to 0.78616, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-033-0.7862.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5592 - acc: 0.7328 - val_loss: 0.5292 - val_acc: 0.7949\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.78616 to 0.79490, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-034-0.7949.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5584 - acc: 0.7323 - val_loss: 0.5191 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.79490 to 0.79700, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-035-0.7970.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5546 - acc: 0.7342 - val_loss: 0.5156 - val_acc: 0.8001\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.79700 to 0.80014, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-036-0.8001.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5485 - acc: 0.7379 - val_loss: 0.5122 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.80014 to 0.80678, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-037-0.8068.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5476 - acc: 0.7372 - val_loss: 0.5026 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.80678 to 0.81097, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-038-0.8110.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5422 - acc: 0.7441 - val_loss: 0.4923 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.81097 to 0.82006, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-039-0.8201.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5403 - acc: 0.7416 - val_loss: 0.5002 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.82006 to 0.82635, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-040-0.8263.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5382 - acc: 0.7435 - val_loss: 0.4880 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82635 to 0.82879, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-041-0.8288.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5365 - acc: 0.7458 - val_loss: 0.4834 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.82879 to 0.83823, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-042-0.8382.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5322 - acc: 0.7459 - val_loss: 0.4849 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83823 to 0.84312, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-043-0.8431.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5281 - acc: 0.7491 - val_loss: 0.4768 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.84312 to 0.84416, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-044-0.8442.hdf5\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5205 - acc: 0.7547 - val_loss: 0.4702 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.84416 to 0.84731, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-045-0.8473.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5256 - acc: 0.7523 - val_loss: 0.4626 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.84731 to 0.85045, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-046-0.8505.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5206 - acc: 0.7558 - val_loss: 0.4613 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.85045 to 0.85500, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-047-0.8550.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5140 - acc: 0.7576 - val_loss: 0.4578 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.85500 to 0.85744, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-048-0.8574.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5140 - acc: 0.7583 - val_loss: 0.4511 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.85744 to 0.85954, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-049-0.8595.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5105 - acc: 0.7617 - val_loss: 0.4531 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.85954 to 0.86338, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-050-0.8634.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5110 - acc: 0.7562 - val_loss: 0.4528 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.86338 to 0.86618, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-051-0.8662.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5074 - acc: 0.7608 - val_loss: 0.4451 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.86618 to 0.86967, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-052-0.8697.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4982 - acc: 0.7646 - val_loss: 0.4432 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.86967 to 0.87282, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-053-0.8728.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5011 - acc: 0.7665 - val_loss: 0.4370 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.87282\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4977 - acc: 0.7696 - val_loss: 0.4418 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.87282 to 0.87736, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-055-0.8774.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4968 - acc: 0.7672 - val_loss: 0.4327 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.87736 to 0.88015, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-056-0.8802.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4903 - acc: 0.7717 - val_loss: 0.4285 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.88015 to 0.88050, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-057-0.8805.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4883 - acc: 0.7774 - val_loss: 0.4195 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.88050 to 0.88190, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-058-0.8819.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4805 - acc: 0.7798 - val_loss: 0.4066 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.88190 to 0.88330, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-059-0.8833.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4832 - acc: 0.7775 - val_loss: 0.4026 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.88330 to 0.88679, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-060-0.8868.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4709 - acc: 0.7822 - val_loss: 0.3993 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.88679 to 0.89064, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-061-0.8906.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4750 - acc: 0.7814 - val_loss: 0.3954 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.89064 to 0.89133, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-062-0.8913.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4732 - acc: 0.7840 - val_loss: 0.4010 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.89133 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-063-0.8969.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4745 - acc: 0.7841 - val_loss: 0.3996 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.89693 to 0.89727, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-064-0.8973.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4662 - acc: 0.7865 - val_loss: 0.3899 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.89727 to 0.89762, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-065-0.8976.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4628 - acc: 0.7890 - val_loss: 0.3859 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.89762 to 0.90042, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-066-0.9004.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4647 - acc: 0.7856 - val_loss: 0.3717 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.90042 to 0.90042, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-067-0.9004.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4624 - acc: 0.7863 - val_loss: 0.3831 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.90042 to 0.90287, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-068-0.9029.hdf5\n",
      "Epoch 69/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4557 - acc: 0.7929 - val_loss: 0.3725 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.90287\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4527 - acc: 0.7936 - val_loss: 0.3780 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.90287 to 0.90496, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-070-0.9050.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4463 - acc: 0.8035 - val_loss: 0.3548 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.90496 to 0.90566, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-071-0.9057.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4453 - acc: 0.7971 - val_loss: 0.3583 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.90566 to 0.91020, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-072-0.9102.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4431 - acc: 0.7972 - val_loss: 0.3515 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.91020 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-073-0.9116.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4432 - acc: 0.7982 - val_loss: 0.3597 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.91160\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4423 - acc: 0.7988 - val_loss: 0.3439 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.91160 to 0.91265, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-075-0.9126.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4372 - acc: 0.8021 - val_loss: 0.3350 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.91265\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4364 - acc: 0.8000 - val_loss: 0.3345 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.91265 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-077-0.9151.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4312 - acc: 0.8039 - val_loss: 0.3289 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.91509 to 0.91754, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-078-0.9175.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4298 - acc: 0.8058 - val_loss: 0.3293 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.91754\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4326 - acc: 0.8048 - val_loss: 0.3264 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.91754 to 0.91789, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-080-0.9179.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4268 - acc: 0.8106 - val_loss: 0.3228 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.91789 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-081-0.9200.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4241 - acc: 0.8083 - val_loss: 0.3157 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.91999 to 0.92068, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-082-0.9207.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4237 - acc: 0.8091 - val_loss: 0.3180 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.92068 to 0.92103, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-083-0.9210.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4263 - acc: 0.8072 - val_loss: 0.3248 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.92103\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4266 - acc: 0.8099 - val_loss: 0.3117 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.92103 to 0.92523, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-085-0.9252.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4215 - acc: 0.8125 - val_loss: 0.3095 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.92523\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4115 - acc: 0.8203 - val_loss: 0.2997 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.92523 to 0.92697, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-087-0.9270.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4080 - acc: 0.8159 - val_loss: 0.2889 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.92697 to 0.92732, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-088-0.9273.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4138 - acc: 0.8131 - val_loss: 0.2891 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.92732 to 0.92942, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-089-0.9294.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4078 - acc: 0.8117 - val_loss: 0.2854 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.92942 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-090-0.9301.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4067 - acc: 0.8203 - val_loss: 0.2889 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.93012 to 0.93047, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-091-0.9305.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4075 - acc: 0.8184 - val_loss: 0.2857 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.93047 to 0.93117, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-092-0.9312.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3995 - acc: 0.8246 - val_loss: 0.2911 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.93117 to 0.93291, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-093-0.9329.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4022 - acc: 0.8193 - val_loss: 0.2709 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93291\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4009 - acc: 0.8195 - val_loss: 0.2720 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93291\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4027 - acc: 0.8195 - val_loss: 0.2784 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.93291 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-096-0.9357.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3962 - acc: 0.8248 - val_loss: 0.2750 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93571\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3981 - acc: 0.8259 - val_loss: 0.2768 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93571\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3909 - acc: 0.8301 - val_loss: 0.2750 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.93571 to 0.93990, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-099-0.9399.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3901 - acc: 0.8243 - val_loss: 0.2679 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93990\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3845 - acc: 0.8305 - val_loss: 0.2616 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.93990\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3825 - acc: 0.8297 - val_loss: 0.2604 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.93990\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3937 - acc: 0.8272 - val_loss: 0.2531 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.93990 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-103-0.9416.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3799 - acc: 0.8315 - val_loss: 0.2448 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.94165 to 0.94235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-104-0.9423.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3893 - acc: 0.8270 - val_loss: 0.2531 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.94235\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3857 - acc: 0.8310 - val_loss: 0.2537 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.94235 to 0.94270, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-106-0.9427.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3850 - acc: 0.8310 - val_loss: 0.2567 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.94270 to 0.94270, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-107-0.9427.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3795 - acc: 0.8361 - val_loss: 0.2508 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.94270 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-108-0.9430.hdf5\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3784 - acc: 0.8339 - val_loss: 0.2418 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.94305 to 0.94375, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-109-0.9437.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3710 - acc: 0.8356 - val_loss: 0.2494 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.94375\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3772 - acc: 0.8332 - val_loss: 0.2439 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.94375\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3816 - acc: 0.8325 - val_loss: 0.2495 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.94375\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3740 - acc: 0.8342 - val_loss: 0.2454 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.94375\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3717 - acc: 0.8361 - val_loss: 0.2313 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.94375\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3678 - acc: 0.8408 - val_loss: 0.2291 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.94375\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3735 - acc: 0.8368 - val_loss: 0.2345 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.94375 to 0.94654, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-116-0.9465.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3711 - acc: 0.8361 - val_loss: 0.2276 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.94654\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3652 - acc: 0.8434 - val_loss: 0.2291 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.94654 to 0.94759, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-118-0.9476.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3729 - acc: 0.8353 - val_loss: 0.2306 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.94759 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-119-0.9490.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3651 - acc: 0.8405 - val_loss: 0.2220 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.94899\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3614 - acc: 0.8443 - val_loss: 0.2249 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.94899\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3630 - acc: 0.8398 - val_loss: 0.2239 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.94899 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-122-0.9507.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3651 - acc: 0.8406 - val_loss: 0.2208 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.95073\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3671 - acc: 0.8400 - val_loss: 0.2246 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.95073\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3570 - acc: 0.8465 - val_loss: 0.2151 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.95073 to 0.95143, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-125-0.9514.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3599 - acc: 0.8447 - val_loss: 0.2125 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.95143 to 0.95248, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-126-0.9525.hdf5\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3595 - acc: 0.8463 - val_loss: 0.2178 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95248\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3603 - acc: 0.8453 - val_loss: 0.2073 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.95248\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3557 - acc: 0.8454 - val_loss: 0.2073 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.95248\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3595 - acc: 0.8415 - val_loss: 0.2137 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95248\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3557 - acc: 0.8475 - val_loss: 0.2118 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.95248\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3431 - acc: 0.8553 - val_loss: 0.2003 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95248\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3474 - acc: 0.8504 - val_loss: 0.1952 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95248\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3593 - acc: 0.8445 - val_loss: 0.2071 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95248\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3501 - acc: 0.8498 - val_loss: 0.2057 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.95248 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-135-0.9532.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3472 - acc: 0.8500 - val_loss: 0.1999 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.95318\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3533 - acc: 0.8455 - val_loss: 0.2038 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.95318\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3463 - acc: 0.8513 - val_loss: 0.1968 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.95318 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-138-0.9539.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3497 - acc: 0.8490 - val_loss: 0.1963 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95388\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3486 - acc: 0.8530 - val_loss: 0.2002 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.95388 to 0.95493, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-140-0.9549.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3438 - acc: 0.8507 - val_loss: 0.1902 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.95493 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-141-0.9560.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3471 - acc: 0.8490 - val_loss: 0.1910 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.95597 to 0.95632, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-142-0.9563.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3370 - acc: 0.8537 - val_loss: 0.1862 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95632\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3407 - acc: 0.8541 - val_loss: 0.1871 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.95632 to 0.95772, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-144-0.9577.hdf5\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3484 - acc: 0.8490 - val_loss: 0.1908 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95772\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3464 - acc: 0.8482 - val_loss: 0.1918 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95772\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3484 - acc: 0.8512 - val_loss: 0.1901 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.95772 to 0.95807, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-147-0.9581.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3408 - acc: 0.8527 - val_loss: 0.1902 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.95807 to 0.95807, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-148-0.9581.hdf5\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3314 - acc: 0.8592 - val_loss: 0.1796 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.95807 to 0.95912, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-149-0.9591.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3415 - acc: 0.8537 - val_loss: 0.1914 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.95912 to 0.96052, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-150-0.9605.hdf5\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3317 - acc: 0.8611 - val_loss: 0.1822 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.96052\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3324 - acc: 0.8571 - val_loss: 0.1827 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.96052\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3366 - acc: 0.8527 - val_loss: 0.1779 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.96052\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3371 - acc: 0.8578 - val_loss: 0.1781 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.96052\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3284 - acc: 0.8568 - val_loss: 0.1672 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.96052\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3269 - acc: 0.8611 - val_loss: 0.1735 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.96052 to 0.96157, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-156-0.9616.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3250 - acc: 0.8591 - val_loss: 0.1673 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.96157\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3296 - acc: 0.8557 - val_loss: 0.1694 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.96157\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3239 - acc: 0.8590 - val_loss: 0.1735 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.96157 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-159-0.9619.hdf5\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3269 - acc: 0.8587 - val_loss: 0.1710 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.96191 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-160-0.9619.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3199 - acc: 0.8623 - val_loss: 0.1627 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.96191 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-161-0.9626.hdf5\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3196 - acc: 0.8625 - val_loss: 0.1681 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.96261 to 0.96401, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-162-0.9640.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3236 - acc: 0.8597 - val_loss: 0.1683 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.96401 to 0.96436, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-163-0.9644.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3208 - acc: 0.8630 - val_loss: 0.1736 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.96436 to 0.96506, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-164-0.9651.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3195 - acc: 0.8623 - val_loss: 0.1709 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.96506 to 0.96576, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-165-0.9658.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3224 - acc: 0.8614 - val_loss: 0.1671 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.96576\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3330 - acc: 0.8586 - val_loss: 0.1788 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.96576\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3247 - acc: 0.8634 - val_loss: 0.1699 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.96576\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3251 - acc: 0.8604 - val_loss: 0.1658 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.96576\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3225 - acc: 0.8623 - val_loss: 0.1641 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.96576\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3182 - acc: 0.8656 - val_loss: 0.1605 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.96576\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3199 - acc: 0.8614 - val_loss: 0.1659 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.96576 to 0.96611, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-172-0.9661.hdf5\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3190 - acc: 0.8620 - val_loss: 0.1605 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00173: val_acc improved from 0.96611 to 0.96785, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-173-0.9679.hdf5\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3131 - acc: 0.8669 - val_loss: 0.1573 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.96785\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3179 - acc: 0.8612 - val_loss: 0.1612 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.96785\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3194 - acc: 0.8647 - val_loss: 0.1639 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.96785\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3160 - acc: 0.8640 - val_loss: 0.1604 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.96785 to 0.96820, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-177-0.9682.hdf5\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3158 - acc: 0.8671 - val_loss: 0.1523 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96820\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3116 - acc: 0.8657 - val_loss: 0.1463 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96820\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3120 - acc: 0.8657 - val_loss: 0.1487 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96820\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3127 - acc: 0.8656 - val_loss: 0.1492 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96820\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3086 - acc: 0.8682 - val_loss: 0.1441 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96820\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3127 - acc: 0.8657 - val_loss: 0.1432 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96820\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3078 - acc: 0.8679 - val_loss: 0.1425 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96820\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3120 - acc: 0.8665 - val_loss: 0.1492 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.96820\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3120 - acc: 0.8668 - val_loss: 0.1440 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96820\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3130 - acc: 0.8655 - val_loss: 0.1435 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.96820\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3169 - acc: 0.8640 - val_loss: 0.1464 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.96820\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3067 - acc: 0.8721 - val_loss: 0.1422 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.96820\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3059 - acc: 0.8711 - val_loss: 0.1390 - val_acc: 0.9675\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.96820\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3071 - acc: 0.8707 - val_loss: 0.1420 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96820\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3054 - acc: 0.8705 - val_loss: 0.1353 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.96820 to 0.96890, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-192-0.9689.hdf5\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3064 - acc: 0.8710 - val_loss: 0.1411 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00193: val_acc improved from 0.96890 to 0.96960, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-193-0.9696.hdf5\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3059 - acc: 0.8713 - val_loss: 0.1354 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.96960\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3040 - acc: 0.8679 - val_loss: 0.1353 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.96960\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3012 - acc: 0.8724 - val_loss: 0.1352 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.96960\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3005 - acc: 0.8726 - val_loss: 0.1281 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.96960\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3005 - acc: 0.8708 - val_loss: 0.1348 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.96960\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3002 - acc: 0.8752 - val_loss: 0.1348 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.96960 to 0.97065, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-199-0.9706.hdf5\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3017 - acc: 0.8711 - val_loss: 0.1351 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.97065 to 0.97100, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/4/weights-improvement-200-0.9710.hdf5\n",
      "It has been  0:18:32.959198\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1000, 26)     0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1000, 10)     270         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1000, 10)     790         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1000, 10)     1310        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 1000, 10)     2350        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1000, 10)     3910        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5000, 10)     0           conv1d_31[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "                                                                 conv1d_34[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 500, 10)      0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 500, 314)     3454        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 500, 314)     0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 500, 77)      24255       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 500, 77)      0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 500, 8)       624         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 500, 8)       0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 4000)         0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            8002        flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6856 - acc: 0.6115 - val_loss: 0.6914 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69637, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-001-0.6964.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6821 - acc: 0.5893 - val_loss: 0.6877 - val_acc: 0.6904\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69637\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6602 - acc: 0.6481 - val_loss: 0.6684 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69637\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6422 - acc: 0.6743 - val_loss: 0.6484 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.69637 to 0.71803, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-004-0.7180.hdf5\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6311 - acc: 0.6896 - val_loss: 0.6357 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71803 to 0.71908, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-005-0.7191.hdf5\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6258 - acc: 0.6915 - val_loss: 0.6296 - val_acc: 0.7173\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71908\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6241 - acc: 0.6935 - val_loss: 0.6264 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71908\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6198 - acc: 0.6973 - val_loss: 0.6205 - val_acc: 0.7177\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71908\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6179 - acc: 0.6999 - val_loss: 0.6157 - val_acc: 0.7219\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71908 to 0.72187, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-009-0.7219.hdf5\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6152 - acc: 0.6989 - val_loss: 0.6125 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72187\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6154 - acc: 0.6960 - val_loss: 0.6098 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.72187\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6136 - acc: 0.7001 - val_loss: 0.6091 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72187\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6126 - acc: 0.7005 - val_loss: 0.6051 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.72187\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6098 - acc: 0.7006 - val_loss: 0.6039 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.72187\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6078 - acc: 0.7043 - val_loss: 0.6004 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.72187\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.6075 - acc: 0.7027 - val_loss: 0.6001 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.72187\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6059 - acc: 0.7044 - val_loss: 0.5959 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.72187\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6028 - acc: 0.7077 - val_loss: 0.5946 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72187\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6030 - acc: 0.7061 - val_loss: 0.5934 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72187\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6006 - acc: 0.7084 - val_loss: 0.5896 - val_acc: 0.7268\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.72187 to 0.72676, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-020-0.7268.hdf5\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5967 - acc: 0.7112 - val_loss: 0.5881 - val_acc: 0.7282\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.72676 to 0.72816, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-021-0.7282.hdf5\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5958 - acc: 0.7108 - val_loss: 0.5879 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.72816\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5963 - acc: 0.7112 - val_loss: 0.5859 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.72816\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5927 - acc: 0.7142 - val_loss: 0.5840 - val_acc: 0.7261\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.72816\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5925 - acc: 0.7120 - val_loss: 0.5830 - val_acc: 0.7285\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.72816 to 0.72851, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-025-0.7285.hdf5\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5912 - acc: 0.7145 - val_loss: 0.5816 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.72851 to 0.73061, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-026-0.7306.hdf5\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5872 - acc: 0.7133 - val_loss: 0.5761 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.73061 to 0.73934, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-027-0.7393.hdf5\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5841 - acc: 0.7179 - val_loss: 0.5778 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.73934\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5843 - acc: 0.7122 - val_loss: 0.5739 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.73934 to 0.74563, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-029-0.7456.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5807 - acc: 0.7183 - val_loss: 0.5716 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.74563 to 0.74668, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-030-0.7467.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5769 - acc: 0.7219 - val_loss: 0.5675 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.74668 to 0.75052, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-031-0.7505.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5729 - acc: 0.7269 - val_loss: 0.5669 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.75052\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5720 - acc: 0.7238 - val_loss: 0.5606 - val_acc: 0.7551\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.75052 to 0.75507, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-033-0.7551.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5699 - acc: 0.7266 - val_loss: 0.5599 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.75507 to 0.75542, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-034-0.7554.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5668 - acc: 0.7278 - val_loss: 0.5573 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.75542 to 0.75926, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-035-0.7593.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5646 - acc: 0.7298 - val_loss: 0.5522 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.75926 to 0.76136, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-036-0.7614.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5607 - acc: 0.7361 - val_loss: 0.5475 - val_acc: 0.7690\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.76136 to 0.76904, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-037-0.7690.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5585 - acc: 0.7344 - val_loss: 0.5419 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.76904 to 0.77778, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-038-0.7778.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5570 - acc: 0.7348 - val_loss: 0.5408 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.77778 to 0.77883, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-039-0.7788.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5500 - acc: 0.7410 - val_loss: 0.5245 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.77883 to 0.79280, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-040-0.7928.hdf5\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5465 - acc: 0.7444 - val_loss: 0.5208 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.79280 to 0.79560, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-041-0.7956.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5460 - acc: 0.7403 - val_loss: 0.5155 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.79560 to 0.80468, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-042-0.8047.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5449 - acc: 0.7388 - val_loss: 0.5136 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.80468 to 0.80783, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-043-0.8078.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5413 - acc: 0.7401 - val_loss: 0.5098 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.80783 to 0.81272, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-044-0.8127.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5375 - acc: 0.7461 - val_loss: 0.5017 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.81272 to 0.82006, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-045-0.8201.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5370 - acc: 0.7488 - val_loss: 0.5019 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.82006 to 0.82460, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-046-0.8246.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5350 - acc: 0.7482 - val_loss: 0.4973 - val_acc: 0.8291\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.82460 to 0.82914, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-047-0.8291.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5297 - acc: 0.7514 - val_loss: 0.4905 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82914 to 0.83019, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-048-0.8302.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5289 - acc: 0.7520 - val_loss: 0.4822 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.83019 to 0.83543, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-049-0.8354.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5245 - acc: 0.7536 - val_loss: 0.4800 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83543 to 0.83962, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-050-0.8396.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5200 - acc: 0.7541 - val_loss: 0.4779 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.83962 to 0.84242, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-051-0.8424.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5186 - acc: 0.7598 - val_loss: 0.4749 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.84242 to 0.84766, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-052-0.8477.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5173 - acc: 0.7586 - val_loss: 0.4708 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84766 to 0.85080, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-053-0.8508.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5136 - acc: 0.7621 - val_loss: 0.4625 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.85080 to 0.85325, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-054-0.8532.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5117 - acc: 0.7584 - val_loss: 0.4578 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85325 to 0.85570, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-055-0.8557.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.5082 - acc: 0.7617 - val_loss: 0.4493 - val_acc: 0.8592\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.85570 to 0.85919, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-056-0.8592.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5067 - acc: 0.7649 - val_loss: 0.4434 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.85919 to 0.86094, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-057-0.8609.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5009 - acc: 0.7679 - val_loss: 0.4287 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.86094 to 0.86548, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-058-0.8655.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4994 - acc: 0.7673 - val_loss: 0.4321 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.86548 to 0.86723, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-059-0.8672.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4999 - acc: 0.7661 - val_loss: 0.4339 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.86723 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-060-0.8693.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4946 - acc: 0.7706 - val_loss: 0.4343 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.86932 to 0.87142, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-061-0.8714.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4961 - acc: 0.7641 - val_loss: 0.4246 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.87142 to 0.87386, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-062-0.8739.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4910 - acc: 0.7699 - val_loss: 0.4361 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.87386\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4893 - acc: 0.7755 - val_loss: 0.4298 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.87386 to 0.87491, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-064-0.8749.hdf5\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4493 - acc: 0.7973 - val_loss: 0.3753 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.89553 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-083-0.8969.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4540 - acc: 0.7920 - val_loss: 0.3706 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.89693 to 0.89902, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-084-0.8990.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4512 - acc: 0.7923 - val_loss: 0.3652 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.89902 to 0.90042, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-085-0.9004.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4441 - acc: 0.7981 - val_loss: 0.3584 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.90042\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4427 - acc: 0.8009 - val_loss: 0.3547 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.90042 to 0.90252, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-087-0.9025.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4449 - acc: 0.7987 - val_loss: 0.3591 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90252 to 0.90287, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-088-0.9029.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4394 - acc: 0.8012 - val_loss: 0.3540 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.90287 to 0.90496, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-089-0.9050.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4366 - acc: 0.8041 - val_loss: 0.3525 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.90496\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4400 - acc: 0.8011 - val_loss: 0.3568 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.90496 to 0.90601, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-091-0.9060.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4336 - acc: 0.8037 - val_loss: 0.3425 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.90601 to 0.90706, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-092-0.9071.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4329 - acc: 0.8047 - val_loss: 0.3467 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.90706 to 0.90741, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-093-0.9074.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4339 - acc: 0.8032 - val_loss: 0.3435 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.90741 to 0.91055, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-094-0.9106.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4298 - acc: 0.8062 - val_loss: 0.3383 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.91055\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4307 - acc: 0.8096 - val_loss: 0.3315 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.91055 to 0.91090, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-096-0.9109.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4247 - acc: 0.8085 - val_loss: 0.3286 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.91090\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4203 - acc: 0.8106 - val_loss: 0.3227 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.91090 to 0.91265, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-098-0.9126.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4159 - acc: 0.8134 - val_loss: 0.3187 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.91265\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4179 - acc: 0.8129 - val_loss: 0.3127 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.91265\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4195 - acc: 0.8104 - val_loss: 0.3253 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.91265 to 0.91474, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-101-0.9147.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4175 - acc: 0.8103 - val_loss: 0.3111 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.91474\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4167 - acc: 0.8150 - val_loss: 0.3158 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.91474\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4128 - acc: 0.8130 - val_loss: 0.3132 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.91474 to 0.91719, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-104-0.9172.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4119 - acc: 0.8132 - val_loss: 0.3186 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.91719 to 0.91894, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-105-0.9189.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4118 - acc: 0.8163 - val_loss: 0.3169 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.91894\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4105 - acc: 0.8136 - val_loss: 0.3090 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.91894\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4111 - acc: 0.8214 - val_loss: 0.3132 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.91894 to 0.91929, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-108-0.9193.hdf5\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4090 - acc: 0.8172 - val_loss: 0.3069 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.91929 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-109-0.9200.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4062 - acc: 0.8183 - val_loss: 0.3030 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.91999\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4018 - acc: 0.8246 - val_loss: 0.2980 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.91999\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4027 - acc: 0.8187 - val_loss: 0.3039 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.91999\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4007 - acc: 0.8211 - val_loss: 0.3043 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.91999\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.4061 - acc: 0.8194 - val_loss: 0.3044 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.91999 to 0.92068, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/5/weights-improvement-114-0.9207.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3996 - acc: 0.8215 - val_loss: 0.2932 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.92068\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 5s 22ms/step - loss: 0.3928 - acc: 0.8260 - val_loss: 0.2955 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.92068\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3918 - acc: 0.8263 - val_loss: 0.2916 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.92068\n",
      "Epoch 118/200\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.3664 - acc: 0.8379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6142 - acc: 0.6988 - val_loss: 0.6132 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.70370 to 0.70790, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-011-0.7079.hdf5\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6135 - acc: 0.6974 - val_loss: 0.6111 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.70790\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6111 - acc: 0.7013 - val_loss: 0.6068 - val_acc: 0.7103\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.70790 to 0.71034, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-013-0.7103.hdf5\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6089 - acc: 0.7008 - val_loss: 0.6030 - val_acc: 0.7156\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.71034 to 0.71558, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-014-0.7156.hdf5\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6066 - acc: 0.7024 - val_loss: 0.5993 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.71558 to 0.71803, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-015-0.7180.hdf5\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6058 - acc: 0.7028 - val_loss: 0.5950 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.71803 to 0.72117, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-016-0.7212.hdf5\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6036 - acc: 0.7053 - val_loss: 0.5926 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.72117 to 0.72397, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-017-0.7240.hdf5\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6022 - acc: 0.7083 - val_loss: 0.5913 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72397\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5979 - acc: 0.7093 - val_loss: 0.5852 - val_acc: 0.7299\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.72397 to 0.72991, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-019-0.7299.hdf5\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5956 - acc: 0.7117 - val_loss: 0.5810 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.72991 to 0.73235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-020-0.7324.hdf5\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5926 - acc: 0.7117 - val_loss: 0.5740 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.73235 to 0.73725, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-021-0.7372.hdf5\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5883 - acc: 0.7136 - val_loss: 0.5699 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.73725 to 0.74423, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-022-0.7442.hdf5\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5857 - acc: 0.7171 - val_loss: 0.5619 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.74423 to 0.74913, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-023-0.7491.hdf5\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5833 - acc: 0.7190 - val_loss: 0.5549 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.74913 to 0.75262, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-024-0.7526.hdf5\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5802 - acc: 0.7168 - val_loss: 0.5463 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.75262 to 0.75996, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-025-0.7600.hdf5\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5757 - acc: 0.7221 - val_loss: 0.5413 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.75996 to 0.76415, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-026-0.7642.hdf5\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5719 - acc: 0.7260 - val_loss: 0.5366 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.76415 to 0.76555, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-027-0.7655.hdf5\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5691 - acc: 0.7253 - val_loss: 0.5317 - val_acc: 0.7708\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.76555 to 0.77079, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-028-0.7708.hdf5\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5652 - acc: 0.7283 - val_loss: 0.5212 - val_acc: 0.7743\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.77079 to 0.77428, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-029-0.7743.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5596 - acc: 0.7310 - val_loss: 0.5142 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.77428 to 0.78022, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-030-0.7802.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5586 - acc: 0.7334 - val_loss: 0.5105 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.78022 to 0.78721, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-031-0.7872.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5556 - acc: 0.7344 - val_loss: 0.5031 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.78721 to 0.79106, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-032-0.7911.hdf5\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5557 - acc: 0.7337 - val_loss: 0.5031 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.79106 to 0.79385, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-033-0.7939.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5524 - acc: 0.7334 - val_loss: 0.4960 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.79385 to 0.79839, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-034-0.7984.hdf5\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5499 - acc: 0.7385 - val_loss: 0.4914 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.79839 to 0.79944, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-035-0.7994.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5468 - acc: 0.7390 - val_loss: 0.4856 - val_acc: 0.8057\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.79944 to 0.80573, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-036-0.8057.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5457 - acc: 0.7403 - val_loss: 0.4834 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.80573 to 0.81202, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-037-0.8120.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5407 - acc: 0.7450 - val_loss: 0.4795 - val_acc: 0.8183\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.81202 to 0.81831, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-038-0.8183.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5412 - acc: 0.7444 - val_loss: 0.4734 - val_acc: 0.8246\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.81831 to 0.82460, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-039-0.8246.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5401 - acc: 0.7452 - val_loss: 0.4674 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.82460 to 0.82704, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-040-0.8270.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5323 - acc: 0.7467 - val_loss: 0.4622 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82704 to 0.83019, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-041-0.8302.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5314 - acc: 0.7465 - val_loss: 0.4571 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.83019 to 0.83368, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-042-0.8337.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5292 - acc: 0.7530 - val_loss: 0.4470 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83368 to 0.83857, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-043-0.8386.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5316 - acc: 0.7485 - val_loss: 0.4471 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.83857 to 0.84067, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-044-0.8407.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.5265 - acc: 0.7516 - val_loss: 0.4364 - val_acc: 0.8417\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.84067 to 0.84172, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-045-0.8417.hdf5\n",
      "Epoch 46/200\n",
      "184/251 [====================>.........] - ETA: 1s - loss: 0.5044 - acc: 0.7687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3807 - acc: 0.8304 - val_loss: 0.2252 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93187\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3755 - acc: 0.8350 - val_loss: 0.2180 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93187\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3761 - acc: 0.8361 - val_loss: 0.2140 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93187\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3768 - acc: 0.8319 - val_loss: 0.2145 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93187\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3802 - acc: 0.8305 - val_loss: 0.2148 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93187\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3755 - acc: 0.8336 - val_loss: 0.2111 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.93187 to 0.93396, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-123-0.9340.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3747 - acc: 0.8355 - val_loss: 0.2130 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.93396 to 0.93501, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-124-0.9350.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3710 - acc: 0.8353 - val_loss: 0.2112 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.93501\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3671 - acc: 0.8373 - val_loss: 0.2074 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.93501 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-126-0.9357.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3697 - acc: 0.8372 - val_loss: 0.2044 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.93571 to 0.93606, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-127-0.9361.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3705 - acc: 0.8369 - val_loss: 0.2102 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.93606 to 0.93885, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-128-0.9389.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3711 - acc: 0.8377 - val_loss: 0.2035 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.93885\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3625 - acc: 0.8395 - val_loss: 0.1993 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.93885 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-130-0.9406.hdf5\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3599 - acc: 0.8419 - val_loss: 0.1947 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.94060\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3649 - acc: 0.8397 - val_loss: 0.1979 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.94060 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-132-0.9416.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3627 - acc: 0.8406 - val_loss: 0.1981 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94165\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3634 - acc: 0.8411 - val_loss: 0.1991 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.94165 to 0.94235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-134-0.9423.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3591 - acc: 0.8390 - val_loss: 0.1977 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.94235 to 0.94340, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-135-0.9434.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3580 - acc: 0.8414 - val_loss: 0.1945 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.94340\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3544 - acc: 0.8445 - val_loss: 0.1913 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.94340\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3550 - acc: 0.8413 - val_loss: 0.1870 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.94340\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3478 - acc: 0.8492 - val_loss: 0.1855 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.94340\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3536 - acc: 0.8461 - val_loss: 0.1881 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.94340 to 0.94410, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-140-0.9441.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3560 - acc: 0.8438 - val_loss: 0.1904 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.94410\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3469 - acc: 0.8454 - val_loss: 0.1822 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.94410\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3515 - acc: 0.8426 - val_loss: 0.1842 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.94410\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3470 - acc: 0.8458 - val_loss: 0.1826 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.94410\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3497 - acc: 0.8451 - val_loss: 0.1806 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.94410\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3525 - acc: 0.8456 - val_loss: 0.1818 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.94410 to 0.94514, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-146-0.9451.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3482 - acc: 0.8479 - val_loss: 0.1794 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.94514 to 0.94654, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/6/weights-improvement-147-0.9465.hdf5\n",
      "Epoch 148/200\n",
      "115/251 [============>.................] - ETA: 2s - loss: 0.3553 - acc: 0.8436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5579 - acc: 0.7356 - val_loss: 0.5423 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79175\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5546 - acc: 0.7360 - val_loss: 0.5375 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.79175\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5551 - acc: 0.7371 - val_loss: 0.5353 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.79175\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5497 - acc: 0.7421 - val_loss: 0.5361 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.79175 to 0.79350, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-043-0.7935.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5497 - acc: 0.7427 - val_loss: 0.5314 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.79350 to 0.79769, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-044-0.7977.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5475 - acc: 0.7418 - val_loss: 0.5301 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.79769 to 0.80154, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-045-0.8015.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5456 - acc: 0.7447 - val_loss: 0.5252 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.80154 to 0.80468, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-046-0.8047.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5432 - acc: 0.7421 - val_loss: 0.5300 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.80468 to 0.80643, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-047-0.8064.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5409 - acc: 0.7431 - val_loss: 0.5185 - val_acc: 0.8138\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.80643 to 0.81377, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-048-0.8138.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5421 - acc: 0.7404 - val_loss: 0.5185 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.81377 to 0.81796, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-049-0.8180.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5360 - acc: 0.7482 - val_loss: 0.5211 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.81796\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5325 - acc: 0.7483 - val_loss: 0.5095 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.81796 to 0.82844, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-051-0.8284.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5309 - acc: 0.7535 - val_loss: 0.5073 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.82844 to 0.83054, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-052-0.8305.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5295 - acc: 0.7483 - val_loss: 0.5052 - val_acc: 0.8312\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.83054 to 0.83124, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-053-0.8312.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5262 - acc: 0.7494 - val_loss: 0.4984 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.83124 to 0.83508, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-054-0.8351.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5284 - acc: 0.7500 - val_loss: 0.4923 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.83508 to 0.83753, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-055-0.8375.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5254 - acc: 0.7553 - val_loss: 0.4955 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.83753 to 0.83788, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-056-0.8379.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5261 - acc: 0.7510 - val_loss: 0.4929 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.83788 to 0.84032, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-057-0.8403.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5222 - acc: 0.7561 - val_loss: 0.4824 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.84032 to 0.84382, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-058-0.8438.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5212 - acc: 0.7511 - val_loss: 0.4900 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.84382\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5199 - acc: 0.7600 - val_loss: 0.4803 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.84382 to 0.84696, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-060-0.8470.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5169 - acc: 0.7576 - val_loss: 0.4711 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.84696 to 0.84906, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-061-0.8491.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5131 - acc: 0.7563 - val_loss: 0.4717 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.84906 to 0.84941, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-062-0.8494.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5156 - acc: 0.7553 - val_loss: 0.4717 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.84941 to 0.85010, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-063-0.8501.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5103 - acc: 0.7662 - val_loss: 0.4634 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.85010 to 0.85395, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-064-0.8539.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5088 - acc: 0.7641 - val_loss: 0.4592 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.85395 to 0.85500, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-065-0.8550.hdf5\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5086 - acc: 0.7649 - val_loss: 0.4499 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.85500 to 0.85709, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-066-0.8571.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5013 - acc: 0.7674 - val_loss: 0.4519 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.85709 to 0.85884, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-067-0.8588.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5049 - acc: 0.7653 - val_loss: 0.4514 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.85884\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5031 - acc: 0.7679 - val_loss: 0.4531 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.85884\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4975 - acc: 0.7692 - val_loss: 0.4402 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.85884 to 0.86338, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-070-0.8634.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4946 - acc: 0.7704 - val_loss: 0.4343 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.86338\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4940 - acc: 0.7758 - val_loss: 0.4316 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.86338 to 0.86548, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-072-0.8655.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4932 - acc: 0.7713 - val_loss: 0.4242 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.86548 to 0.87107, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-073-0.8711.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4917 - acc: 0.7753 - val_loss: 0.4254 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87107\n",
      "Epoch 75/200\n",
      "247/251 [============================>.] - ETA: 0s - loss: 0.4960 - acc: 0.7719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3343 - acc: 0.8561 - val_loss: 0.2123 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.93431\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3311 - acc: 0.8593 - val_loss: 0.2140 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.93431\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3324 - acc: 0.8569 - val_loss: 0.2139 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.93431\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3400 - acc: 0.8529 - val_loss: 0.2176 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.93431 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-171-0.9357.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3354 - acc: 0.8562 - val_loss: 0.2092 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.93571 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-172-0.9371.hdf5\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3278 - acc: 0.8617 - val_loss: 0.2118 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.93711\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3306 - acc: 0.8590 - val_loss: 0.2109 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.93711\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3199 - acc: 0.8623 - val_loss: 0.2064 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.93711\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3211 - acc: 0.8646 - val_loss: 0.2095 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.93711\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3259 - acc: 0.8621 - val_loss: 0.2011 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.93711 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-177-0.9396.hdf5\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3289 - acc: 0.8597 - val_loss: 0.2119 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.93955 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-178-0.9413.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3254 - acc: 0.8595 - val_loss: 0.1998 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.94130\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3192 - acc: 0.8611 - val_loss: 0.2033 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.94130\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3182 - acc: 0.8648 - val_loss: 0.2005 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.94130\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3135 - acc: 0.8660 - val_loss: 0.1983 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.94130\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3147 - acc: 0.8653 - val_loss: 0.1983 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.94130\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3235 - acc: 0.8605 - val_loss: 0.2049 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00184: val_acc improved from 0.94130 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-184-0.9413.hdf5\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3210 - acc: 0.8645 - val_loss: 0.2015 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.94130\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3205 - acc: 0.8661 - val_loss: 0.1976 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.94130 to 0.94235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-186-0.9423.hdf5\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3176 - acc: 0.8640 - val_loss: 0.1990 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.94235\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3156 - acc: 0.8645 - val_loss: 0.1916 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.94235\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3203 - acc: 0.8640 - val_loss: 0.1993 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.94235 to 0.94619, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-189-0.9462.hdf5\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3094 - acc: 0.8691 - val_loss: 0.1923 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.94619\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3129 - acc: 0.8682 - val_loss: 0.1934 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.94619\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3102 - acc: 0.8709 - val_loss: 0.1935 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.94619\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3127 - acc: 0.8678 - val_loss: 0.1938 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.94619\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3069 - acc: 0.8683 - val_loss: 0.1896 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.94619\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3114 - acc: 0.8685 - val_loss: 0.1909 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.94619\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3071 - acc: 0.8699 - val_loss: 0.1850 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.94619 to 0.94654, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-196-0.9465.hdf5\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3123 - acc: 0.8690 - val_loss: 0.1906 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.94654 to 0.94864, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/7/weights-improvement-197-0.9486.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3045 - acc: 0.8743 - val_loss: 0.1872 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.94864\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.2989 - acc: 0.8777 - val_loss: 0.1855 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.94864\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3064 - acc: 0.8710 - val_loss: 0.1862 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.94864\n",
      "It has been  0:19:07.508817\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 1000, 26)     0           input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 1000, 10)     270         dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1000, 10)     790         dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 1000, 10)     1310        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 1000, 10)     2350        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 1000, 10)     3910        dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5000, 10)     0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "                                                                 conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 500, 10)      0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 500, 314)     3454        max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 500, 314)     0           dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 500, 77)      24255       dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 500, 77)      0           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 500, 8)       624         dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 500, 8)       0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 4000)         0           dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 2)            8002        flatten_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "251/251 [==============================] - 7s 27ms/step - loss: 0.6785 - acc: 0.6169 - val_loss: 0.6862 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69602, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-001-0.6960.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6739 - acc: 0.6127 - val_loss: 0.6831 - val_acc: 0.6820\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.69602\n",
      "Epoch 3/200\n",
      "217/251 [========================>.....] - ETA: 0s - loss: 0.6193 - acc: 0.6888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4186 - acc: 0.8088 - val_loss: 0.3068 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.92767 to 0.92837, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-095-0.9284.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4143 - acc: 0.8139 - val_loss: 0.2995 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.92837\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4111 - acc: 0.8181 - val_loss: 0.2942 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.92837\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4133 - acc: 0.8147 - val_loss: 0.3112 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.92837 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-098-0.9301.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4112 - acc: 0.8206 - val_loss: 0.2918 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.93012 to 0.93117, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-099-0.9312.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.4087 - acc: 0.8184 - val_loss: 0.3010 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93117\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4056 - acc: 0.8185 - val_loss: 0.2914 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.93117 to 0.93291, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-101-0.9329.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3996 - acc: 0.8207 - val_loss: 0.2866 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.93291 to 0.93326, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-102-0.9333.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4055 - acc: 0.8197 - val_loss: 0.2886 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.93326 to 0.93431, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-103-0.9343.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3988 - acc: 0.8237 - val_loss: 0.2835 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.93431 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-104-0.9371.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3986 - acc: 0.8226 - val_loss: 0.2912 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93711\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3947 - acc: 0.8263 - val_loss: 0.2634 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.93711 to 0.93816, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-106-0.9382.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3966 - acc: 0.8237 - val_loss: 0.2739 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93816\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3963 - acc: 0.8277 - val_loss: 0.2835 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.93816 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-108-0.9396.hdf5\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3953 - acc: 0.8239 - val_loss: 0.2770 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93955\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3947 - acc: 0.8251 - val_loss: 0.2764 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.93955\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3916 - acc: 0.8222 - val_loss: 0.2724 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.93955 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-111-0.9406.hdf5\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3870 - acc: 0.8288 - val_loss: 0.2588 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.94060 to 0.94270, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-112-0.9427.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3796 - acc: 0.8316 - val_loss: 0.2391 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.94270 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-113-0.9430.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3873 - acc: 0.8269 - val_loss: 0.2442 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.94305\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3855 - acc: 0.8288 - val_loss: 0.2566 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.94305 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-115-0.9455.hdf5\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3836 - acc: 0.8313 - val_loss: 0.2497 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.94549\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3841 - acc: 0.8292 - val_loss: 0.2473 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.94549\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3784 - acc: 0.8347 - val_loss: 0.2392 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.94549 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-118-0.9458.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3779 - acc: 0.8325 - val_loss: 0.2349 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.94584\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3740 - acc: 0.8356 - val_loss: 0.2386 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.94584 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-120-0.9490.hdf5\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3769 - acc: 0.8319 - val_loss: 0.2478 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.94899\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3739 - acc: 0.8380 - val_loss: 0.2309 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.94899\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3707 - acc: 0.8386 - val_loss: 0.2386 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.94899 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-123-0.9504.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3661 - acc: 0.8396 - val_loss: 0.2238 - val_acc: 0.9507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00124: val_acc improved from 0.95038 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-124-0.9507.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3754 - acc: 0.8353 - val_loss: 0.2306 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.95073\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3649 - acc: 0.8395 - val_loss: 0.2199 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.95073 to 0.95178, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-126-0.9518.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3681 - acc: 0.8383 - val_loss: 0.2138 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95178\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3711 - acc: 0.8369 - val_loss: 0.2321 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.95178 to 0.95248, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-128-0.9525.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3662 - acc: 0.8413 - val_loss: 0.2355 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.95248 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-129-0.9539.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3567 - acc: 0.8434 - val_loss: 0.2214 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.95388 to 0.95737, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/8/weights-improvement-130-0.9574.hdf5\n",
      "Epoch 131/200\n",
      " 43/251 [====>.........................] - ETA: 4s - loss: 0.2773 - acc: 0.8833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5970 - acc: 0.7073 - val_loss: 0.5901 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.76101\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5991 - acc: 0.7067 - val_loss: 0.5909 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.76101\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5953 - acc: 0.7100 - val_loss: 0.5877 - val_acc: 0.7285\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.76101\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5949 - acc: 0.7078 - val_loss: 0.5841 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.76101\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5907 - acc: 0.7113 - val_loss: 0.5832 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.76101\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5893 - acc: 0.7115 - val_loss: 0.5797 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.76101\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5869 - acc: 0.7159 - val_loss: 0.5806 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.76101\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5846 - acc: 0.7150 - val_loss: 0.5744 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.76101\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5828 - acc: 0.7155 - val_loss: 0.5757 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.76101\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5822 - acc: 0.7168 - val_loss: 0.5752 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.76101\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5811 - acc: 0.7177 - val_loss: 0.5738 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.76101\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5774 - acc: 0.7184 - val_loss: 0.5700 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.76101\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5751 - acc: 0.7196 - val_loss: 0.5652 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.76101\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5728 - acc: 0.7221 - val_loss: 0.5655 - val_acc: 0.7488\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.76101\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5695 - acc: 0.7274 - val_loss: 0.5597 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.76101\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5672 - acc: 0.7261 - val_loss: 0.5534 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.76101 to 0.76415, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-038-0.7642.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5624 - acc: 0.7267 - val_loss: 0.5500 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.76415 to 0.76765, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-039-0.7676.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5622 - acc: 0.7298 - val_loss: 0.5444 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.76765 to 0.77673, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-040-0.7767.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5582 - acc: 0.7315 - val_loss: 0.5325 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.77673 to 0.79106, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-041-0.7911.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5519 - acc: 0.7352 - val_loss: 0.5259 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.79106 to 0.79700, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-042-0.7970.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5509 - acc: 0.7375 - val_loss: 0.5127 - val_acc: 0.8075\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.79700 to 0.80748, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-043-0.8075.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5512 - acc: 0.7389 - val_loss: 0.5210 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80748\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5455 - acc: 0.7424 - val_loss: 0.5108 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.80748 to 0.81132, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-045-0.8113.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5451 - acc: 0.7458 - val_loss: 0.5098 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.81132 to 0.81551, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-046-0.8155.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5394 - acc: 0.7421 - val_loss: 0.5015 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.81551 to 0.82390, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-047-0.8239.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5358 - acc: 0.7447 - val_loss: 0.4965 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.82390 to 0.82704, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-048-0.8270.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5343 - acc: 0.7457 - val_loss: 0.4951 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.82704 to 0.83054, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-049-0.8305.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5269 - acc: 0.7517 - val_loss: 0.4815 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83054 to 0.83753, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-050-0.8375.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5277 - acc: 0.7517 - val_loss: 0.4802 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.83753 to 0.83962, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-051-0.8396.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5237 - acc: 0.7527 - val_loss: 0.4754 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.83962 to 0.84521, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-052-0.8452.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5254 - acc: 0.7514 - val_loss: 0.4721 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84521 to 0.84801, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-053-0.8480.hdf5\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5168 - acc: 0.7583 - val_loss: 0.4608 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.84801 to 0.85360, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-054-0.8536.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5154 - acc: 0.7582 - val_loss: 0.4598 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85360 to 0.85604, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-055-0.8560.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5101 - acc: 0.7632 - val_loss: 0.4520 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.85604 to 0.86198, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-056-0.8620.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5084 - acc: 0.7647 - val_loss: 0.4439 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.86198 to 0.86758, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-057-0.8676.hdf5\n",
      "Epoch 58/200\n",
      "157/251 [=================>............] - ETA: 1s - loss: 0.4954 - acc: 0.7742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3467 - acc: 0.8499 - val_loss: 0.2257 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.95842 to 0.95912, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-149-0.9591.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3480 - acc: 0.8516 - val_loss: 0.2285 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95912\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3434 - acc: 0.8540 - val_loss: 0.2361 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95912\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3462 - acc: 0.8513 - val_loss: 0.2287 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00152: val_acc improved from 0.95912 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-152-0.9595.hdf5\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3386 - acc: 0.8548 - val_loss: 0.2283 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.95947 to 0.96087, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-153-0.9609.hdf5\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3416 - acc: 0.8553 - val_loss: 0.2208 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.96087\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3424 - acc: 0.8544 - val_loss: 0.2195 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.96087\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3411 - acc: 0.8508 - val_loss: 0.2304 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.96087 to 0.96122, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-156-0.9612.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3374 - acc: 0.8561 - val_loss: 0.2101 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.96122 to 0.96122, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-157-0.9612.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3382 - acc: 0.8538 - val_loss: 0.2276 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.96122\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3366 - acc: 0.8590 - val_loss: 0.2278 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.96122 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-159-0.9619.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3316 - acc: 0.8566 - val_loss: 0.2103 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.96191 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-160-0.9626.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3392 - acc: 0.8537 - val_loss: 0.2325 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.96261\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3402 - acc: 0.8567 - val_loss: 0.2221 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.96261\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3299 - acc: 0.8599 - val_loss: 0.2265 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.96261\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3333 - acc: 0.8567 - val_loss: 0.2099 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.96261 to 0.96296, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-164-0.9630.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3339 - acc: 0.8571 - val_loss: 0.2131 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.96296 to 0.96366, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-165-0.9637.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3308 - acc: 0.8594 - val_loss: 0.2173 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.96366\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3313 - acc: 0.8573 - val_loss: 0.2197 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.96366\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3274 - acc: 0.8589 - val_loss: 0.2142 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.96366\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3353 - acc: 0.8566 - val_loss: 0.2112 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.96366\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3249 - acc: 0.8634 - val_loss: 0.2187 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00170: val_acc improved from 0.96366 to 0.96366, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-170-0.9637.hdf5\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3295 - acc: 0.8557 - val_loss: 0.2124 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.96366 to 0.96506, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-171-0.9651.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3239 - acc: 0.8596 - val_loss: 0.2105 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.96506 to 0.96541, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-172-0.9654.hdf5\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3286 - acc: 0.8598 - val_loss: 0.2038 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.96541\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3302 - acc: 0.8575 - val_loss: 0.2060 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.96541\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3190 - acc: 0.8617 - val_loss: 0.2029 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.96541\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3211 - acc: 0.8657 - val_loss: 0.1948 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.96541 to 0.96646, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/post_padding/9/weights-improvement-176-0.9665.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3292 - acc: 0.8583 - val_loss: 0.2134 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.96646\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3242 - acc: 0.8639 - val_loss: 0.1999 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96646\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3253 - acc: 0.8592 - val_loss: 0.2061 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96646\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3186 - acc: 0.8666 - val_loss: 0.1998 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96646\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3304 - acc: 0.8566 - val_loss: 0.2179 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96646\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3275 - acc: 0.8634 - val_loss: 0.2063 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96646\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3214 - acc: 0.8660 - val_loss: 0.2044 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96646\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3331 - acc: 0.8588 - val_loss: 0.2046 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96646\n",
      "Epoch 185/200\n",
      " 34/251 [===>..........................] - ETA: 4s - loss: 0.2474 - acc: 0.9085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4832 - acc: 0.7751 - val_loss: 0.4262 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.88085 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-076-0.8829.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4792 - acc: 0.7779 - val_loss: 0.4164 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.88295 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-077-0.8850.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4819 - acc: 0.7789 - val_loss: 0.4015 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.88505 to 0.88854, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-078-0.8885.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4732 - acc: 0.7813 - val_loss: 0.4036 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.88854 to 0.89203, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-079-0.8920.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4720 - acc: 0.7810 - val_loss: 0.4139 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.89203\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4702 - acc: 0.7848 - val_loss: 0.3966 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.89203 to 0.89413, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-081-0.8941.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4674 - acc: 0.7854 - val_loss: 0.3966 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.89413 to 0.89623, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-082-0.8962.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4676 - acc: 0.7810 - val_loss: 0.3915 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.89623 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-083-0.8969.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4607 - acc: 0.7895 - val_loss: 0.3903 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.89693 to 0.89867, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-084-0.8987.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4581 - acc: 0.7910 - val_loss: 0.3800 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.89867 to 0.90147, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-085-0.9015.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4558 - acc: 0.7930 - val_loss: 0.3749 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.90147 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-086-0.9043.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4626 - acc: 0.7876 - val_loss: 0.3818 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.90426\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4595 - acc: 0.7940 - val_loss: 0.3786 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90426 to 0.90706, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-088-0.9071.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4581 - acc: 0.7894 - val_loss: 0.3765 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.90706\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4521 - acc: 0.7942 - val_loss: 0.3743 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.90706 to 0.90741, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-090-0.9074.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4501 - acc: 0.7933 - val_loss: 0.3636 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.90741 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-091-0.9095.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4453 - acc: 0.7981 - val_loss: 0.3519 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.90950\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4417 - acc: 0.7967 - val_loss: 0.3578 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.90950\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4487 - acc: 0.7955 - val_loss: 0.3568 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.90950 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-094-0.9116.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4396 - acc: 0.8022 - val_loss: 0.3402 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.91160 to 0.91300, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-095-0.9130.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4406 - acc: 0.7982 - val_loss: 0.3400 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.91300 to 0.91405, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-096-0.9140.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4372 - acc: 0.8015 - val_loss: 0.3405 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.91405 to 0.91440, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-097-0.9144.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4338 - acc: 0.8030 - val_loss: 0.3387 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.91440 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-098-0.9151.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4274 - acc: 0.8066 - val_loss: 0.3269 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.91509 to 0.91754, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-099-0.9175.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4331 - acc: 0.8044 - val_loss: 0.3355 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.91754\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4259 - acc: 0.8063 - val_loss: 0.3254 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.91754\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4281 - acc: 0.8084 - val_loss: 0.3303 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.91754 to 0.91859, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-102-0.9186.hdf5\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4273 - acc: 0.8015 - val_loss: 0.3321 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.91859 to 0.92278, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-103-0.9228.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4177 - acc: 0.8096 - val_loss: 0.3174 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.92278 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-104-0.9231.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4162 - acc: 0.8125 - val_loss: 0.3189 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.92313 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-105-0.9235.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4209 - acc: 0.8135 - val_loss: 0.3185 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.92348 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-106-0.9238.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4185 - acc: 0.8133 - val_loss: 0.3118 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.92383\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4108 - acc: 0.8144 - val_loss: 0.3181 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.92383\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4130 - acc: 0.8165 - val_loss: 0.2979 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.92383\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4087 - acc: 0.8172 - val_loss: 0.2955 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.92383 to 0.92907, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/0/weights-improvement-110-0.9291.hdf5\n",
      "Epoch 111/200\n",
      "139/251 [===============>..............] - ETA: 2s - loss: 0.4061 - acc: 0.8191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6726 - acc: 0.6010 - val_loss: 0.6805 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69741 to 0.78721, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-002-0.7872.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6580 - acc: 0.6416 - val_loss: 0.6551 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.78721\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6389 - acc: 0.6750 - val_loss: 0.6274 - val_acc: 0.7743\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78721\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6290 - acc: 0.6842 - val_loss: 0.6144 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78721\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6232 - acc: 0.6930 - val_loss: 0.6060 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78721\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6216 - acc: 0.6968 - val_loss: 0.6025 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78721\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6190 - acc: 0.6960 - val_loss: 0.5985 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78721\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6183 - acc: 0.6944 - val_loss: 0.5986 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78721\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6164 - acc: 0.6976 - val_loss: 0.5959 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78721\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6161 - acc: 0.6963 - val_loss: 0.5948 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78721\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6154 - acc: 0.6965 - val_loss: 0.5935 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78721\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6124 - acc: 0.6979 - val_loss: 0.5910 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78721\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6129 - acc: 0.6990 - val_loss: 0.5904 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78721\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6104 - acc: 0.7016 - val_loss: 0.5878 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78721\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6082 - acc: 0.7012 - val_loss: 0.5872 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78721\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.6087 - acc: 0.7019 - val_loss: 0.5852 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78721\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6049 - acc: 0.7051 - val_loss: 0.5818 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78721\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6045 - acc: 0.7031 - val_loss: 0.5820 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78721\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6029 - acc: 0.7061 - val_loss: 0.5823 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.78721\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6017 - acc: 0.7086 - val_loss: 0.5782 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.78721\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5999 - acc: 0.7092 - val_loss: 0.5788 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.78721\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5978 - acc: 0.7088 - val_loss: 0.5745 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.78721\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5946 - acc: 0.7111 - val_loss: 0.5723 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.78721\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5925 - acc: 0.7154 - val_loss: 0.5700 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78721\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5902 - acc: 0.7161 - val_loss: 0.5678 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.78721\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5876 - acc: 0.7169 - val_loss: 0.5640 - val_acc: 0.7607\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.78721\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5848 - acc: 0.7148 - val_loss: 0.5632 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.78721\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5802 - acc: 0.7216 - val_loss: 0.5599 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.78721\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5796 - acc: 0.7223 - val_loss: 0.5520 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.78721\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5735 - acc: 0.7256 - val_loss: 0.5463 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.78721\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5719 - acc: 0.7260 - val_loss: 0.5451 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.78721\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5689 - acc: 0.7252 - val_loss: 0.5428 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.78721\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5679 - acc: 0.7294 - val_loss: 0.5426 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.78721\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5635 - acc: 0.7340 - val_loss: 0.5337 - val_acc: 0.7991\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.78721 to 0.79909, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-035-0.7991.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5639 - acc: 0.7298 - val_loss: 0.5360 - val_acc: 0.7963\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.79909\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5575 - acc: 0.7373 - val_loss: 0.5217 - val_acc: 0.8124\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.79909 to 0.81237, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-037-0.8124.hdf5\n",
      "Epoch 38/200\n",
      " 28/251 [==>...........................] - ETA: 4s - loss: 0.4809 - acc: 0.7983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3971 - acc: 0.8237 - val_loss: 0.2560 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.93291 to 0.93361, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-129-0.9336.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3916 - acc: 0.8260 - val_loss: 0.2618 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.93361\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3886 - acc: 0.8239 - val_loss: 0.2576 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.93361\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3890 - acc: 0.8262 - val_loss: 0.2453 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.93361 to 0.93536, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-132-0.9354.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3896 - acc: 0.8277 - val_loss: 0.2587 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.93536\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3815 - acc: 0.8305 - val_loss: 0.2326 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.93536 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-134-0.9357.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3848 - acc: 0.8282 - val_loss: 0.2516 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.93571 to 0.93606, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-135-0.9361.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3901 - acc: 0.8226 - val_loss: 0.2540 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.93606 to 0.93676, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-136-0.9368.hdf5\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3850 - acc: 0.8300 - val_loss: 0.2447 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.93676 to 0.93781, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-137-0.9378.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3825 - acc: 0.8306 - val_loss: 0.2521 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.93781 to 0.93990, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-138-0.9399.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3815 - acc: 0.8305 - val_loss: 0.2424 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.93990\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3886 - acc: 0.8274 - val_loss: 0.2503 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.93990\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3747 - acc: 0.8330 - val_loss: 0.2391 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.93990 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-141-0.9403.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3756 - acc: 0.8340 - val_loss: 0.2496 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.94025\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3813 - acc: 0.8305 - val_loss: 0.2432 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.94025\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3761 - acc: 0.8337 - val_loss: 0.2389 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.94025\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3778 - acc: 0.8368 - val_loss: 0.2485 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.94025\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3778 - acc: 0.8330 - val_loss: 0.2371 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.94025\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3705 - acc: 0.8375 - val_loss: 0.2345 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.94025 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-147-0.9406.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3668 - acc: 0.8398 - val_loss: 0.2231 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.94060\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3695 - acc: 0.8376 - val_loss: 0.2199 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.94060 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-149-0.9430.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3664 - acc: 0.8410 - val_loss: 0.2235 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.94305\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3663 - acc: 0.8417 - val_loss: 0.2241 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.94305\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3661 - acc: 0.8419 - val_loss: 0.2163 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.94305\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3696 - acc: 0.8397 - val_loss: 0.2288 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.94305 to 0.94444, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-153-0.9444.hdf5\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3655 - acc: 0.8408 - val_loss: 0.2212 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.94444\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3634 - acc: 0.8398 - val_loss: 0.2194 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.94444 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-155-0.9455.hdf5\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3655 - acc: 0.8410 - val_loss: 0.2294 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.94549 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-156-0.9455.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3610 - acc: 0.8414 - val_loss: 0.2130 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.94549\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3660 - acc: 0.8414 - val_loss: 0.2202 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.94549\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3650 - acc: 0.8400 - val_loss: 0.2190 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.94549 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-159-0.9458.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3600 - acc: 0.8421 - val_loss: 0.2233 - val_acc: 0.9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00160: val_acc improved from 0.94584 to 0.94759, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-160-0.9476.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3576 - acc: 0.8493 - val_loss: 0.2227 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.94759 to 0.94829, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/1/weights-improvement-161-0.9483.hdf5\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3575 - acc: 0.8413 - val_loss: 0.2125 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.94829\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3602 - acc: 0.8418 - val_loss: 0.2250 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.94829\n",
      "Epoch 164/200\n",
      "175/251 [===================>..........] - ETA: 1s - loss: 0.3463 - acc: 0.8478"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5373 - acc: 0.7472 - val_loss: 0.5099 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.83997 to 0.84102, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-056-0.8410.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5395 - acc: 0.7449 - val_loss: 0.5083 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.84102 to 0.84242, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-057-0.8424.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5360 - acc: 0.7491 - val_loss: 0.5048 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.84242 to 0.84451, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-058-0.8445.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5298 - acc: 0.7520 - val_loss: 0.4993 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.84451 to 0.84626, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-059-0.8463.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5290 - acc: 0.7511 - val_loss: 0.4951 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.84626 to 0.84906, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-060-0.8491.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5244 - acc: 0.7587 - val_loss: 0.4898 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.84906 to 0.84976, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-061-0.8498.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5257 - acc: 0.7566 - val_loss: 0.4879 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.84976 to 0.85115, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-062-0.8512.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5263 - acc: 0.7554 - val_loss: 0.4880 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.85115 to 0.85255, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-063-0.8526.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5232 - acc: 0.7546 - val_loss: 0.4825 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.85255 to 0.85395, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-064-0.8539.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5221 - acc: 0.7538 - val_loss: 0.4846 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.85395 to 0.85570, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-065-0.8557.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5183 - acc: 0.7590 - val_loss: 0.4774 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.85570 to 0.85709, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-066-0.8571.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5156 - acc: 0.7604 - val_loss: 0.4741 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.85709 to 0.86094, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-067-0.8609.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5134 - acc: 0.7635 - val_loss: 0.4676 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.86094\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5095 - acc: 0.7628 - val_loss: 0.4622 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.86094 to 0.86338, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-069-0.8634.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5072 - acc: 0.7655 - val_loss: 0.4576 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.86338 to 0.86688, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-070-0.8669.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5040 - acc: 0.7657 - val_loss: 0.4545 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.86688 to 0.86897, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-071-0.8690.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5047 - acc: 0.7660 - val_loss: 0.4499 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.86897 to 0.87177, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-072-0.8718.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5021 - acc: 0.7677 - val_loss: 0.4465 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.87177 to 0.87386, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-073-0.8739.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5029 - acc: 0.7650 - val_loss: 0.4401 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.87386 to 0.87701, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-074-0.8770.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4961 - acc: 0.7679 - val_loss: 0.4339 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.87701 to 0.87876, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-075-0.8788.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4970 - acc: 0.7713 - val_loss: 0.4387 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.87876 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-076-0.8850.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4978 - acc: 0.7679 - val_loss: 0.4343 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.88505\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4885 - acc: 0.7790 - val_loss: 0.4253 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.88505 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-078-0.8864.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4870 - acc: 0.7776 - val_loss: 0.4159 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.88644 to 0.88819, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-079-0.8882.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4889 - acc: 0.7710 - val_loss: 0.4227 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00080: val_acc improved from 0.88819 to 0.88889, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-080-0.8889.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4829 - acc: 0.7777 - val_loss: 0.4113 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88889\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4834 - acc: 0.7776 - val_loss: 0.4133 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.88889 to 0.88959, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-082-0.8896.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4795 - acc: 0.7782 - val_loss: 0.4097 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.88959 to 0.89064, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-083-0.8906.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4778 - acc: 0.7778 - val_loss: 0.4059 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.89064 to 0.89099, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-084-0.8910.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4765 - acc: 0.7821 - val_loss: 0.4002 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.89099 to 0.89343, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-085-0.8934.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4783 - acc: 0.7769 - val_loss: 0.4028 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.89343 to 0.89588, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-086-0.8959.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4731 - acc: 0.7859 - val_loss: 0.3946 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.89588\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4746 - acc: 0.7787 - val_loss: 0.3960 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.89588 to 0.89588, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-088-0.8959.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4704 - acc: 0.7841 - val_loss: 0.3912 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.89588 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-089-0.8969.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4613 - acc: 0.7902 - val_loss: 0.3747 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.89693\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4638 - acc: 0.7877 - val_loss: 0.3824 - val_acc: 0.8973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3599 - acc: 0.8454 - val_loss: 0.2464 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.93152 to 0.93536, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-163-0.9354.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3608 - acc: 0.8399 - val_loss: 0.2363 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.93536\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3563 - acc: 0.8465 - val_loss: 0.2433 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.93536\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3617 - acc: 0.8429 - val_loss: 0.2413 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.93536\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3608 - acc: 0.8471 - val_loss: 0.2434 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.93536\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3555 - acc: 0.8486 - val_loss: 0.2343 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.93536\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3598 - acc: 0.8421 - val_loss: 0.2416 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.93536\n",
      "Epoch 170/200\n",
      " 79/251 [========>.....................] - ETA: 3s - loss: 0.3565 - acc: 0.8474"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3350 - acc: 0.8564 - val_loss: 0.2081 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.94444 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-192-0.9458.hdf5\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3274 - acc: 0.8633 - val_loss: 0.2127 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.94584\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3366 - acc: 0.8568 - val_loss: 0.2146 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.94584\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3402 - acc: 0.8558 - val_loss: 0.2165 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.94584\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3346 - acc: 0.8589 - val_loss: 0.2115 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.94584 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/2/weights-improvement-196-0.9479.hdf5\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3330 - acc: 0.8536 - val_loss: 0.2077 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.94794\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3343 - acc: 0.8590 - val_loss: 0.2126 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.94794\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3317 - acc: 0.8581 - val_loss: 0.2079 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.94794\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3410 - acc: 0.8532 - val_loss: 0.2146 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.94794\n",
      "It has been  0:19:17.066293\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1000, 26)     0           input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_71 (Conv1D)              (None, 1000, 10)     270         dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_72 (Conv1D)              (None, 1000, 10)     790         dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_73 (Conv1D)              (None, 1000, 10)     1310        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_74 (Conv1D)              (None, 1000, 10)     2350        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_75 (Conv1D)              (None, 1000, 10)     3910        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 5000, 10)     0           conv1d_71[0][0]                  \n",
      "                                                                 conv1d_72[0][0]                  \n",
      "                                                                 conv1d_73[0][0]                  \n",
      "                                                                 conv1d_74[0][0]                  \n",
      "                                                                 conv1d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 500, 10)      0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 500, 314)     3454        max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 500, 314)     0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 500, 77)      24255       dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 500, 77)      0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 500, 8)       624         dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 500, 8)       0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 4000)         0           dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 2)            8002        flatten_15[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 7s 29ms/step - loss: 0.6756 - acc: 0.6234 - val_loss: 0.6809 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.77009, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-001-0.7701.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6548 - acc: 0.6407 - val_loss: 0.6614 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.77009 to 0.78896, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-002-0.7890.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6380 - acc: 0.6752 - val_loss: 0.6420 - val_acc: 0.7806\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.78896\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6291 - acc: 0.6902 - val_loss: 0.6288 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78896\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6247 - acc: 0.6941 - val_loss: 0.6208 - val_acc: 0.7547\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78896\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6220 - acc: 0.6964 - val_loss: 0.6142 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78896\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6194 - acc: 0.6949 - val_loss: 0.6095 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78896\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6180 - acc: 0.6983 - val_loss: 0.6056 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78896\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6172 - acc: 0.6978 - val_loss: 0.6045 - val_acc: 0.7397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78896\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6152 - acc: 0.6996 - val_loss: 0.6005 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78896\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6151 - acc: 0.7005 - val_loss: 0.5994 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78896\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6147 - acc: 0.6981 - val_loss: 0.5965 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78896\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6124 - acc: 0.6990 - val_loss: 0.5920 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78896\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6112 - acc: 0.7008 - val_loss: 0.5925 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78896\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6120 - acc: 0.7002 - val_loss: 0.5911 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78896\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6090 - acc: 0.7004 - val_loss: 0.5884 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78896\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6083 - acc: 0.7000 - val_loss: 0.5869 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78896\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6076 - acc: 0.7025 - val_loss: 0.5847 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78896\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6063 - acc: 0.7003 - val_loss: 0.5824 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.78896\n",
      "Epoch 20/200\n",
      " 10/251 [>.............................] - ETA: 5s - loss: 0.5529 - acc: 0.7333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4668 - acc: 0.7877 - val_loss: 0.4298 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.88609\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4645 - acc: 0.7900 - val_loss: 0.4276 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.88609\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4600 - acc: 0.7893 - val_loss: 0.4188 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.88609 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-092-0.8861.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4593 - acc: 0.7940 - val_loss: 0.4241 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.88609 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-093-0.8878.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4578 - acc: 0.7930 - val_loss: 0.4150 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.88784 to 0.88819, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-094-0.8882.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4553 - acc: 0.7932 - val_loss: 0.4161 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.88819 to 0.89099, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-095-0.8910.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4497 - acc: 0.7956 - val_loss: 0.4022 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.89099\n",
      "Epoch 97/200\n",
      "190/251 [=====================>........] - ETA: 1s - loss: 0.4363 - acc: 0.8033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4109 - acc: 0.8189 - val_loss: 0.3754 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.90461 to 0.90566, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-119-0.9057.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4106 - acc: 0.8200 - val_loss: 0.3687 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.90566\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4154 - acc: 0.8146 - val_loss: 0.3790 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.90566\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4070 - acc: 0.8212 - val_loss: 0.3646 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.90566 to 0.90636, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-122-0.9064.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4086 - acc: 0.8220 - val_loss: 0.3625 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.90636\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4029 - acc: 0.8199 - val_loss: 0.3690 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.90636\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3986 - acc: 0.8246 - val_loss: 0.3593 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.90636 to 0.90776, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-125-0.9078.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3977 - acc: 0.8254 - val_loss: 0.3571 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.90776 to 0.90915, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-126-0.9092.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4040 - acc: 0.8192 - val_loss: 0.3561 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.90915\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3982 - acc: 0.8264 - val_loss: 0.3626 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.90915\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3953 - acc: 0.8280 - val_loss: 0.3579 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.90915\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4001 - acc: 0.8246 - val_loss: 0.3680 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.90915\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3927 - acc: 0.8291 - val_loss: 0.3507 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.90915\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3974 - acc: 0.8263 - val_loss: 0.3696 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.90915 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-132-0.9095.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3904 - acc: 0.8300 - val_loss: 0.3570 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.90950\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3958 - acc: 0.8267 - val_loss: 0.3587 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.90950\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3899 - acc: 0.8282 - val_loss: 0.3520 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.90950\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3935 - acc: 0.8278 - val_loss: 0.3594 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.90950\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3912 - acc: 0.8301 - val_loss: 0.3537 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.90950\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3850 - acc: 0.8309 - val_loss: 0.3457 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.90950\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3895 - acc: 0.8309 - val_loss: 0.3493 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.90950 to 0.91090, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-139-0.9109.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3853 - acc: 0.8333 - val_loss: 0.3472 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.91090 to 0.91405, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/3/weights-improvement-140-0.9140.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3773 - acc: 0.8340 - val_loss: 0.3446 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.91405\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3803 - acc: 0.8337 - val_loss: 0.3497 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.91405\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3828 - acc: 0.8335 - val_loss: 0.3469 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.91405\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3782 - acc: 0.8344 - val_loss: 0.3306 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.91405\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3764 - acc: 0.8348 - val_loss: 0.3387 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.91405\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3768 - acc: 0.8379 - val_loss: 0.3467 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.91405\n",
      "Epoch 147/200\n",
      " 61/251 [======>.......................] - ETA: 4s - loss: 0.3444 - acc: 0.8619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6067 - acc: 0.7045 - val_loss: 0.5956 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74074\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6059 - acc: 0.7067 - val_loss: 0.5955 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.74074\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6052 - acc: 0.7023 - val_loss: 0.5932 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.74074\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6014 - acc: 0.7053 - val_loss: 0.5924 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.74074\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6006 - acc: 0.7061 - val_loss: 0.5900 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.74074\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5983 - acc: 0.7080 - val_loss: 0.5864 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.74074 to 0.74179, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-023-0.7418.hdf5\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5963 - acc: 0.7079 - val_loss: 0.5849 - val_acc: 0.7453\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.74179 to 0.74528, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-024-0.7453.hdf5\n",
      "Epoch 25/200\n",
      " 79/251 [========>.....................] - ETA: 3s - loss: 0.6066 - acc: 0.7004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5440 - acc: 0.7427 - val_loss: 0.5121 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.83194 to 0.83368, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-047-0.8337.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5417 - acc: 0.7421 - val_loss: 0.5091 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.83368 to 0.83823, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-048-0.8382.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5407 - acc: 0.7469 - val_loss: 0.5067 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.83823 to 0.83997, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-049-0.8400.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5356 - acc: 0.7468 - val_loss: 0.4993 - val_acc: 0.8459\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83997 to 0.84591, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-050-0.8459.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5373 - acc: 0.7459 - val_loss: 0.5002 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.84591 to 0.85220, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-051-0.8522.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5341 - acc: 0.7481 - val_loss: 0.4968 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.85220 to 0.85465, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-052-0.8546.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5327 - acc: 0.7501 - val_loss: 0.4953 - val_acc: 0.8543\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.85465\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5324 - acc: 0.7508 - val_loss: 0.4907 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.85465 to 0.85570, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-054-0.8557.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5241 - acc: 0.7550 - val_loss: 0.4835 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85570 to 0.85639, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-055-0.8564.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5259 - acc: 0.7557 - val_loss: 0.4851 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.85639 to 0.85954, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-056-0.8595.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5223 - acc: 0.7551 - val_loss: 0.4829 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.85954 to 0.86583, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-057-0.8658.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5219 - acc: 0.7568 - val_loss: 0.4799 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.86583 to 0.86723, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-058-0.8672.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5186 - acc: 0.7553 - val_loss: 0.4733 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.86723 to 0.86792, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-059-0.8679.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5159 - acc: 0.7571 - val_loss: 0.4723 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.86792 to 0.86862, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-060-0.8686.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5133 - acc: 0.7592 - val_loss: 0.4672 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.86862 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-061-0.8693.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5122 - acc: 0.7599 - val_loss: 0.4627 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.86932 to 0.87072, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-062-0.8707.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5090 - acc: 0.7629 - val_loss: 0.4612 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.87072\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5134 - acc: 0.7608 - val_loss: 0.4658 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.87072 to 0.87212, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-064-0.8721.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5057 - acc: 0.7636 - val_loss: 0.4562 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.87212 to 0.87352, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-065-0.8735.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5024 - acc: 0.7660 - val_loss: 0.4463 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.87352 to 0.87491, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-066-0.8749.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5004 - acc: 0.7668 - val_loss: 0.4488 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87491\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5001 - acc: 0.7699 - val_loss: 0.4420 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.87491 to 0.87736, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-068-0.8774.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4987 - acc: 0.7676 - val_loss: 0.4423 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.87736\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4970 - acc: 0.7693 - val_loss: 0.4426 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87736\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4936 - acc: 0.7705 - val_loss: 0.4389 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.87736 to 0.87945, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-071-0.8795.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4898 - acc: 0.7748 - val_loss: 0.4272 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.87945 to 0.88085, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-072-0.8809.hdf5\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4942 - acc: 0.7717 - val_loss: 0.4378 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.88085 to 0.88225, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-073-0.8823.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4913 - acc: 0.7728 - val_loss: 0.4348 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.88225 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-074-0.8864.hdf5\n",
      "Epoch 75/200\n",
      " 79/251 [========>.....................] - ETA: 3s - loss: 0.4944 - acc: 0.7705"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3768 - acc: 0.8350 - val_loss: 0.2849 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.93606 to 0.93850, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-144-0.9385.hdf5\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3695 - acc: 0.8386 - val_loss: 0.2815 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.93850\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3713 - acc: 0.8362 - val_loss: 0.2765 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.93850\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3708 - acc: 0.8390 - val_loss: 0.2856 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.93850 to 0.93885, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-147-0.9389.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3706 - acc: 0.8377 - val_loss: 0.2831 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.93885\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3699 - acc: 0.8365 - val_loss: 0.2820 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.93885 to 0.93920, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-149-0.9392.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3718 - acc: 0.8397 - val_loss: 0.2827 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.93920 to 0.93990, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-150-0.9399.hdf5\n",
      "Epoch 151/200\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.3572 - acc: 0.8440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3558 - acc: 0.8436 - val_loss: 0.2613 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.94584\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3507 - acc: 0.8510 - val_loss: 0.2608 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.94584\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3496 - acc: 0.8506 - val_loss: 0.2532 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00175: val_acc improved from 0.94584 to 0.94724, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-175-0.9472.hdf5\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3398 - acc: 0.8516 - val_loss: 0.2418 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.94724 to 0.94759, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-176-0.9476.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3454 - acc: 0.8507 - val_loss: 0.2510 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.94759\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3506 - acc: 0.8465 - val_loss: 0.2540 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.94759\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3531 - acc: 0.8475 - val_loss: 0.2636 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00179: val_acc improved from 0.94759 to 0.94899, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-179-0.9490.hdf5\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3436 - acc: 0.8544 - val_loss: 0.2526 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.94899\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3509 - acc: 0.8482 - val_loss: 0.2527 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.94899\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3387 - acc: 0.8550 - val_loss: 0.2492 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.94899\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3496 - acc: 0.8512 - val_loss: 0.2488 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.94899 to 0.95108, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-183-0.9511.hdf5\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3376 - acc: 0.8528 - val_loss: 0.2404 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.95108\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3424 - acc: 0.8526 - val_loss: 0.2466 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.95108\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3477 - acc: 0.8488 - val_loss: 0.2482 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.95108 to 0.95283, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-186-0.9528.hdf5\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3492 - acc: 0.8503 - val_loss: 0.2506 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00187: val_acc improved from 0.95283 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-187-0.9532.hdf5\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3414 - acc: 0.8567 - val_loss: 0.2397 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.95318\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3431 - acc: 0.8536 - val_loss: 0.2493 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.95318\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3337 - acc: 0.8574 - val_loss: 0.2423 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.95318\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3400 - acc: 0.8508 - val_loss: 0.2517 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.95318\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3397 - acc: 0.8540 - val_loss: 0.2433 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.95318\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3409 - acc: 0.8561 - val_loss: 0.2318 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00193: val_acc improved from 0.95318 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-193-0.9539.hdf5\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3351 - acc: 0.8572 - val_loss: 0.2400 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.95388\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3381 - acc: 0.8561 - val_loss: 0.2506 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.95388\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3316 - acc: 0.8571 - val_loss: 0.2340 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.95388\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3366 - acc: 0.8561 - val_loss: 0.2342 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95388\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3357 - acc: 0.8564 - val_loss: 0.2397 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.95388 to 0.95563, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-198-0.9556.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3305 - acc: 0.8603 - val_loss: 0.2288 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.95563\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3343 - acc: 0.8608 - val_loss: 0.2421 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.95563 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/4/weights-improvement-200-0.9560.hdf5\n",
      "It has been  0:19:22.701535\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 1000, 26)     0           input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_81 (Conv1D)              (None, 1000, 10)     270         dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_82 (Conv1D)              (None, 1000, 10)     790         dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_83 (Conv1D)              (None, 1000, 10)     1310        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_84 (Conv1D)              (None, 1000, 10)     2350        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_85 (Conv1D)              (None, 1000, 10)     3910        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 5000, 10)     0           conv1d_81[0][0]                  \n",
      "                                                                 conv1d_82[0][0]                  \n",
      "                                                                 conv1d_83[0][0]                  \n",
      "                                                                 conv1d_84[0][0]                  \n",
      "                                                                 conv1d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 500, 10)      0           concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 500, 314)     3454        max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 500, 314)     0           dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 500, 77)      24255       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 500, 77)      0           dense_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 500, 8)       624         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 500, 8)       0           dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 4000)         0           dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 2)            8002        flatten_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "193/251 [======================>.......] - ETA: 1s - loss: 0.6683 - acc: 0.6436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4751 - acc: 0.7835 - val_loss: 0.3849 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.90147\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4771 - acc: 0.7817 - val_loss: 0.3807 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.90147 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-072-0.9043.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4743 - acc: 0.7801 - val_loss: 0.3762 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.90426\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4702 - acc: 0.7838 - val_loss: 0.3751 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.90426\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4673 - acc: 0.7867 - val_loss: 0.3709 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.90426\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4667 - acc: 0.7852 - val_loss: 0.3671 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.90426 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-076-0.9043.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4580 - acc: 0.7934 - val_loss: 0.3613 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.90426 to 0.90496, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-077-0.9050.hdf5\n",
      "Epoch 78/200\n",
      "178/251 [====================>.........] - ETA: 1s - loss: 0.4486 - acc: 0.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4191 - acc: 0.8108 - val_loss: 0.3145 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.92383\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4185 - acc: 0.8108 - val_loss: 0.3021 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.92383\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4171 - acc: 0.8149 - val_loss: 0.2954 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.92383 to 0.92558, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-102-0.9256.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4141 - acc: 0.8139 - val_loss: 0.2934 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.92558\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4217 - acc: 0.8128 - val_loss: 0.3059 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.92558 to 0.93082, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-104-0.9308.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4131 - acc: 0.8155 - val_loss: 0.2985 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93082\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4048 - acc: 0.8181 - val_loss: 0.2928 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.93082\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4084 - acc: 0.8165 - val_loss: 0.2904 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93082\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4046 - acc: 0.8195 - val_loss: 0.2805 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93082\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4095 - acc: 0.8174 - val_loss: 0.2930 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93082\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4045 - acc: 0.8217 - val_loss: 0.2795 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.93082\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4066 - acc: 0.8169 - val_loss: 0.2808 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.93082\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4014 - acc: 0.8235 - val_loss: 0.2782 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.93082\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3995 - acc: 0.8231 - val_loss: 0.2767 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.93082 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-113-0.9315.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4083 - acc: 0.8181 - val_loss: 0.2880 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.93152 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-114-0.9322.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3933 - acc: 0.8231 - val_loss: 0.2741 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.93222 to 0.93641, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-115-0.9364.hdf5\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4007 - acc: 0.8215 - val_loss: 0.2773 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93641\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3969 - acc: 0.8240 - val_loss: 0.2762 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.93641\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3918 - acc: 0.8257 - val_loss: 0.2709 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.93641 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-118-0.9371.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4005 - acc: 0.8206 - val_loss: 0.2755 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.93711 to 0.93746, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-119-0.9375.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3890 - acc: 0.8268 - val_loss: 0.2716 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93746\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3935 - acc: 0.8257 - val_loss: 0.2795 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.93746 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-121-0.9406.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3911 - acc: 0.8290 - val_loss: 0.2689 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.94060\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3955 - acc: 0.8266 - val_loss: 0.2756 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.94060\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3901 - acc: 0.8283 - val_loss: 0.2737 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.94060 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-124-0.9416.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3879 - acc: 0.8302 - val_loss: 0.2745 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.94165\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3919 - acc: 0.8293 - val_loss: 0.2686 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.94165\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3838 - acc: 0.8293 - val_loss: 0.2601 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.94165\n",
      "Epoch 128/200\n",
      " 43/251 [====>.........................] - ETA: 4s - loss: 0.3023 - acc: 0.8867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3386 - acc: 0.8546 - val_loss: 0.2039 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.96087\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3301 - acc: 0.8567 - val_loss: 0.1965 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.96087\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3290 - acc: 0.8588 - val_loss: 0.1953 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.96087 to 0.96157, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-199-0.9616.hdf5\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3255 - acc: 0.8586 - val_loss: 0.2013 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.96157 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/5/weights-improvement-200-0.9619.hdf5\n",
      "It has been  0:19:27.847112\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_18 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 1000, 26)     0           input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_86 (Conv1D)              (None, 1000, 10)     270         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_87 (Conv1D)              (None, 1000, 10)     790         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_88 (Conv1D)              (None, 1000, 10)     1310        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_89 (Conv1D)              (None, 1000, 10)     2350        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_90 (Conv1D)              (None, 1000, 10)     3910        dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 5000, 10)     0           conv1d_86[0][0]                  \n",
      "                                                                 conv1d_87[0][0]                  \n",
      "                                                                 conv1d_88[0][0]                  \n",
      "                                                                 conv1d_89[0][0]                  \n",
      "                                                                 conv1d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 500, 10)      0           concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 500, 314)     3454        max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 500, 314)     0           dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 500, 77)      24255       dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 500, 77)      0           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 500, 8)       624         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 500, 8)       0           dense_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 4000)         0           dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 2)            8002        flatten_18[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 8s 30ms/step - loss: 0.6748 - acc: 0.6321 - val_loss: 0.6820 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.79700, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-001-0.7970.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6585 - acc: 0.6349 - val_loss: 0.6762 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.79700\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6462 - acc: 0.6720 - val_loss: 0.6586 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.79700\n",
      "Epoch 4/200\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.6266 - acc: 0.6964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5958 - acc: 0.7058 - val_loss: 0.5883 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.79700\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5948 - acc: 0.7092 - val_loss: 0.5861 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79700\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5901 - acc: 0.7075 - val_loss: 0.5834 - val_acc: 0.7358\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79700\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5897 - acc: 0.7107 - val_loss: 0.5801 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.79700\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5881 - acc: 0.7106 - val_loss: 0.5800 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.79700\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5833 - acc: 0.7145 - val_loss: 0.5832 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.79700\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5837 - acc: 0.7166 - val_loss: 0.5797 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.79700\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5793 - acc: 0.7179 - val_loss: 0.5740 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79700\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5777 - acc: 0.7210 - val_loss: 0.5701 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79700\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5748 - acc: 0.7201 - val_loss: 0.5667 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.79700\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5680 - acc: 0.7245 - val_loss: 0.5574 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.79700\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5667 - acc: 0.7250 - val_loss: 0.5498 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.79700\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5621 - acc: 0.7309 - val_loss: 0.5503 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.79700\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5572 - acc: 0.7325 - val_loss: 0.5412 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79700\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5551 - acc: 0.7355 - val_loss: 0.5376 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.79700 to 0.80398, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-040-0.8040.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5526 - acc: 0.7348 - val_loss: 0.5346 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.80398 to 0.81027, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-041-0.8103.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5487 - acc: 0.7416 - val_loss: 0.5305 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.81027 to 0.81586, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-042-0.8159.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5443 - acc: 0.7427 - val_loss: 0.5266 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.81586 to 0.82006, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-043-0.8201.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5431 - acc: 0.7405 - val_loss: 0.5167 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.82006 to 0.82774, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-044-0.8277.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5390 - acc: 0.7466 - val_loss: 0.5123 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.82774 to 0.83019, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-045-0.8302.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5344 - acc: 0.7495 - val_loss: 0.5185 - val_acc: 0.8298\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.83019\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5325 - acc: 0.7488 - val_loss: 0.5110 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.83019 to 0.83823, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-047-0.8382.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5263 - acc: 0.7507 - val_loss: 0.4976 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.83823 to 0.84242, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-048-0.8424.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5272 - acc: 0.7520 - val_loss: 0.5070 - val_acc: 0.8414\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.84242\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5249 - acc: 0.7537 - val_loss: 0.5042 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.84242 to 0.84731, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-050-0.8473.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5200 - acc: 0.7572 - val_loss: 0.4924 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.84731 to 0.85360, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-051-0.8536.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5205 - acc: 0.7544 - val_loss: 0.4917 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.85360 to 0.85604, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-052-0.8560.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5182 - acc: 0.7577 - val_loss: 0.4984 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.85604\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5141 - acc: 0.7627 - val_loss: 0.4910 - val_acc: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3783 - acc: 0.8356 - val_loss: 0.3198 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93990\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3774 - acc: 0.8343 - val_loss: 0.3202 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.93990\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3694 - acc: 0.8358 - val_loss: 0.3075 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.93990\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3743 - acc: 0.8351 - val_loss: 0.3165 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.93990 to 0.93990, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-127-0.9399.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3679 - acc: 0.8357 - val_loss: 0.3015 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.93990\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3681 - acc: 0.8409 - val_loss: 0.3040 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.93990 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-129-0.9406.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3721 - acc: 0.8361 - val_loss: 0.3097 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.94060\n",
      "Epoch 131/200\n",
      " 82/251 [========>.....................] - ETA: 3s - loss: 0.3639 - acc: 0.8403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3415 - acc: 0.8524 - val_loss: 0.2671 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95283\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3364 - acc: 0.8544 - val_loss: 0.2601 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95283\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3407 - acc: 0.8531 - val_loss: 0.2852 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95283\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3415 - acc: 0.8566 - val_loss: 0.2627 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.95283\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3417 - acc: 0.8580 - val_loss: 0.2512 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.95283\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3355 - acc: 0.8558 - val_loss: 0.2609 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.95283 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-158-0.9539.hdf5\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3395 - acc: 0.8531 - val_loss: 0.2720 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95388\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3426 - acc: 0.8529 - val_loss: 0.2822 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.95388 to 0.95493, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-160-0.9549.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3388 - acc: 0.8565 - val_loss: 0.2629 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95493\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3358 - acc: 0.8547 - val_loss: 0.2610 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.95493 to 0.95493, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-162-0.9549.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3421 - acc: 0.8562 - val_loss: 0.2551 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95493\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3364 - acc: 0.8531 - val_loss: 0.2528 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.95493 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-164-0.9560.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3305 - acc: 0.8596 - val_loss: 0.2577 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.95597 to 0.95667, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-165-0.9567.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3353 - acc: 0.8566 - val_loss: 0.2607 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.95667\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3349 - acc: 0.8551 - val_loss: 0.2575 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95667\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3415 - acc: 0.8533 - val_loss: 0.2707 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.95667 to 0.95772, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-168-0.9577.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3301 - acc: 0.8590 - val_loss: 0.2433 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00169: val_acc improved from 0.95772 to 0.95807, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-169-0.9581.hdf5\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3345 - acc: 0.8557 - val_loss: 0.2654 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95807\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3319 - acc: 0.8596 - val_loss: 0.2675 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95807\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3279 - acc: 0.8598 - val_loss: 0.2562 - val_acc: 0.9567\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.95807\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3338 - acc: 0.8564 - val_loss: 0.2430 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00173: val_acc improved from 0.95807 to 0.95982, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-173-0.9598.hdf5\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3242 - acc: 0.8604 - val_loss: 0.2282 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.95982 to 0.96017, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-174-0.9602.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3269 - acc: 0.8592 - val_loss: 0.2327 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00175: val_acc improved from 0.96017 to 0.96087, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-175-0.9609.hdf5\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3287 - acc: 0.8583 - val_loss: 0.2367 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.96087 to 0.96122, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-176-0.9612.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3224 - acc: 0.8626 - val_loss: 0.2444 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.96122\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3318 - acc: 0.8575 - val_loss: 0.2466 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.96122\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3219 - acc: 0.8614 - val_loss: 0.2360 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00179: val_acc improved from 0.96122 to 0.96122, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/6/weights-improvement-179-0.9612.hdf5\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3312 - acc: 0.8602 - val_loss: 0.2501 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96122\n",
      "Epoch 181/200\n",
      "178/251 [====================>.........] - ETA: 1s - loss: 0.3061 - acc: 0.8669"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5441 - acc: 0.7452 - val_loss: 0.5417 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.78826 to 0.79769, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-050-0.7977.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5427 - acc: 0.7456 - val_loss: 0.5363 - val_acc: 0.8089\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.79769 to 0.80887, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-051-0.8089.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5386 - acc: 0.7458 - val_loss: 0.5316 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.80887 to 0.81167, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-052-0.8117.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5387 - acc: 0.7517 - val_loss: 0.5281 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.81167 to 0.82215, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-053-0.8222.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5387 - acc: 0.7455 - val_loss: 0.5314 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.82215\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5348 - acc: 0.7522 - val_loss: 0.5265 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.82215 to 0.82565, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-055-0.8256.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5296 - acc: 0.7544 - val_loss: 0.5198 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.82565 to 0.83578, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-056-0.8358.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5283 - acc: 0.7551 - val_loss: 0.5189 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.83578\n",
      "Epoch 58/200\n",
      " 46/251 [====>.........................] - ETA: 4s - loss: 0.4519 - acc: 0.8229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4790 - acc: 0.7819 - val_loss: 0.4127 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89343 to 0.89483, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-079-0.8948.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4751 - acc: 0.7809 - val_loss: 0.4089 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.89483 to 0.90007, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-080-0.9001.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4689 - acc: 0.7885 - val_loss: 0.3965 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.90007 to 0.90252, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-081-0.9025.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4639 - acc: 0.7900 - val_loss: 0.3904 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.90252\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4650 - acc: 0.7900 - val_loss: 0.3878 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.90252 to 0.90356, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-083-0.9036.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4567 - acc: 0.7946 - val_loss: 0.3824 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.90356\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4605 - acc: 0.7933 - val_loss: 0.3852 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.90356 to 0.90496, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-085-0.9050.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4577 - acc: 0.7948 - val_loss: 0.3818 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.90496\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4523 - acc: 0.7928 - val_loss: 0.3733 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.90496\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4516 - acc: 0.7959 - val_loss: 0.3698 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90496 to 0.90531, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-088-0.9053.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4533 - acc: 0.7990 - val_loss: 0.3705 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.90531 to 0.90636, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-089-0.9064.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4501 - acc: 0.7988 - val_loss: 0.3638 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.90636 to 0.90881, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-090-0.9088.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4471 - acc: 0.7985 - val_loss: 0.3628 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.90881 to 0.91090, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-091-0.9109.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4433 - acc: 0.7992 - val_loss: 0.3567 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.91090 to 0.91230, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-092-0.9123.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4392 - acc: 0.8027 - val_loss: 0.3511 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.91230 to 0.91335, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-093-0.9133.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4382 - acc: 0.7999 - val_loss: 0.3491 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.91335 to 0.91544, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-094-0.9154.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4377 - acc: 0.8023 - val_loss: 0.3402 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.91544 to 0.91649, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-095-0.9165.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4360 - acc: 0.8075 - val_loss: 0.3440 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.91649 to 0.91929, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-096-0.9193.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4329 - acc: 0.8054 - val_loss: 0.3393 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.91929 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-097-0.9200.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4233 - acc: 0.8088 - val_loss: 0.3288 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.91999\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4273 - acc: 0.8107 - val_loss: 0.3314 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.91999\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4224 - acc: 0.8103 - val_loss: 0.3242 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.91999 to 0.92068, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-100-0.9207.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4219 - acc: 0.8142 - val_loss: 0.3185 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.92068 to 0.92173, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-101-0.9217.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4279 - acc: 0.8125 - val_loss: 0.3282 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.92173 to 0.92488, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-102-0.9249.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4170 - acc: 0.8141 - val_loss: 0.3206 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.92488 to 0.92558, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-103-0.9256.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4159 - acc: 0.8169 - val_loss: 0.3132 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.92558 to 0.92628, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-104-0.9263.hdf5\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4137 - acc: 0.8137 - val_loss: 0.3099 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.92628 to 0.92662, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-105-0.9266.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4164 - acc: 0.8140 - val_loss: 0.3183 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.92662 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-106-0.9287.hdf5\n",
      "Epoch 107/200\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.3773 - acc: 0.8369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3406 - acc: 0.8518 - val_loss: 0.2079 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.96191 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-176-0.9626.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3312 - acc: 0.8615 - val_loss: 0.1981 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.96261 to 0.96331, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-177-0.9633.hdf5\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3358 - acc: 0.8553 - val_loss: 0.2050 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.96331 to 0.96401, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/7/weights-improvement-178-0.9640.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3346 - acc: 0.8586 - val_loss: 0.2019 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.96401\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3444 - acc: 0.8549 - val_loss: 0.2070 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.96401\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3366 - acc: 0.8561 - val_loss: 0.1995 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.96401\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3286 - acc: 0.8616 - val_loss: 0.1921 - val_acc: 0.9633\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.96401\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3280 - acc: 0.8608 - val_loss: 0.1974 - val_acc: 0.9630\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.96401\n",
      "Epoch 184/200\n",
      " 28/251 [==>...........................] - ETA: 4s - loss: 0.2486 - acc: 0.9074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6193 - acc: 0.6960 - val_loss: 0.6264 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75472\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6175 - acc: 0.6950 - val_loss: 0.6216 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75472\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6151 - acc: 0.6985 - val_loss: 0.6178 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75472\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6153 - acc: 0.6966 - val_loss: 0.6151 - val_acc: 0.7243\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75472\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6135 - acc: 0.6968 - val_loss: 0.6113 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75472\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6130 - acc: 0.6943 - val_loss: 0.6088 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75472\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6115 - acc: 0.6993 - val_loss: 0.6072 - val_acc: 0.7271\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75472\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6099 - acc: 0.6981 - val_loss: 0.6043 - val_acc: 0.7292\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75472\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6100 - acc: 0.6972 - val_loss: 0.6038 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75472\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6103 - acc: 0.6972 - val_loss: 0.6022 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75472\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6082 - acc: 0.6978 - val_loss: 0.5992 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75472\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6064 - acc: 0.6994 - val_loss: 0.5982 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75472\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6034 - acc: 0.7013 - val_loss: 0.5962 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75472\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6016 - acc: 0.7022 - val_loss: 0.5952 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75472\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6030 - acc: 0.7016 - val_loss: 0.5934 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75472\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6005 - acc: 0.7036 - val_loss: 0.5905 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75472\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5987 - acc: 0.7007 - val_loss: 0.5893 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75472\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5979 - acc: 0.7013 - val_loss: 0.5869 - val_acc: 0.7428\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75472\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5982 - acc: 0.7011 - val_loss: 0.5858 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75472\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5966 - acc: 0.7024 - val_loss: 0.5841 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.75472\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5930 - acc: 0.7050 - val_loss: 0.5807 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.75472\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5899 - acc: 0.7060 - val_loss: 0.5776 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.75472\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5880 - acc: 0.7080 - val_loss: 0.5782 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.75472\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5870 - acc: 0.7109 - val_loss: 0.5750 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.75472\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5840 - acc: 0.7106 - val_loss: 0.5710 - val_acc: 0.7505\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.75472\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5799 - acc: 0.7173 - val_loss: 0.5684 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.75472\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5803 - acc: 0.7165 - val_loss: 0.5656 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.75472 to 0.75577, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-033-0.7558.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5791 - acc: 0.7124 - val_loss: 0.5633 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.75577 to 0.76031, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-034-0.7603.hdf5\n",
      "Epoch 35/200\n",
      " 52/251 [=====>........................] - ETA: 4s - loss: 0.5074 - acc: 0.7849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4047 - acc: 0.8173 - val_loss: 0.3421 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.92208 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-103-0.9235.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4095 - acc: 0.8175 - val_loss: 0.3525 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.92348 to 0.92488, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-104-0.9249.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4067 - acc: 0.8234 - val_loss: 0.3472 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.92488 to 0.92523, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-105-0.9252.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4089 - acc: 0.8187 - val_loss: 0.3469 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.92523 to 0.92662, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-106-0.9266.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3990 - acc: 0.8217 - val_loss: 0.3422 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.92662 to 0.92662, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-107-0.9266.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3993 - acc: 0.8226 - val_loss: 0.3411 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00108: val_acc improved from 0.92662 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-108-0.9287.hdf5\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4027 - acc: 0.8220 - val_loss: 0.3320 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.92872 to 0.92942, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-109-0.9294.hdf5\n",
      "Epoch 110/200\n",
      "238/251 [===========================>..] - ETA: 0s - loss: 0.4007 - acc: 0.8249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3604 - acc: 0.8438 - val_loss: 0.2866 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94130\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3655 - acc: 0.8381 - val_loss: 0.2887 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.94130 to 0.94444, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-134-0.9444.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3650 - acc: 0.8416 - val_loss: 0.2943 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.94444\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3664 - acc: 0.8409 - val_loss: 0.2859 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.94444\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3659 - acc: 0.8403 - val_loss: 0.2967 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.94444\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3568 - acc: 0.8456 - val_loss: 0.2855 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.94444\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3619 - acc: 0.8456 - val_loss: 0.2834 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.94444\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3585 - acc: 0.8465 - val_loss: 0.2914 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.94444 to 0.94479, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-140-0.9448.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3597 - acc: 0.8463 - val_loss: 0.2912 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.94479\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3645 - acc: 0.8425 - val_loss: 0.2876 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.94479 to 0.94514, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-142-0.9451.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3628 - acc: 0.8432 - val_loss: 0.2905 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.94514 to 0.94689, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-143-0.9469.hdf5\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3621 - acc: 0.8401 - val_loss: 0.2808 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.94689\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3675 - acc: 0.8422 - val_loss: 0.2953 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00145: val_acc improved from 0.94689 to 0.95003, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-145-0.9500.hdf5\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3578 - acc: 0.8459 - val_loss: 0.2751 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.95003 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-146-0.9504.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3539 - acc: 0.8500 - val_loss: 0.2833 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.95038\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3597 - acc: 0.8456 - val_loss: 0.2813 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95038\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3537 - acc: 0.8466 - val_loss: 0.2828 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.95038\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3532 - acc: 0.8466 - val_loss: 0.2738 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95038\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3536 - acc: 0.8479 - val_loss: 0.2688 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.95038 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-151-0.9504.hdf5\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3555 - acc: 0.8454 - val_loss: 0.2748 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.95038\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3531 - acc: 0.8452 - val_loss: 0.2802 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.95038 to 0.95108, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-153-0.9511.hdf5\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3533 - acc: 0.8465 - val_loss: 0.2829 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.95108\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3531 - acc: 0.8474 - val_loss: 0.2786 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.95108\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3547 - acc: 0.8448 - val_loss: 0.2733 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.95108\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3463 - acc: 0.8497 - val_loss: 0.2683 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.95108 to 0.95143, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/8/weights-improvement-157-0.9514.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3534 - acc: 0.8468 - val_loss: 0.2833 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95143\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3468 - acc: 0.8500 - val_loss: 0.2635 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95143\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3407 - acc: 0.8569 - val_loss: 0.2597 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.95143\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3443 - acc: 0.8527 - val_loss: 0.2579 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95143\n",
      "Epoch 162/200\n",
      " 13/251 [>.............................] - ETA: 5s - loss: 0.2888 - acc: 0.8860"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5851 - acc: 0.7145 - val_loss: 0.5712 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.76625\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5849 - acc: 0.7138 - val_loss: 0.5668 - val_acc: 0.7530\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.76625\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5837 - acc: 0.7100 - val_loss: 0.5678 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.76625\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5803 - acc: 0.7170 - val_loss: 0.5652 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.76625\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5773 - acc: 0.7188 - val_loss: 0.5628 - val_acc: 0.7631\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.76625\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5760 - acc: 0.7224 - val_loss: 0.5525 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.76625 to 0.76625, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-036-0.7662.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5732 - acc: 0.7213 - val_loss: 0.5507 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.76625 to 0.76730, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-037-0.7673.hdf5\n",
      "Epoch 38/200\n",
      "133/251 [==============>...............] - ETA: 2s - loss: 0.5767 - acc: 0.7173"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5170 - acc: 0.7607 - val_loss: 0.4760 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.85779 to 0.86024, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-061-0.8602.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5121 - acc: 0.7638 - val_loss: 0.4773 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.86024\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5087 - acc: 0.7645 - val_loss: 0.4786 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.86024\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5078 - acc: 0.7627 - val_loss: 0.4688 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.86024 to 0.86338, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-064-0.8634.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5063 - acc: 0.7646 - val_loss: 0.4695 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.86338\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5052 - acc: 0.7661 - val_loss: 0.4616 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.86338 to 0.86618, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-066-0.8662.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5023 - acc: 0.7669 - val_loss: 0.4519 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.86618 to 0.87142, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-067-0.8714.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4957 - acc: 0.7700 - val_loss: 0.4556 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.87142\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5011 - acc: 0.7676 - val_loss: 0.4556 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87142 to 0.87352, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-069-0.8735.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4953 - acc: 0.7704 - val_loss: 0.4459 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.87352 to 0.87561, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-070-0.8756.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4897 - acc: 0.7728 - val_loss: 0.4440 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.87561\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4898 - acc: 0.7734 - val_loss: 0.4493 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.87561\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4859 - acc: 0.7759 - val_loss: 0.4384 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.87561 to 0.87736, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-073-0.8774.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4884 - acc: 0.7732 - val_loss: 0.4433 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.87736 to 0.87771, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-074-0.8777.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4849 - acc: 0.7778 - val_loss: 0.4442 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87771\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4836 - acc: 0.7812 - val_loss: 0.4345 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.87771 to 0.87945, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-076-0.8795.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4841 - acc: 0.7764 - val_loss: 0.4302 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.87945 to 0.88050, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-077-0.8805.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4778 - acc: 0.7776 - val_loss: 0.4227 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.88050 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-078-0.8829.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4741 - acc: 0.7810 - val_loss: 0.4220 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.88295 to 0.88365, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-079-0.8836.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4759 - acc: 0.7787 - val_loss: 0.4241 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.88365\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4721 - acc: 0.7824 - val_loss: 0.4234 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.88365 to 0.88470, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-081-0.8847.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4733 - acc: 0.7845 - val_loss: 0.4253 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.88470 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-082-0.8861.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4636 - acc: 0.7860 - val_loss: 0.4074 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.88609 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-083-0.8878.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4630 - acc: 0.7889 - val_loss: 0.4028 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.88784 to 0.88854, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-084-0.8885.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4629 - acc: 0.7883 - val_loss: 0.4048 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.88854 to 0.89203, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-085-0.8920.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4592 - acc: 0.7907 - val_loss: 0.3993 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.89203 to 0.89343, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-086-0.8934.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4618 - acc: 0.7888 - val_loss: 0.3919 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.89343 to 0.89762, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-087-0.8976.hdf5\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4552 - acc: 0.7901 - val_loss: 0.3964 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.89762\n",
      "Epoch 89/200\n",
      " 91/251 [=========>....................] - ETA: 3s - loss: 0.4641 - acc: 0.7875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3832 - acc: 0.8319 - val_loss: 0.3109 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.92558 to 0.92628, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-135-0.9263.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3867 - acc: 0.8330 - val_loss: 0.3059 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.92628 to 0.92697, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-136-0.9270.hdf5\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3861 - acc: 0.8268 - val_loss: 0.3123 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.92697 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-137-0.9315.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3833 - acc: 0.8323 - val_loss: 0.3083 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.93152\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3760 - acc: 0.8348 - val_loss: 0.3086 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.93152\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3812 - acc: 0.8310 - val_loss: 0.3098 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.93152\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3768 - acc: 0.8353 - val_loss: 0.2980 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.93152\n",
      "Epoch 142/200\n",
      " 70/251 [=======>......................] - ETA: 3s - loss: 0.3749 - acc: 0.8339"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3585 - acc: 0.8440 - val_loss: 0.2813 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00165: val_acc improved from 0.93920 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-165-0.9396.hdf5\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3587 - acc: 0.8429 - val_loss: 0.2737 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.93955 to 0.93990, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-166-0.9399.hdf5\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3564 - acc: 0.8462 - val_loss: 0.2805 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.93990\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3529 - acc: 0.8473 - val_loss: 0.2782 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.93990 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-168-0.9403.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3564 - acc: 0.8505 - val_loss: 0.2877 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.94025\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3553 - acc: 0.8459 - val_loss: 0.2798 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.94025\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3513 - acc: 0.8512 - val_loss: 0.2711 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.94025 to 0.94235, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-171-0.9423.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3459 - acc: 0.8488 - val_loss: 0.2656 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.94235\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3517 - acc: 0.8488 - val_loss: 0.2644 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.94235\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3521 - acc: 0.8466 - val_loss: 0.2706 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.94235 to 0.94444, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/pre_padding/9/weights-improvement-174-0.9444.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3493 - acc: 0.8502 - val_loss: 0.2564 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.94444\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3441 - acc: 0.8512 - val_loss: 0.2605 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.94444\n",
      "Epoch 177/200\n",
      " 49/251 [====>.........................] - ETA: 4s - loss: 0.2788 - acc: 0.8874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3303 - acc: 0.8611 - val_loss: 0.2283 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.95038\n",
      "It has been  0:19:19.749716\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_22 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 1000, 26)     0           input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_106 (Conv1D)             (None, 1000, 10)     270         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_107 (Conv1D)             (None, 1000, 10)     790         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_108 (Conv1D)             (None, 1000, 10)     1310        dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_109 (Conv1D)             (None, 1000, 10)     2350        dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_110 (Conv1D)             (None, 1000, 10)     3910        dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 5000, 10)     0           conv1d_106[0][0]                 \n",
      "                                                                 conv1d_107[0][0]                 \n",
      "                                                                 conv1d_108[0][0]                 \n",
      "                                                                 conv1d_109[0][0]                 \n",
      "                                                                 conv1d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 500, 10)      0           concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 500, 314)     3454        max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 500, 314)     0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 500, 77)      24255       dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 500, 77)      0           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 500, 8)       624         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 500, 8)       0           dense_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)            (None, 4000)         0           dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 2)            8002        flatten_22[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 8s 32ms/step - loss: 0.6769 - acc: 0.6173 - val_loss: 0.6816 - val_acc: 0.8001\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.80014, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-001-0.8001.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6560 - acc: 0.6386 - val_loss: 0.6644 - val_acc: 0.7575\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.80014\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6476 - acc: 0.6671 - val_loss: 0.6489 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.80014\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6364 - acc: 0.6799 - val_loss: 0.6316 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.80014\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6293 - acc: 0.6912 - val_loss: 0.6178 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80014\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6260 - acc: 0.6901 - val_loss: 0.6127 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80014\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6220 - acc: 0.6941 - val_loss: 0.6076 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80014\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6190 - acc: 0.6952 - val_loss: 0.6032 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80014\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6189 - acc: 0.6943 - val_loss: 0.6007 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80014\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6170 - acc: 0.6945 - val_loss: 0.5983 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80014\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6150 - acc: 0.6973 - val_loss: 0.5971 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80014\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6129 - acc: 0.6971 - val_loss: 0.5939 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80014\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6094 - acc: 0.6999 - val_loss: 0.5895 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80014\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6100 - acc: 0.7020 - val_loss: 0.5900 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80014\n",
      "Epoch 15/200\n",
      "241/251 [===========================>..] - ETA: 0s - loss: 0.6033 - acc: 0.7049"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4806 - acc: 0.7760 - val_loss: 0.3929 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.87666 to 0.87876, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-061-0.8788.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4757 - acc: 0.7779 - val_loss: 0.3738 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.87876 to 0.87980, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-062-0.8798.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4721 - acc: 0.7837 - val_loss: 0.3773 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87980 to 0.88190, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-063-0.8819.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4717 - acc: 0.7837 - val_loss: 0.3768 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.88190 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-064-0.8850.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4735 - acc: 0.7818 - val_loss: 0.3776 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.88505\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4693 - acc: 0.7850 - val_loss: 0.3706 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.88505 to 0.88819, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-066-0.8882.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4631 - acc: 0.7891 - val_loss: 0.3748 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.88819\n",
      "Epoch 68/200\n",
      "214/251 [========================>.....] - ETA: 0s - loss: 0.4239 - acc: 0.8093"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4101 - acc: 0.8147 - val_loss: 0.3038 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.91370 to 0.91789, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-091-0.9179.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4026 - acc: 0.8248 - val_loss: 0.2974 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.91789\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4053 - acc: 0.8187 - val_loss: 0.2851 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.91789\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3996 - acc: 0.8206 - val_loss: 0.2967 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.91789 to 0.91859, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-094-0.9186.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3995 - acc: 0.8210 - val_loss: 0.2785 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.91859\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3946 - acc: 0.8250 - val_loss: 0.2723 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.91859\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3949 - acc: 0.8246 - val_loss: 0.2867 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.91859 to 0.92243, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-097-0.9224.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3864 - acc: 0.8304 - val_loss: 0.2689 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.92243\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3923 - acc: 0.8227 - val_loss: 0.2760 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.92243 to 0.92453, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-099-0.9245.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3912 - acc: 0.8263 - val_loss: 0.2738 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.92453\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3867 - acc: 0.8264 - val_loss: 0.2754 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.92453 to 0.92523, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-101-0.9252.hdf5\n",
      "Epoch 102/200\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.3755 - acc: 0.8362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3436 - acc: 0.8524 - val_loss: 0.2318 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.94095\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3409 - acc: 0.8540 - val_loss: 0.2261 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.94095 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-127-0.9458.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3494 - acc: 0.8490 - val_loss: 0.2276 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.94584 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-128-0.9479.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3418 - acc: 0.8538 - val_loss: 0.2265 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.94794\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3444 - acc: 0.8496 - val_loss: 0.2274 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.94794 to 0.94969, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-130-0.9497.hdf5\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3432 - acc: 0.8495 - val_loss: 0.2303 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.94969\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3388 - acc: 0.8561 - val_loss: 0.2204 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.94969\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3380 - acc: 0.8552 - val_loss: 0.2254 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94969\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3389 - acc: 0.8547 - val_loss: 0.2227 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.94969\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3391 - acc: 0.8525 - val_loss: 0.2232 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.94969\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3305 - acc: 0.8589 - val_loss: 0.2161 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.94969 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-136-0.9504.hdf5\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3361 - acc: 0.8559 - val_loss: 0.2174 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.95038 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-137-0.9507.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3354 - acc: 0.8578 - val_loss: 0.2165 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95073\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3351 - acc: 0.8539 - val_loss: 0.2093 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95073\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3222 - acc: 0.8604 - val_loss: 0.2042 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.95073 to 0.95353, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-140-0.9535.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3225 - acc: 0.8622 - val_loss: 0.2189 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.95353 to 0.95458, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-141-0.9546.hdf5\n",
      "Epoch 142/200\n",
      " 43/251 [====>.........................] - ETA: 4s - loss: 0.2515 - acc: 0.8953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2949 - acc: 0.8740 - val_loss: 0.1838 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96820\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2865 - acc: 0.8809 - val_loss: 0.1779 - val_acc: 0.9689\n",
      "\n",
      "Epoch 00187: val_acc improved from 0.96820 to 0.96890, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/0/weights-improvement-187-0.9689.hdf5\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2856 - acc: 0.8792 - val_loss: 0.1708 - val_acc: 0.9682\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.96890\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2844 - acc: 0.8804 - val_loss: 0.1709 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.96890\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2922 - acc: 0.8766 - val_loss: 0.1847 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.96890\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2888 - acc: 0.8783 - val_loss: 0.1838 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96890\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2895 - acc: 0.8767 - val_loss: 0.1889 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.96890\n",
      "Epoch 193/200\n",
      "250/251 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.8781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6089 - acc: 0.7016 - val_loss: 0.5921 - val_acc: 0.7397\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75297\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6052 - acc: 0.7020 - val_loss: 0.5895 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75297\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6045 - acc: 0.7016 - val_loss: 0.5876 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75297\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6006 - acc: 0.7041 - val_loss: 0.5860 - val_acc: 0.7393\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75297\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6003 - acc: 0.7058 - val_loss: 0.5848 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.75297\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5991 - acc: 0.7056 - val_loss: 0.5822 - val_acc: 0.7432\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.75297\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5954 - acc: 0.7078 - val_loss: 0.5810 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.75297\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5913 - acc: 0.7098 - val_loss: 0.5758 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.75297\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5882 - acc: 0.7151 - val_loss: 0.5716 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.75297\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5853 - acc: 0.7152 - val_loss: 0.5683 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.75297\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5820 - acc: 0.7188 - val_loss: 0.5643 - val_acc: 0.7551\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.75297 to 0.75507, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-026-0.7551.hdf5\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5794 - acc: 0.7207 - val_loss: 0.5585 - val_acc: 0.7575\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.75507 to 0.75751, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-027-0.7575.hdf5\n",
      "Epoch 28/200\n",
      "163/251 [==================>...........] - ETA: 1s - loss: 0.5707 - acc: 0.7262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5177 - acc: 0.7568 - val_loss: 0.4611 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86408\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5134 - acc: 0.7619 - val_loss: 0.4545 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.86408 to 0.86618, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-052-0.8662.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5112 - acc: 0.7630 - val_loss: 0.4511 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.86618 to 0.86827, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-053-0.8683.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5076 - acc: 0.7624 - val_loss: 0.4450 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.86827 to 0.87072, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-054-0.8707.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5066 - acc: 0.7623 - val_loss: 0.4456 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.87072 to 0.87421, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-055-0.8742.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5048 - acc: 0.7632 - val_loss: 0.4424 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.87421 to 0.87666, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-056-0.8767.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4977 - acc: 0.7700 - val_loss: 0.4362 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.87666\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5012 - acc: 0.7694 - val_loss: 0.4376 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.87666 to 0.87771, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-058-0.8777.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4979 - acc: 0.7666 - val_loss: 0.4298 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.87771 to 0.88085, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-059-0.8809.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4965 - acc: 0.7683 - val_loss: 0.4329 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.88085 to 0.88120, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-060-0.8812.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4919 - acc: 0.7719 - val_loss: 0.4285 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.88120 to 0.88330, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-061-0.8833.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4883 - acc: 0.7751 - val_loss: 0.4344 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.88330\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4878 - acc: 0.7695 - val_loss: 0.4230 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.88330 to 0.88714, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-063-0.8871.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4885 - acc: 0.7742 - val_loss: 0.4172 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.88714\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4849 - acc: 0.7760 - val_loss: 0.4157 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.88714 to 0.88749, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-065-0.8875.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4801 - acc: 0.7792 - val_loss: 0.4108 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.88749 to 0.88994, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-066-0.8899.hdf5\n",
      "Epoch 67/200\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.4335 - acc: 0.8044"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3919 - acc: 0.8246 - val_loss: 0.2822 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.91020\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3974 - acc: 0.8246 - val_loss: 0.2885 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.91020 to 0.91020, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-114-0.9102.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3907 - acc: 0.8290 - val_loss: 0.2844 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.91020\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3935 - acc: 0.8293 - val_loss: 0.2784 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.91020\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3881 - acc: 0.8291 - val_loss: 0.2721 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.91020 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-117-0.9116.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3905 - acc: 0.8274 - val_loss: 0.2903 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.91160\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3856 - acc: 0.8319 - val_loss: 0.2756 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.91160\n",
      "Epoch 120/200\n",
      "184/251 [====================>.........] - ETA: 1s - loss: 0.3767 - acc: 0.8371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3611 - acc: 0.8459 - val_loss: 0.2459 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.92558\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3528 - acc: 0.8483 - val_loss: 0.2358 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.92558\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3498 - acc: 0.8455 - val_loss: 0.2390 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.92558\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3526 - acc: 0.8473 - val_loss: 0.2315 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.92558\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3532 - acc: 0.8483 - val_loss: 0.2339 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.92558\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3494 - acc: 0.8468 - val_loss: 0.2329 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.92558\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3527 - acc: 0.8487 - val_loss: 0.2343 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.92558 to 0.92802, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-148-0.9280.hdf5\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3454 - acc: 0.8496 - val_loss: 0.2184 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.92802\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3463 - acc: 0.8496 - val_loss: 0.2189 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.92802\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3523 - acc: 0.8468 - val_loss: 0.2309 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.92802 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-151-0.9287.hdf5\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3483 - acc: 0.8526 - val_loss: 0.2263 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.92872\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3486 - acc: 0.8503 - val_loss: 0.2298 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.92872\n",
      "Epoch 154/200\n",
      "172/251 [===================>..........] - ETA: 1s - loss: 0.3387 - acc: 0.8550"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3266 - acc: 0.8600 - val_loss: 0.1994 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.93850 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-178-0.9416.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3233 - acc: 0.8575 - val_loss: 0.1971 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.94165\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3238 - acc: 0.8629 - val_loss: 0.1960 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.94165\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3206 - acc: 0.8655 - val_loss: 0.2017 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.94165\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3262 - acc: 0.8600 - val_loss: 0.2078 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.94165\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3205 - acc: 0.8640 - val_loss: 0.1927 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.94165\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3179 - acc: 0.8642 - val_loss: 0.1931 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.94165\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3186 - acc: 0.8611 - val_loss: 0.1916 - val_acc: 0.9410\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.94165\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3129 - acc: 0.8660 - val_loss: 0.1868 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.94165\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3211 - acc: 0.8641 - val_loss: 0.1953 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.94165\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3124 - acc: 0.8677 - val_loss: 0.1911 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00188: val_acc improved from 0.94165 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-188-0.9430.hdf5\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3151 - acc: 0.8651 - val_loss: 0.1919 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.94305\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3187 - acc: 0.8662 - val_loss: 0.1845 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.94305 to 0.94514, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/1/weights-improvement-190-0.9451.hdf5\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3102 - acc: 0.8694 - val_loss: 0.1928 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.94514\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3179 - acc: 0.8656 - val_loss: 0.1924 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.94514\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3100 - acc: 0.8678 - val_loss: 0.1909 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.94514\n",
      "Epoch 194/200\n",
      "112/251 [============>.................] - ETA: 2s - loss: 0.3333 - acc: 0.8583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5516 - acc: 0.7390 - val_loss: 0.5296 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.79665 to 0.80468, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-038-0.8047.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5509 - acc: 0.7382 - val_loss: 0.5295 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.80468 to 0.80468, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-039-0.8047.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5461 - acc: 0.7406 - val_loss: 0.5257 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.80468 to 0.81761, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-040-0.8176.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5432 - acc: 0.7427 - val_loss: 0.5183 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.81761 to 0.82355, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-041-0.8235.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5377 - acc: 0.7466 - val_loss: 0.5112 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.82355 to 0.82774, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-042-0.8277.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5350 - acc: 0.7497 - val_loss: 0.5064 - val_acc: 0.8312\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.82774 to 0.83124, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-043-0.8312.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5325 - acc: 0.7474 - val_loss: 0.5068 - val_acc: 0.8375\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.83124 to 0.83753, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-044-0.8375.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5288 - acc: 0.7534 - val_loss: 0.5043 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.83753 to 0.84416, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-045-0.8442.hdf5\n",
      "Epoch 46/200\n",
      "  1/251 [..............................] - ETA: 4s - loss: 0.5582 - acc: 0.6667"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4765 - acc: 0.7802 - val_loss: 0.4233 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.88050 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-068-0.8829.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4701 - acc: 0.7864 - val_loss: 0.4189 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.88295 to 0.88400, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-069-0.8840.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4670 - acc: 0.7859 - val_loss: 0.4112 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.88400 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-070-0.8850.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4656 - acc: 0.7873 - val_loss: 0.4023 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.88505 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-071-0.8861.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4596 - acc: 0.7918 - val_loss: 0.4043 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.88609 to 0.88819, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-072-0.8882.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4627 - acc: 0.7914 - val_loss: 0.4052 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88819\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4520 - acc: 0.7948 - val_loss: 0.3968 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88819\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4527 - acc: 0.7973 - val_loss: 0.3934 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.88819 to 0.88854, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-075-0.8885.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4526 - acc: 0.7914 - val_loss: 0.3946 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.88854 to 0.88994, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-076-0.8899.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4482 - acc: 0.7975 - val_loss: 0.3850 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.88994 to 0.89308, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-077-0.8931.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4494 - acc: 0.7935 - val_loss: 0.3908 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.89308\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4516 - acc: 0.7928 - val_loss: 0.3938 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89308 to 0.89413, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-079-0.8941.hdf5\n",
      "Epoch 80/200\n",
      " 13/251 [>.............................] - ETA: 4s - loss: 0.3450 - acc: 0.8575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4002 - acc: 0.8238 - val_loss: 0.3366 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.90950\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4033 - acc: 0.8236 - val_loss: 0.3276 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.90950 to 0.91370, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-104-0.9137.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3964 - acc: 0.8263 - val_loss: 0.3257 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.91370 to 0.91370, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-105-0.9137.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3922 - acc: 0.8279 - val_loss: 0.3229 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.91370\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3930 - acc: 0.8278 - val_loss: 0.3236 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.91370 to 0.91894, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-107-0.9189.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3906 - acc: 0.8305 - val_loss: 0.3249 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.91894\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3901 - acc: 0.8285 - val_loss: 0.3252 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.91894\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3919 - acc: 0.8286 - val_loss: 0.3262 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.91894\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3830 - acc: 0.8314 - val_loss: 0.3128 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.91894\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3879 - acc: 0.8282 - val_loss: 0.3198 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.91894\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3830 - acc: 0.8342 - val_loss: 0.3157 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.91894\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3827 - acc: 0.8316 - val_loss: 0.3050 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.91894 to 0.92103, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-114-0.9210.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3819 - acc: 0.8331 - val_loss: 0.3204 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.92103\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 22ms/step - loss: 0.3810 - acc: 0.8334 - val_loss: 0.3024 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.92103 to 0.92523, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-116-0.9252.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3842 - acc: 0.8314 - val_loss: 0.3204 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.92523\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3766 - acc: 0.8364 - val_loss: 0.3053 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.92523\n",
      "Epoch 119/200\n",
      "154/251 [=================>............] - ETA: 2s - loss: 0.3575 - acc: 0.8426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3369 - acc: 0.8559 - val_loss: 0.2487 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.94829 to 0.94864, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-164-0.9486.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3266 - acc: 0.8629 - val_loss: 0.2515 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.94864\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3361 - acc: 0.8583 - val_loss: 0.2567 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.94864\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3306 - acc: 0.8598 - val_loss: 0.2400 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.94864\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3260 - acc: 0.8606 - val_loss: 0.2416 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.94864 to 0.95108, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-168-0.9511.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3322 - acc: 0.8570 - val_loss: 0.2484 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95108\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3290 - acc: 0.8633 - val_loss: 0.2459 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00170: val_acc improved from 0.95108 to 0.95213, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-170-0.9521.hdf5\n",
      "Epoch 171/200\n",
      "163/251 [==================>...........] - ETA: 1s - loss: 0.3127 - acc: 0.8639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3140 - acc: 0.8668 - val_loss: 0.2241 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00195: val_acc improved from 0.95912 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-195-0.9595.hdf5\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3075 - acc: 0.8713 - val_loss: 0.2199 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.95947\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3157 - acc: 0.8673 - val_loss: 0.2344 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95947\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3152 - acc: 0.8673 - val_loss: 0.2257 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.95947 to 0.96052, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/2/weights-improvement-198-0.9605.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3172 - acc: 0.8664 - val_loss: 0.2345 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.96052\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3075 - acc: 0.8695 - val_loss: 0.2288 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.96052\n",
      "It has been  0:19:04.676589\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 1000, 26)     0           input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_121 (Conv1D)             (None, 1000, 10)     270         dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_122 (Conv1D)             (None, 1000, 10)     790         dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_123 (Conv1D)             (None, 1000, 10)     1310        dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_124 (Conv1D)             (None, 1000, 10)     2350        dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_125 (Conv1D)             (None, 1000, 10)     3910        dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 5000, 10)     0           conv1d_121[0][0]                 \n",
      "                                                                 conv1d_122[0][0]                 \n",
      "                                                                 conv1d_123[0][0]                 \n",
      "                                                                 conv1d_124[0][0]                 \n",
      "                                                                 conv1d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 500, 10)      0           concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 500, 314)     3454        max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 500, 314)     0           dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 500, 77)      24255       dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 500, 77)      0           dense_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 500, 8)       624         dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 500, 8)       0           dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 4000)         0           dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 2)            8002        flatten_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 8s 34ms/step - loss: 0.6832 - acc: 0.6079 - val_loss: 0.6926 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70894, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-001-0.7089.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6713 - acc: 0.5967 - val_loss: 0.6859 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70894 to 0.75996, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-002-0.7600.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6591 - acc: 0.6429 - val_loss: 0.6746 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75996\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6467 - acc: 0.6775 - val_loss: 0.6590 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75996\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6358 - acc: 0.6860 - val_loss: 0.6449 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75996\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6304 - acc: 0.6895 - val_loss: 0.6346 - val_acc: 0.7264\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75996\n",
      "Epoch 7/200\n",
      " 37/251 [===>..........................] - ETA: 4s - loss: 0.5795 - acc: 0.7673"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5757 - acc: 0.7249 - val_loss: 0.5534 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.76799\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5753 - acc: 0.7196 - val_loss: 0.5506 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.76799 to 0.77219, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-030-0.7722.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5721 - acc: 0.7278 - val_loss: 0.5478 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.77219 to 0.77918, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-031-0.7792.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5673 - acc: 0.7294 - val_loss: 0.5401 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.77918 to 0.78686, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-032-0.7869.hdf5\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5644 - acc: 0.7316 - val_loss: 0.5380 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.78686 to 0.79036, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-033-0.7904.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5626 - acc: 0.7311 - val_loss: 0.5357 - val_acc: 0.7959\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.79036 to 0.79595, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-034-0.7959.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5583 - acc: 0.7337 - val_loss: 0.5274 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.79595 to 0.80189, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-035-0.8019.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5567 - acc: 0.7359 - val_loss: 0.5245 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.80189 to 0.81412, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-036-0.8141.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5547 - acc: 0.7382 - val_loss: 0.5237 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.81412 to 0.81586, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-037-0.8159.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5507 - acc: 0.7393 - val_loss: 0.5153 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.81586 to 0.82041, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-038-0.8204.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5486 - acc: 0.7424 - val_loss: 0.5181 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.82041 to 0.82215, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-039-0.8222.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5444 - acc: 0.7447 - val_loss: 0.5093 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.82215 to 0.82635, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-040-0.8263.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5429 - acc: 0.7418 - val_loss: 0.5067 - val_acc: 0.8284\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.82635 to 0.82844, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-041-0.8284.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5401 - acc: 0.7477 - val_loss: 0.4995 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.82844 to 0.83194, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-042-0.8319.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5353 - acc: 0.7480 - val_loss: 0.4938 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83194 to 0.83403, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-043-0.8340.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5350 - acc: 0.7487 - val_loss: 0.4917 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.83403 to 0.83613, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-044-0.8361.hdf5\n",
      "Epoch 45/200\n",
      "208/251 [=======================>......] - ETA: 0s - loss: 0.5040 - acc: 0.7689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4369 - acc: 0.8001 - val_loss: 0.3228 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.91125\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4302 - acc: 0.8066 - val_loss: 0.3167 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.91125 to 0.91335, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-092-0.9133.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4377 - acc: 0.8025 - val_loss: 0.3140 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.91335 to 0.91474, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-093-0.9147.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4301 - acc: 0.8058 - val_loss: 0.3134 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.91474\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4268 - acc: 0.8065 - val_loss: 0.3099 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.91474 to 0.91719, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-095-0.9172.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4244 - acc: 0.8111 - val_loss: 0.3067 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.91719 to 0.91824, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-096-0.9182.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4225 - acc: 0.8097 - val_loss: 0.2954 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.91824\n",
      "Epoch 98/200\n",
      " 82/251 [========>.....................] - ETA: 3s - loss: 0.4055 - acc: 0.8119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3895 - acc: 0.8296 - val_loss: 0.2498 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93850\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3896 - acc: 0.8267 - val_loss: 0.2500 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.93850 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-122-0.9396.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3841 - acc: 0.8287 - val_loss: 0.2409 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.93955 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-123-0.9413.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3821 - acc: 0.8316 - val_loss: 0.2393 - val_acc: 0.9416\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.94130 to 0.94165, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-124-0.9416.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3849 - acc: 0.8326 - val_loss: 0.2489 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.94165 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-125-0.9420.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3832 - acc: 0.8300 - val_loss: 0.2471 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.94200 to 0.94340, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-126-0.9434.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3774 - acc: 0.8356 - val_loss: 0.2351 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.94340\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3770 - acc: 0.8324 - val_loss: 0.2425 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.94340\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3776 - acc: 0.8313 - val_loss: 0.2326 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.94340 to 0.94479, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-129-0.9448.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3827 - acc: 0.8306 - val_loss: 0.2389 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.94479 to 0.94549, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-130-0.9455.hdf5\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3749 - acc: 0.8363 - val_loss: 0.2357 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.94549 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-131-0.9458.hdf5\n",
      "Epoch 132/200\n",
      "214/251 [========================>.....] - ETA: 0s - loss: 0.3417 - acc: 0.8476"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3464 - acc: 0.8492 - val_loss: 0.2009 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.95213 to 0.95458, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-156-0.9546.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3497 - acc: 0.8483 - val_loss: 0.2015 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.95458\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3459 - acc: 0.8469 - val_loss: 0.2055 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95458\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3401 - acc: 0.8537 - val_loss: 0.2079 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95458\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3459 - acc: 0.8527 - val_loss: 0.1918 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.95458 to 0.95563, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-160-0.9556.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3419 - acc: 0.8502 - val_loss: 0.2009 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95563\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3437 - acc: 0.8505 - val_loss: 0.1943 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.95563 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-162-0.9560.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3376 - acc: 0.8542 - val_loss: 0.1990 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95597\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3373 - acc: 0.8537 - val_loss: 0.1979 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.95597\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3326 - acc: 0.8577 - val_loss: 0.1916 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.95597\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3455 - acc: 0.8510 - val_loss: 0.1921 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.95597\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3381 - acc: 0.8545 - val_loss: 0.1876 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.95597 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/3/weights-improvement-167-0.9560.hdf5\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3381 - acc: 0.8519 - val_loss: 0.1877 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95597\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3351 - acc: 0.8577 - val_loss: 0.1891 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.95597\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3411 - acc: 0.8503 - val_loss: 0.1927 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95597\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3377 - acc: 0.8541 - val_loss: 0.1992 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95597\n",
      "Epoch 172/200\n",
      " 79/251 [========>.....................] - ETA: 3s - loss: 0.3109 - acc: 0.8586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6086 - acc: 0.7033 - val_loss: 0.6066 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.79944\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6079 - acc: 0.7023 - val_loss: 0.6066 - val_acc: 0.7145\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79944\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6067 - acc: 0.7055 - val_loss: 0.6025 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.79944\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6042 - acc: 0.7068 - val_loss: 0.6011 - val_acc: 0.7219\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.79944\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6026 - acc: 0.7037 - val_loss: 0.5979 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.79944\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6022 - acc: 0.7071 - val_loss: 0.5935 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79944\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5984 - acc: 0.7071 - val_loss: 0.5935 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79944\n",
      "Epoch 23/200\n",
      "157/251 [=================>............] - ETA: 2s - loss: 0.5978 - acc: 0.7059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5179 - acc: 0.7569 - val_loss: 0.4789 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.84382 to 0.85010, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-047-0.8501.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5159 - acc: 0.7593 - val_loss: 0.4726 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.85010\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5127 - acc: 0.7593 - val_loss: 0.4702 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.85010 to 0.85744, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-049-0.8574.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5157 - acc: 0.7601 - val_loss: 0.4706 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.85744\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5044 - acc: 0.7639 - val_loss: 0.4617 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00051: val_acc improved from 0.85744 to 0.86198, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-051-0.8620.hdf5\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5051 - acc: 0.7643 - val_loss: 0.4598 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.86198 to 0.86723, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-052-0.8672.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5010 - acc: 0.7697 - val_loss: 0.4502 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.86723 to 0.87142, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-053-0.8714.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4982 - acc: 0.7688 - val_loss: 0.4464 - val_acc: 0.8760\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.87142 to 0.87596, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-054-0.8760.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4942 - acc: 0.7697 - val_loss: 0.4425 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.87596 to 0.87666, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-055-0.8767.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4895 - acc: 0.7736 - val_loss: 0.4329 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00056: val_acc improved from 0.87666 to 0.87876, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-056-0.8788.hdf5\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4882 - acc: 0.7752 - val_loss: 0.4366 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.87876 to 0.88400, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-057-0.8840.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4869 - acc: 0.7781 - val_loss: 0.4248 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.88400\n",
      "Epoch 59/200\n",
      " 52/251 [=====>........................] - ETA: 4s - loss: 0.4077 - acc: 0.8301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4330 - acc: 0.8059 - val_loss: 0.3460 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.92103 to 0.92488, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-081-0.9249.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4247 - acc: 0.8108 - val_loss: 0.3283 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.92488\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4235 - acc: 0.8085 - val_loss: 0.3300 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.92488\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4218 - acc: 0.8107 - val_loss: 0.3221 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.92488 to 0.92662, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-084-0.9266.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4194 - acc: 0.8125 - val_loss: 0.3234 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.92662 to 0.92907, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-085-0.9291.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4131 - acc: 0.8164 - val_loss: 0.3117 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.92907\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4163 - acc: 0.8113 - val_loss: 0.3095 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.92907 to 0.92942, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-087-0.9294.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4114 - acc: 0.8180 - val_loss: 0.3065 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.92942 to 0.93082, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-088-0.9308.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4099 - acc: 0.8157 - val_loss: 0.3084 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.93082 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-089-0.9315.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4124 - acc: 0.8189 - val_loss: 0.2979 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93152\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4099 - acc: 0.8170 - val_loss: 0.3027 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.93152\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4108 - acc: 0.8204 - val_loss: 0.2902 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.93152\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4026 - acc: 0.8223 - val_loss: 0.2833 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.93152 to 0.93256, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-093-0.9326.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3941 - acc: 0.8263 - val_loss: 0.2837 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.93256 to 0.93676, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-094-0.9368.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4032 - acc: 0.8231 - val_loss: 0.2967 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93676\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4023 - acc: 0.8229 - val_loss: 0.2934 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.93676 to 0.93746, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-096-0.9375.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3984 - acc: 0.8238 - val_loss: 0.2917 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.93746 to 0.93746, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-097-0.9375.hdf5\n",
      "Epoch 98/200\n",
      "  7/251 [..............................] - ETA: 5s - loss: 0.2397 - acc: 0.9206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3367 - acc: 0.8565 - val_loss: 0.2152 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.96017 to 0.96122, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-143-0.9612.hdf5\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3347 - acc: 0.8583 - val_loss: 0.2187 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.96122\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3425 - acc: 0.8548 - val_loss: 0.2274 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.96122\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3354 - acc: 0.8590 - val_loss: 0.2133 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.96122\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3460 - acc: 0.8496 - val_loss: 0.2151 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.96122 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-147-0.9619.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3383 - acc: 0.8578 - val_loss: 0.2193 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.96191\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3367 - acc: 0.8567 - val_loss: 0.2108 - val_acc: 0.9647\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.96191 to 0.96471, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-149-0.9647.hdf5\n",
      "Epoch 150/200\n",
      " 61/251 [======>.......................] - ETA: 4s - loss: 0.2789 - acc: 0.8907"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3129 - acc: 0.8663 - val_loss: 0.1849 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.97030 to 0.97135, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-174-0.9713.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3204 - acc: 0.8661 - val_loss: 0.1994 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.97135\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3161 - acc: 0.8670 - val_loss: 0.1869 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.97135\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3096 - acc: 0.8687 - val_loss: 0.1792 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.97135 to 0.97240, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-177-0.9724.hdf5\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3070 - acc: 0.8699 - val_loss: 0.1764 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.97240\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3165 - acc: 0.8637 - val_loss: 0.1863 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.97240\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3103 - acc: 0.8669 - val_loss: 0.1796 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.97240\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3100 - acc: 0.8684 - val_loss: 0.1809 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.97240 to 0.97275, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-181-0.9727.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3108 - acc: 0.8699 - val_loss: 0.1695 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.97275 to 0.97379, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/4/weights-improvement-182-0.9738.hdf5\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3040 - acc: 0.8702 - val_loss: 0.1712 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.97379\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3086 - acc: 0.8715 - val_loss: 0.1805 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.97379\n",
      "Epoch 185/200\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.3055 - acc: 0.8716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6191 - acc: 0.6984 - val_loss: 0.6363 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74668\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6170 - acc: 0.7001 - val_loss: 0.6336 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.74668\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6178 - acc: 0.6961 - val_loss: 0.6321 - val_acc: 0.6943\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.74668\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6150 - acc: 0.6977 - val_loss: 0.6314 - val_acc: 0.6922\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.74668\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6146 - acc: 0.6988 - val_loss: 0.6284 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.74668\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6121 - acc: 0.7002 - val_loss: 0.6242 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.74668\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6107 - acc: 0.7019 - val_loss: 0.6219 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.74668\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6087 - acc: 0.7024 - val_loss: 0.6190 - val_acc: 0.7023\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.74668\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6071 - acc: 0.7033 - val_loss: 0.6177 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.74668\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6041 - acc: 0.7041 - val_loss: 0.6157 - val_acc: 0.7065\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.74668\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6025 - acc: 0.7053 - val_loss: 0.6122 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74668\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5998 - acc: 0.7061 - val_loss: 0.6086 - val_acc: 0.7124\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.74668\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5988 - acc: 0.7095 - val_loss: 0.6060 - val_acc: 0.7166\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.74668\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5971 - acc: 0.7106 - val_loss: 0.6014 - val_acc: 0.7250\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.74668\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5947 - acc: 0.7134 - val_loss: 0.5966 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.74668\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5905 - acc: 0.7164 - val_loss: 0.5936 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.74668\n",
      "Epoch 24/200\n",
      " 52/251 [=====>........................] - ETA: 4s - loss: 0.5141 - acc: 0.7838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4516 - acc: 0.7947 - val_loss: 0.3439 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.88644 to 0.88714, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-068-0.8871.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4512 - acc: 0.7911 - val_loss: 0.3407 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.88714 to 0.89064, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-069-0.8906.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4501 - acc: 0.7981 - val_loss: 0.3399 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.89064 to 0.89238, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-070-0.8924.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4463 - acc: 0.7997 - val_loss: 0.3384 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.89238 to 0.89343, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-071-0.8934.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4430 - acc: 0.7947 - val_loss: 0.3294 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.89343\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4445 - acc: 0.7986 - val_loss: 0.3327 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.89343\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4380 - acc: 0.8019 - val_loss: 0.3252 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.89343 to 0.89518, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-074-0.8952.hdf5\n",
      "Epoch 75/200\n",
      "244/251 [============================>.] - ETA: 0s - loss: 0.4442 - acc: 0.7971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3917 - acc: 0.8254 - val_loss: 0.2597 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.92697\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3915 - acc: 0.8265 - val_loss: 0.2692 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.92697 to 0.92837, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-100-0.9284.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3927 - acc: 0.8252 - val_loss: 0.2588 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.92837 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-101-0.9287.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3895 - acc: 0.8296 - val_loss: 0.2577 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.92872 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-102-0.9287.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3877 - acc: 0.8254 - val_loss: 0.2549 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.92872 to 0.92907, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-103-0.9291.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3848 - acc: 0.8310 - val_loss: 0.2591 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.92907 to 0.93291, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-104-0.9329.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3905 - acc: 0.8271 - val_loss: 0.2640 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93291\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3860 - acc: 0.8310 - val_loss: 0.2496 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.93291 to 0.93396, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-106-0.9340.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3826 - acc: 0.8358 - val_loss: 0.2535 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.93396 to 0.93606, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-107-0.9361.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3829 - acc: 0.8311 - val_loss: 0.2535 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93606\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3783 - acc: 0.8381 - val_loss: 0.2445 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93606\n",
      "Epoch 110/200\n",
      "175/251 [===================>..........] - ETA: 1s - loss: 0.3610 - acc: 0.8420"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3436 - acc: 0.8514 - val_loss: 0.2102 - val_acc: 0.9448\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.94934\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3499 - acc: 0.8471 - val_loss: 0.2135 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.94934\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3505 - acc: 0.8496 - val_loss: 0.2141 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.94934 to 0.94969, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-134-0.9497.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3523 - acc: 0.8475 - val_loss: 0.2164 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.94969\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3458 - acc: 0.8489 - val_loss: 0.2119 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.94969\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3427 - acc: 0.8519 - val_loss: 0.2089 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.94969 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-137-0.9504.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3490 - acc: 0.8485 - val_loss: 0.2127 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95038\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3450 - acc: 0.8500 - val_loss: 0.2044 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95038\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3404 - acc: 0.8548 - val_loss: 0.2054 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00140: val_acc improved from 0.95038 to 0.95038, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-140-0.9504.hdf5\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3397 - acc: 0.8547 - val_loss: 0.2053 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.95038 to 0.95143, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-141-0.9514.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3483 - acc: 0.8499 - val_loss: 0.2103 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.95143 to 0.95423, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-142-0.9542.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3408 - acc: 0.8539 - val_loss: 0.2003 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95423\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3401 - acc: 0.8552 - val_loss: 0.2056 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95423\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3372 - acc: 0.8556 - val_loss: 0.2033 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95423\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3354 - acc: 0.8572 - val_loss: 0.1948 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.95423 to 0.95423, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-146-0.9542.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3356 - acc: 0.8581 - val_loss: 0.1961 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.95423 to 0.95632, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-147-0.9563.hdf5\n",
      "Epoch 148/200\n",
      "223/251 [=========================>....] - ETA: 0s - loss: 0.3019 - acc: 0.8719"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3074 - acc: 0.8687 - val_loss: 0.1617 - val_acc: 0.9640\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.96506\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3040 - acc: 0.8705 - val_loss: 0.1565 - val_acc: 0.9651\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.96506 to 0.96506, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-194-0.9651.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3039 - acc: 0.8721 - val_loss: 0.1600 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00195: val_acc improved from 0.96506 to 0.96611, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-195-0.9661.hdf5\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.2999 - acc: 0.8721 - val_loss: 0.1593 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.96611 to 0.96646, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-196-0.9665.hdf5\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3050 - acc: 0.8732 - val_loss: 0.1595 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.96646\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3012 - acc: 0.8715 - val_loss: 0.1586 - val_acc: 0.9665\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.96646\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3036 - acc: 0.8747 - val_loss: 0.1605 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.96646 to 0.96785, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/5/weights-improvement-199-0.9679.hdf5\n",
      "Epoch 200/200\n",
      "160/251 [==================>...........] - ETA: 2s - loss: 0.2823 - acc: 0.8823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5936 - acc: 0.7106 - val_loss: 0.5689 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.76275\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5905 - acc: 0.7109 - val_loss: 0.5641 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.76275\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5887 - acc: 0.7089 - val_loss: 0.5616 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.76275\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5829 - acc: 0.7187 - val_loss: 0.5555 - val_acc: 0.7628\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.76275\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5786 - acc: 0.7189 - val_loss: 0.5499 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.76275 to 0.76730, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-027-0.7673.hdf5\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5778 - acc: 0.7185 - val_loss: 0.5478 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.76730 to 0.77044, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-028-0.7704.hdf5\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5742 - acc: 0.7196 - val_loss: 0.5431 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.77044 to 0.77952, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-029-0.7795.hdf5\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5729 - acc: 0.7192 - val_loss: 0.5436 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.77952 to 0.78791, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-030-0.7879.hdf5\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5692 - acc: 0.7262 - val_loss: 0.5411 - val_acc: 0.7963\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.78791 to 0.79630, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-031-0.7963.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5632 - acc: 0.7293 - val_loss: 0.5320 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.79630 to 0.80433, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-032-0.8043.hdf5\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5628 - acc: 0.7271 - val_loss: 0.5335 - val_acc: 0.8050\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.80433 to 0.80503, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-033-0.8050.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5559 - acc: 0.7345 - val_loss: 0.5259 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.80503 to 0.81586, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-034-0.8159.hdf5\n",
      "Epoch 35/200\n",
      "187/251 [=====================>........] - ETA: 1s - loss: 0.5407 - acc: 0.744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4927 - acc: 0.7703 - val_loss: 0.4300 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.86548 to 0.86827, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-057-0.8683.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4889 - acc: 0.7697 - val_loss: 0.4226 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.86827\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4907 - acc: 0.7702 - val_loss: 0.4292 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.86827 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-059-0.8693.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4882 - acc: 0.7727 - val_loss: 0.4188 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.86932 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-060-0.8693.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4869 - acc: 0.7725 - val_loss: 0.4220 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.86932\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4819 - acc: 0.7745 - val_loss: 0.4098 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.86932 to 0.87107, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-062-0.8711.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4812 - acc: 0.7711 - val_loss: 0.4110 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87107 to 0.87177, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-063-0.8718.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4803 - acc: 0.7779 - val_loss: 0.4123 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87177\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4785 - acc: 0.7767 - val_loss: 0.4054 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.87177 to 0.87247, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-065-0.8725.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4726 - acc: 0.7819 - val_loss: 0.4097 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.87247 to 0.87421, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-066-0.8742.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4689 - acc: 0.7840 - val_loss: 0.3930 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.87421 to 0.87561, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-067-0.8756.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4680 - acc: 0.7835 - val_loss: 0.3936 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.87561 to 0.87736, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-068-0.8774.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4672 - acc: 0.7827 - val_loss: 0.3979 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87736 to 0.87911, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-069-0.8791.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4617 - acc: 0.7874 - val_loss: 0.3826 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.87911 to 0.88050, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-070-0.8805.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4603 - acc: 0.7905 - val_loss: 0.3887 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.88050\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4579 - acc: 0.7891 - val_loss: 0.3861 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88050\n",
      "Epoch 73/200\n",
      " 70/251 [=======>......................] - ETA: 3s - loss: 0.4552 - acc: 0.7878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3759 - acc: 0.8316 - val_loss: 0.3045 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.91684\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3744 - acc: 0.8319 - val_loss: 0.3079 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.91684\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3691 - acc: 0.8354 - val_loss: 0.2915 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.91684 to 0.91754, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-119-0.9175.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3658 - acc: 0.8343 - val_loss: 0.3062 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.91754 to 0.91824, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-120-0.9182.hdf5\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3713 - acc: 0.8338 - val_loss: 0.2953 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.91824 to 0.92173, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-121-0.9217.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3671 - acc: 0.8340 - val_loss: 0.2866 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.92173\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3685 - acc: 0.8335 - val_loss: 0.3021 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.92173 to 0.92243, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-123-0.9224.hdf5\n",
      "Epoch 124/200\n",
      "139/251 [===============>..............] - ETA: 2s - loss: 0.3702 - acc: 0.8325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3435 - acc: 0.8530 - val_loss: 0.2698 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.93711\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3348 - acc: 0.8578 - val_loss: 0.2619 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.93711\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3390 - acc: 0.8526 - val_loss: 0.2615 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.93711\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3368 - acc: 0.8530 - val_loss: 0.2548 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.93711\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3368 - acc: 0.8568 - val_loss: 0.2616 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.93711\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3372 - acc: 0.8476 - val_loss: 0.2606 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.93711\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3300 - acc: 0.8582 - val_loss: 0.2493 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.93711 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-154-0.9371.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3318 - acc: 0.8551 - val_loss: 0.2504 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.93711 to 0.93885, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-155-0.9389.hdf5\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3399 - acc: 0.8554 - val_loss: 0.2598 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.93885\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3363 - acc: 0.8544 - val_loss: 0.2570 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.93885\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3299 - acc: 0.8564 - val_loss: 0.2600 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.93885\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3305 - acc: 0.8592 - val_loss: 0.2547 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.93885\n",
      "Epoch 160/200\n",
      " 40/251 [===>..........................] - ETA: 4s - loss: 0.2688 - acc: 0.8889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3066 - acc: 0.8674 - val_loss: 0.2275 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.94479\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3185 - acc: 0.8626 - val_loss: 0.2399 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.94479 to 0.94619, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-183-0.9462.hdf5\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3142 - acc: 0.8658 - val_loss: 0.2344 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00184: val_acc improved from 0.94619 to 0.94724, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-184-0.9472.hdf5\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3126 - acc: 0.8659 - val_loss: 0.2344 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.94724\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3078 - acc: 0.8693 - val_loss: 0.2259 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.94724\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3160 - acc: 0.8617 - val_loss: 0.2289 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.94724\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3154 - acc: 0.8640 - val_loss: 0.2337 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.94724\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3052 - acc: 0.8714 - val_loss: 0.2218 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.94724\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3066 - acc: 0.8662 - val_loss: 0.2334 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.94724\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3019 - acc: 0.8699 - val_loss: 0.2172 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.94724 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-191-0.9479.hdf5\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3054 - acc: 0.8667 - val_loss: 0.2285 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.94794\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3088 - acc: 0.8676 - val_loss: 0.2270 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.94794\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3093 - acc: 0.8673 - val_loss: 0.2334 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.94794 to 0.94969, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-194-0.9497.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3003 - acc: 0.8729 - val_loss: 0.2251 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.94969\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3058 - acc: 0.8690 - val_loss: 0.2116 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.94969 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-196-0.9507.hdf5\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3079 - acc: 0.8686 - val_loss: 0.2267 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.95073 to 0.95283, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-197-0.9528.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3063 - acc: 0.8677 - val_loss: 0.2065 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.95283 to 0.95632, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/6/weights-improvement-198-0.9563.hdf5\n",
      "Epoch 199/200\n",
      "  7/251 [..............................] - ETA: 5s - loss: 0.1617 - acc: 0.9471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5467 - acc: 0.7413 - val_loss: 0.5442 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.78162 to 0.78232, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-043-0.7823.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5455 - acc: 0.7427 - val_loss: 0.5406 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.78232 to 0.79071, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-044-0.7907.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5413 - acc: 0.7405 - val_loss: 0.5274 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.79071 to 0.79979, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-045-0.7998.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5376 - acc: 0.7451 - val_loss: 0.5169 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.79979 to 0.81342, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-046-0.8134.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5348 - acc: 0.7486 - val_loss: 0.5156 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.81342 to 0.81726, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-047-0.8173.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5372 - acc: 0.7446 - val_loss: 0.5159 - val_acc: 0.8208\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.81726 to 0.82075, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-048-0.8208.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5275 - acc: 0.7548 - val_loss: 0.5038 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.82075 to 0.83019, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-049-0.8302.hdf5\n",
      "Epoch 50/200\n",
      "162/251 [==================>...........] - ETA: 1s - loss: 0.5168 - acc: 0.7606"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4712 - acc: 0.7805 - val_loss: 0.3948 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.88155 to 0.88190, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-073-0.8819.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4707 - acc: 0.7819 - val_loss: 0.3838 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88190\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4657 - acc: 0.7875 - val_loss: 0.3758 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.88190 to 0.88400, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-075-0.8840.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4644 - acc: 0.7864 - val_loss: 0.3801 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.88400\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4661 - acc: 0.7902 - val_loss: 0.3812 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.88400 to 0.88714, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-077-0.8871.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4605 - acc: 0.7885 - val_loss: 0.3715 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.88714 to 0.88994, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-078-0.8899.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4609 - acc: 0.7874 - val_loss: 0.3722 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.88994\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4590 - acc: 0.7891 - val_loss: 0.3674 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.88994 to 0.89099, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-080-0.8910.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4492 - acc: 0.7939 - val_loss: 0.3540 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.89099\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4531 - acc: 0.7953 - val_loss: 0.3610 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.89099 to 0.89308, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-082-0.8931.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4481 - acc: 0.7962 - val_loss: 0.3491 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.89308\n",
      "Epoch 84/200\n",
      "235/251 [===========================>..] - ETA: 0s - loss: 0.4371 - acc: 0.8039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4059 - acc: 0.8172 - val_loss: 0.2888 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.91789\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4016 - acc: 0.8203 - val_loss: 0.2869 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.91789 to 0.91964, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-109-0.9196.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4014 - acc: 0.8184 - val_loss: 0.2801 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.91964 to 0.91964, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-110-0.9196.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4011 - acc: 0.8191 - val_loss: 0.2778 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.91964\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3988 - acc: 0.8207 - val_loss: 0.2808 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.91964 to 0.92208, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-112-0.9221.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3987 - acc: 0.8224 - val_loss: 0.2822 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.92208\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3994 - acc: 0.8228 - val_loss: 0.2754 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.92208 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-114-0.9238.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3913 - acc: 0.8259 - val_loss: 0.2716 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.92383\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3958 - acc: 0.8235 - val_loss: 0.2709 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.92383 to 0.92662, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-116-0.9266.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3923 - acc: 0.8219 - val_loss: 0.2763 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.92662 to 0.93047, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-117-0.9305.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3938 - acc: 0.8237 - val_loss: 0.2676 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93047\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3924 - acc: 0.8257 - val_loss: 0.2681 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93047\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3796 - acc: 0.8320 - val_loss: 0.2543 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93047\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3879 - acc: 0.8286 - val_loss: 0.2633 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.93047 to 0.93431, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-121-0.9343.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3858 - acc: 0.8296 - val_loss: 0.2707 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93431\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3884 - acc: 0.8298 - val_loss: 0.2639 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.93431 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-123-0.9357.hdf5\n",
      "Epoch 124/200\n",
      " 31/251 [==>...........................] - ETA: 4s - loss: 0.2653 - acc: 0.8943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3464 - acc: 0.8513 - val_loss: 0.2004 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.95807 to 0.95912, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-167-0.9591.hdf5\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3366 - acc: 0.8564 - val_loss: 0.1944 - val_acc: 0.9598\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.95912 to 0.95982, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-168-0.9598.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3369 - acc: 0.8547 - val_loss: 0.1933 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00169: val_acc improved from 0.95982 to 0.96052, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-169-0.9605.hdf5\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3424 - acc: 0.8531 - val_loss: 0.1987 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.96052\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3366 - acc: 0.8568 - val_loss: 0.1912 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.96052\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3341 - acc: 0.8577 - val_loss: 0.1872 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.96052\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3275 - acc: 0.8631 - val_loss: 0.1929 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.96052\n",
      "Epoch 174/200\n",
      "187/251 [=====================>........] - ETA: 1s - loss: 0.3174 - acc: 0.8647"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3197 - acc: 0.8646 - val_loss: 0.1647 - val_acc: 0.9686\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.96820 to 0.96855, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/7/weights-improvement-199-0.9686.hdf5\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3185 - acc: 0.8684 - val_loss: 0.1720 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.96855\n",
      "It has been  0:20:07.105558\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_30 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 1000, 26)     0           input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_146 (Conv1D)             (None, 1000, 10)     270         dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_147 (Conv1D)             (None, 1000, 10)     790         dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_148 (Conv1D)             (None, 1000, 10)     1310        dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_149 (Conv1D)             (None, 1000, 10)     2350        dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_150 (Conv1D)             (None, 1000, 10)     3910        dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 5000, 10)     0           conv1d_146[0][0]                 \n",
      "                                                                 conv1d_147[0][0]                 \n",
      "                                                                 conv1d_148[0][0]                 \n",
      "                                                                 conv1d_149[0][0]                 \n",
      "                                                                 conv1d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 500, 10)      0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 500, 314)     3454        max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 500, 314)     0           dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 500, 77)      24255       dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 500, 77)      0           dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 500, 8)       624         dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 500, 8)       0           dense_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_30 (Flatten)            (None, 4000)         0           dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 2)            8002        flatten_30[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 9s 35ms/step - loss: 0.6753 - acc: 0.6161 - val_loss: 0.6903 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73795, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-001-0.7379.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6634 - acc: 0.6186 - val_loss: 0.6825 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.73795\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6467 - acc: 0.6568 - val_loss: 0.6615 - val_acc: 0.7121\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73795\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6360 - acc: 0.6825 - val_loss: 0.6473 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73795\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6278 - acc: 0.6878 - val_loss: 0.6367 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73795\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6243 - acc: 0.6958 - val_loss: 0.6315 - val_acc: 0.7041\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73795\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6233 - acc: 0.6946 - val_loss: 0.6282 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73795\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6211 - acc: 0.6986 - val_loss: 0.6243 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73795\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.6193 - acc: 0.6970 - val_loss: 0.6206 - val_acc: 0.7107\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73795\n",
      "Epoch 10/200\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.5903 - acc: 0.7171"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5640 - acc: 0.7301 - val_loss: 0.5370 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.79315 to 0.80189, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-033-0.8019.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5622 - acc: 0.7300 - val_loss: 0.5328 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.80189 to 0.80678, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-034-0.8068.hdf5\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5559 - acc: 0.7368 - val_loss: 0.5203 - val_acc: 0.8201\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.80678 to 0.82006, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-035-0.8201.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5561 - acc: 0.7342 - val_loss: 0.5148 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.82006 to 0.82425, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-036-0.8242.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5514 - acc: 0.7376 - val_loss: 0.5061 - val_acc: 0.8312\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.82425 to 0.83124, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-037-0.8312.hdf5\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5443 - acc: 0.7424 - val_loss: 0.5037 - val_acc: 0.8368\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.83124 to 0.83683, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-038-0.8368.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5458 - acc: 0.7418 - val_loss: 0.4932 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.83683 to 0.84067, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-039-0.8407.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5397 - acc: 0.7438 - val_loss: 0.4900 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.84067 to 0.84416, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-040-0.8442.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5377 - acc: 0.7459 - val_loss: 0.4765 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.84416 to 0.84661, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-041-0.8466.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5335 - acc: 0.7455 - val_loss: 0.4646 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.84661 to 0.84731, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-042-0.8473.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5309 - acc: 0.7483 - val_loss: 0.4611 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.84731 to 0.85010, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-043-0.8501.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5294 - acc: 0.7473 - val_loss: 0.4617 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.85010 to 0.85150, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-044-0.8515.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5252 - acc: 0.7512 - val_loss: 0.4545 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.85150 to 0.85325, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-045-0.8532.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5253 - acc: 0.7533 - val_loss: 0.4470 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.85325 to 0.85639, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-046-0.8564.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5213 - acc: 0.7539 - val_loss: 0.4434 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.85639 to 0.85709, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-047-0.8571.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5182 - acc: 0.7542 - val_loss: 0.4427 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.85709 to 0.86024, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-048-0.8602.hdf5\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.5143 - acc: 0.7547 - val_loss: 0.4393 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.86024 to 0.86233, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-049-0.8623.hdf5\n",
      "Epoch 50/200\n",
      " 25/251 [=>............................] - ETA: 4s - loss: 0.4076 - acc: 0.8341"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4651 - acc: 0.7833 - val_loss: 0.3561 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.89099 to 0.89343, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-068-0.8934.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4629 - acc: 0.7832 - val_loss: 0.3439 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.89343 to 0.89448, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-069-0.8945.hdf5\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4618 - acc: 0.7884 - val_loss: 0.3576 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.89448 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-070-0.8969.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4567 - acc: 0.7908 - val_loss: 0.3449 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.89693 to 0.89832, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-071-0.8983.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4546 - acc: 0.7913 - val_loss: 0.3400 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.89832 to 0.90077, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-072-0.9008.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4493 - acc: 0.7957 - val_loss: 0.3437 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.90077 to 0.90182, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-073-0.9018.hdf5\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4494 - acc: 0.7924 - val_loss: 0.3401 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.90182 to 0.90391, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-074-0.9039.hdf5\n",
      "Epoch 75/200\n",
      "180/251 [====================>.........] - ETA: 1s - loss: 0.4242 - acc: 0.8040"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4082 - acc: 0.8141 - val_loss: 0.2780 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.92558 to 0.92732, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-099-0.9273.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4110 - acc: 0.8130 - val_loss: 0.2680 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.92732\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4026 - acc: 0.8203 - val_loss: 0.2782 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.92732 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-101-0.9301.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4035 - acc: 0.8208 - val_loss: 0.2739 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.93012 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-102-0.9315.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.4064 - acc: 0.8171 - val_loss: 0.2720 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.93152 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-103-0.9322.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3957 - acc: 0.8276 - val_loss: 0.2628 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.93222 to 0.93501, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-104-0.9350.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3925 - acc: 0.8240 - val_loss: 0.2595 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93501\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3990 - acc: 0.8228 - val_loss: 0.2696 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.93501 to 0.93536, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-106-0.9354.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3989 - acc: 0.8241 - val_loss: 0.2649 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93536\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3966 - acc: 0.8253 - val_loss: 0.2676 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93536\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3922 - acc: 0.8246 - val_loss: 0.2618 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.93536 to 0.93850, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-109-0.9385.hdf5\n",
      "Epoch 110/200\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.3563 - acc: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3589 - acc: 0.8444 - val_loss: 0.2166 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95178\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3614 - acc: 0.8426 - val_loss: 0.2116 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.95178\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3627 - acc: 0.8420 - val_loss: 0.2120 - val_acc: 0.9535\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.95178 to 0.95353, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-136-0.9535.hdf5\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3606 - acc: 0.8444 - val_loss: 0.2175 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.95353\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3582 - acc: 0.8431 - val_loss: 0.2120 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95353\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3596 - acc: 0.8446 - val_loss: 0.2172 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.95353 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-139-0.9539.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3544 - acc: 0.8460 - val_loss: 0.2020 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95388\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3530 - acc: 0.8448 - val_loss: 0.1966 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.95388\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3542 - acc: 0.8451 - val_loss: 0.2064 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00142: val_acc improved from 0.95388 to 0.95458, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-142-0.9546.hdf5\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3505 - acc: 0.8489 - val_loss: 0.2054 - val_acc: 0.9553\n",
      "\n",
      "Epoch 00143: val_acc improved from 0.95458 to 0.95528, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-143-0.9553.hdf5\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3530 - acc: 0.8453 - val_loss: 0.2040 - val_acc: 0.9560\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.95528 to 0.95597, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-144-0.9560.hdf5\n",
      "Epoch 145/200\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.3132 - acc: 0.8678"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3166 - acc: 0.8634 - val_loss: 0.1545 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.97065\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3152 - acc: 0.8666 - val_loss: 0.1555 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.97065\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3152 - acc: 0.8654 - val_loss: 0.1551 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.97065\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3150 - acc: 0.8636 - val_loss: 0.1511 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.97065\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3139 - acc: 0.8676 - val_loss: 0.1505 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.97065\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3104 - acc: 0.8669 - val_loss: 0.1405 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.97065\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3011 - acc: 0.8733 - val_loss: 0.1423 - val_acc: 0.9700\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.97065\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3138 - acc: 0.8706 - val_loss: 0.1497 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.97065\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3045 - acc: 0.8691 - val_loss: 0.1453 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.97065 to 0.97205, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/8/weights-improvement-197-0.9720.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3071 - acc: 0.8727 - val_loss: 0.1471 - val_acc: 0.9710\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.97205\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3067 - acc: 0.8693 - val_loss: 0.1421 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.97205\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 23ms/step - loss: 0.3064 - acc: 0.8701 - val_loss: 0.1467 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.97205\n",
      "It has been  0:19:46.150168\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 1000, 26)     0           input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_151 (Conv1D)             (None, 1000, 10)     270         dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_152 (Conv1D)             (None, 1000, 10)     790         dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_153 (Conv1D)             (None, 1000, 10)     1310        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_154 (Conv1D)             (None, 1000, 10)     2350        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_155 (Conv1D)             (None, 1000, 10)     3910        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 5000, 10)     0           conv1d_151[0][0]                 \n",
      "                                                                 conv1d_152[0][0]                 \n",
      "                                                                 conv1d_153[0][0]                 \n",
      "                                                                 conv1d_154[0][0]                 \n",
      "                                                                 conv1d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 500, 10)      0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 500, 314)     3454        max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 500, 314)     0           dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 500, 77)      24255       dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 500, 77)      0           dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 500, 8)       624         dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 500, 8)       0           dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_31 (Flatten)            (None, 4000)         0           dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 2)            8002        flatten_31[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "199/251 [======================>.......] - ETA: 1s - loss: 0.6628 - acc: 0.6567"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5930 - acc: 0.7042 - val_loss: 0.5901 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.78197\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5899 - acc: 0.7123 - val_loss: 0.5872 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.78197\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5898 - acc: 0.7131 - val_loss: 0.5902 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.78197\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5875 - acc: 0.7123 - val_loss: 0.5833 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.78197\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5845 - acc: 0.7179 - val_loss: 0.5800 - val_acc: 0.7453\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.78197\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5814 - acc: 0.7168 - val_loss: 0.5761 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.78197\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5787 - acc: 0.7179 - val_loss: 0.5674 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.78197\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5747 - acc: 0.7237 - val_loss: 0.5662 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.78197\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5740 - acc: 0.7233 - val_loss: 0.5683 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.78197\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5701 - acc: 0.7250 - val_loss: 0.5643 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.78197\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5661 - acc: 0.7277 - val_loss: 0.5629 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.78197\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5624 - acc: 0.7302 - val_loss: 0.5558 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.78197\n",
      "Epoch 37/200\n",
      " 46/251 [====>.........................] - ETA: 4s - loss: 0.4949 - acc: 0.7895"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4993 - acc: 0.7712 - val_loss: 0.4725 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00059: val_acc improved from 0.85989 to 0.86233, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-059-0.8623.hdf5\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4928 - acc: 0.7728 - val_loss: 0.4654 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.86233\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4903 - acc: 0.7691 - val_loss: 0.4597 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.86233 to 0.86303, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-061-0.8630.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4900 - acc: 0.7758 - val_loss: 0.4598 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.86303 to 0.86862, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-062-0.8686.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4827 - acc: 0.7797 - val_loss: 0.4533 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.86862 to 0.86967, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-063-0.8697.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4836 - acc: 0.7768 - val_loss: 0.4523 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.86967 to 0.86967, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-064-0.8697.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4784 - acc: 0.7815 - val_loss: 0.4429 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.86967 to 0.87282, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-065-0.8728.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4706 - acc: 0.7840 - val_loss: 0.4299 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.87282 to 0.87701, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-066-0.8770.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4731 - acc: 0.7840 - val_loss: 0.4339 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.87701 to 0.87701, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-067-0.8770.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4720 - acc: 0.7864 - val_loss: 0.4255 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.87701 to 0.87876, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-068-0.8788.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4682 - acc: 0.7926 - val_loss: 0.4298 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87876 to 0.88015, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-069-0.8802.hdf5\n",
      "Epoch 70/200\n",
      " 82/251 [========>.....................] - ETA: 3s - loss: 0.4784 - acc: 0.7857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3827 - acc: 0.8313 - val_loss: 0.2932 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.93256 to 0.93361, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-114-0.9336.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3792 - acc: 0.8355 - val_loss: 0.2949 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.93361\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3794 - acc: 0.8350 - val_loss: 0.2916 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93361\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3764 - acc: 0.8358 - val_loss: 0.2875 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.93361 to 0.93641, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-117-0.9364.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3739 - acc: 0.8367 - val_loss: 0.2843 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93641\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3748 - acc: 0.8397 - val_loss: 0.2877 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93641\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3685 - acc: 0.8375 - val_loss: 0.2824 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93641\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3736 - acc: 0.8394 - val_loss: 0.2813 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.93641 to 0.93676, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-121-0.9368.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3723 - acc: 0.8368 - val_loss: 0.2767 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.93676 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-122-0.9371.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3651 - acc: 0.8448 - val_loss: 0.2730 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.93711 to 0.93781, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-123-0.9378.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3637 - acc: 0.8411 - val_loss: 0.2660 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93781\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3626 - acc: 0.8445 - val_loss: 0.2762 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.93781 to 0.93850, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-125-0.9385.hdf5\n",
      "Epoch 126/200\n",
      " 52/251 [=====>........................] - ETA: 4s - loss: 0.3202 - acc: 0.8718"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3429 - acc: 0.8535 - val_loss: 0.2503 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.94549 to 0.94689, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-148-0.9469.hdf5\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3444 - acc: 0.8526 - val_loss: 0.2468 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.94689\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3432 - acc: 0.8533 - val_loss: 0.2398 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00150: val_acc improved from 0.94689 to 0.94724, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-150-0.9472.hdf5\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3341 - acc: 0.8576 - val_loss: 0.2364 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.94724\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3358 - acc: 0.8550 - val_loss: 0.2347 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.94724\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3349 - acc: 0.8564 - val_loss: 0.2367 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.94724 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-153-0.9479.hdf5\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3360 - acc: 0.8571 - val_loss: 0.2405 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.94794\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3349 - acc: 0.8570 - val_loss: 0.2336 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.94794\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3318 - acc: 0.8595 - val_loss: 0.2312 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.94794 to 0.94934, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-156-0.9493.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3322 - acc: 0.8550 - val_loss: 0.2280 - val_acc: 0.9521\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.94934 to 0.95213, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-157-0.9521.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3319 - acc: 0.8592 - val_loss: 0.2348 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.95213\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3311 - acc: 0.8580 - val_loss: 0.2285 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.95213\n",
      "Epoch 160/200\n",
      "166/251 [==================>...........] - ETA: 1s - loss: 0.3259 - acc: 0.8582- ETA: 2s - loss: 0.3348 - acc"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3195 - acc: 0.8650 - val_loss: 0.2121 - val_acc: 0.9605\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.96017 to 0.96052, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-183-0.9605.hdf5\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3122 - acc: 0.8659 - val_loss: 0.2096 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.96052\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3209 - acc: 0.8641 - val_loss: 0.2180 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.96052\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3111 - acc: 0.8702 - val_loss: 0.2127 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.96052\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3180 - acc: 0.8646 - val_loss: 0.2112 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.96052\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3152 - acc: 0.8660 - val_loss: 0.2041 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00188: val_acc improved from 0.96052 to 0.96157, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-188-0.9616.hdf5\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3172 - acc: 0.8656 - val_loss: 0.2102 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.96157\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3134 - acc: 0.8675 - val_loss: 0.2010 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.96157 to 0.96226, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-190-0.9623.hdf5\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3128 - acc: 0.8654 - val_loss: 0.1949 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.96226\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3087 - acc: 0.8689 - val_loss: 0.2056 - val_acc: 0.9626\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.96226 to 0.96261, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/mid_padding/9/weights-improvement-192-0.9626.hdf5\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3107 - acc: 0.8675 - val_loss: 0.2113 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.96261\n",
      "Epoch 194/200\n",
      " 94/251 [==========>...................] - ETA: 3s - loss: 0.3211 - acc: 0.8643"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5850 - acc: 0.7163 - val_loss: 0.5216 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.79839\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5823 - acc: 0.7207 - val_loss: 0.5235 - val_acc: 0.7718\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.79839\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5814 - acc: 0.7222 - val_loss: 0.5220 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.79839\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5808 - acc: 0.7196 - val_loss: 0.5172 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.79839\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5781 - acc: 0.7227 - val_loss: 0.5150 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.79839\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5778 - acc: 0.7234 - val_loss: 0.5143 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.79839\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5737 - acc: 0.7301 - val_loss: 0.5124 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.79839\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5724 - acc: 0.7252 - val_loss: 0.5120 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.79839\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5715 - acc: 0.7242 - val_loss: 0.5084 - val_acc: 0.7872\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.79839\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5700 - acc: 0.7257 - val_loss: 0.5079 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.79839\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5682 - acc: 0.7277 - val_loss: 0.5054 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.79839\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5655 - acc: 0.7304 - val_loss: 0.5030 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.79839\n",
      "Epoch 49/200\n",
      "  7/251 [..............................] - ETA: 5s - loss: 0.5015 - acc: 0.7566"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5179 - acc: 0.7631 - val_loss: 0.4587 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.85010\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5147 - acc: 0.7615 - val_loss: 0.4500 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.85010\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5127 - acc: 0.7649 - val_loss: 0.4490 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.85010\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5170 - acc: 0.7620 - val_loss: 0.4517 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.85010\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5118 - acc: 0.7610 - val_loss: 0.4455 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.85010 to 0.85465, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-076-0.8546.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5096 - acc: 0.7666 - val_loss: 0.4430 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.85465\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5134 - acc: 0.7621 - val_loss: 0.4442 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.85465 to 0.85465, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-078-0.8546.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5068 - acc: 0.7688 - val_loss: 0.4394 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.85465\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5075 - acc: 0.7679 - val_loss: 0.4400 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.85465 to 0.85814, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-080-0.8581.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5031 - acc: 0.7677 - val_loss: 0.4369 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.85814 to 0.86024, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-081-0.8602.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5041 - acc: 0.7668 - val_loss: 0.4369 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.86024\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5039 - acc: 0.7649 - val_loss: 0.4343 - val_acc: 0.8588\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.86024\n",
      "Epoch 84/200\n",
      "115/251 [============>.................] - ETA: 3s - loss: 0.5114 - acc: 0.7636"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4766 - acc: 0.7818 - val_loss: 0.4032 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.87876\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4719 - acc: 0.7857 - val_loss: 0.3992 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.87876 to 0.88050, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-107-0.8805.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4707 - acc: 0.7865 - val_loss: 0.3973 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.88050\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4688 - acc: 0.7854 - val_loss: 0.3916 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.88050 to 0.88225, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-109-0.8823.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4734 - acc: 0.7828 - val_loss: 0.3989 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.88225\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4709 - acc: 0.7857 - val_loss: 0.3898 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.88225 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-111-0.8829.hdf5\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4657 - acc: 0.7852 - val_loss: 0.3871 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.88295 to 0.88505, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-112-0.8850.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4681 - acc: 0.7877 - val_loss: 0.3875 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.88505 to 0.88539, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-113-0.8854.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4640 - acc: 0.7908 - val_loss: 0.3827 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.88539 to 0.88749, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-114-0.8875.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4631 - acc: 0.7902 - val_loss: 0.3823 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.88749 to 0.88959, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-115-0.8896.hdf5\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4597 - acc: 0.7876 - val_loss: 0.3763 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.88959\n",
      "Epoch 117/200\n",
      "216/251 [========================>.....] - ETA: 0s - loss: 0.4182 - acc: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4226 - acc: 0.8089 - val_loss: 0.3233 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.91125 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-160-0.9116.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4252 - acc: 0.8098 - val_loss: 0.3212 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.91160\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4184 - acc: 0.8107 - val_loss: 0.3176 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.91160\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4235 - acc: 0.8105 - val_loss: 0.3194 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.91160 to 0.91440, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-163-0.9144.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4174 - acc: 0.8090 - val_loss: 0.3163 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.91440\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4141 - acc: 0.8161 - val_loss: 0.3126 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.91440\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4160 - acc: 0.8145 - val_loss: 0.3126 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.91440\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4221 - acc: 0.8105 - val_loss: 0.3184 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.91440 to 0.91579, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-167-0.9158.hdf5\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4186 - acc: 0.8121 - val_loss: 0.3123 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.91579 to 0.91719, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-168-0.9172.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4159 - acc: 0.8116 - val_loss: 0.3150 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.91719\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4143 - acc: 0.8143 - val_loss: 0.3075 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00170: val_acc improved from 0.91719 to 0.91754, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-170-0.9175.hdf5\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4130 - acc: 0.8139 - val_loss: 0.3101 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.91754\n",
      "Epoch 172/200\n",
      "133/251 [==============>...............] - ETA: 2s - loss: 0.4080 - acc: 0.8138"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3951 - acc: 0.8209 - val_loss: 0.2877 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.92208\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3930 - acc: 0.8273 - val_loss: 0.2857 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.92208\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3925 - acc: 0.8267 - val_loss: 0.2888 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.92208\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3981 - acc: 0.8228 - val_loss: 0.2840 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00199: val_acc improved from 0.92208 to 0.92278, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/0/weights-improvement-199-0.9228.hdf5\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3972 - acc: 0.8198 - val_loss: 0.2847 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.92278\n",
      "It has been  0:20:33.100741\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 1000, 26)     0           input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_161 (Conv1D)             (None, 1000, 10)     270         dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_162 (Conv1D)             (None, 1000, 10)     790         dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_163 (Conv1D)             (None, 1000, 10)     1310        dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_164 (Conv1D)             (None, 1000, 10)     2350        dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_165 (Conv1D)             (None, 1000, 10)     3910        dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 5000, 10)     0           conv1d_161[0][0]                 \n",
      "                                                                 conv1d_162[0][0]                 \n",
      "                                                                 conv1d_163[0][0]                 \n",
      "                                                                 conv1d_164[0][0]                 \n",
      "                                                                 conv1d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 500, 10)      0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 500, 314)     3454        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 500, 314)     0           dense_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 500, 77)      24255       dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 500, 77)      0           dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 500, 8)       624         dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 500, 8)       0           dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 4000)         0           dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 2)            8002        flatten_33[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 10s 39ms/step - loss: 0.6924 - acc: 0.5836 - val_loss: 0.6939 - val_acc: 0.3057\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30573, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-001-0.3057.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6874 - acc: 0.5504 - val_loss: 0.6938 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.30573\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6929 - acc: 0.5330 - val_loss: 0.6952 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.30573\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6903 - acc: 0.5834 - val_loss: 0.6727 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.30573 to 0.78966, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-004-0.7897.hdf5\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6815 - acc: 0.6313 - val_loss: 0.6201 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78966\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6584 - acc: 0.6611 - val_loss: 0.5621 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78966\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6348 - acc: 0.6788 - val_loss: 0.5270 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.78966\n",
      "Epoch 8/200\n",
      " 84/251 [=========>....................] - ETA: 3s - loss: 0.6124 - acc: 0.6750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5998 - acc: 0.7099 - val_loss: 0.5054 - val_acc: 0.7998\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.81621\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6003 - acc: 0.7115 - val_loss: 0.5060 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.81621\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5990 - acc: 0.7108 - val_loss: 0.5063 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.81621\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5982 - acc: 0.7133 - val_loss: 0.5058 - val_acc: 0.7963\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.81621\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5986 - acc: 0.7121 - val_loss: 0.5067 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.81621\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5974 - acc: 0.7148 - val_loss: 0.5081 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.81621\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5964 - acc: 0.7140 - val_loss: 0.5084 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.81621\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5959 - acc: 0.7143 - val_loss: 0.5072 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.81621\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5943 - acc: 0.7144 - val_loss: 0.5069 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.81621\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5946 - acc: 0.7139 - val_loss: 0.5081 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.81621\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5936 - acc: 0.7129 - val_loss: 0.5085 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.81621\n",
      "Epoch 41/200\n",
      "108/251 [===========>..................] - ETA: 3s - loss: 0.6047 - acc: 0.6932"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5364 - acc: 0.7465 - val_loss: 0.4658 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.82075 to 0.82390, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-083-0.8239.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5363 - acc: 0.7472 - val_loss: 0.4625 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.82390 to 0.82704, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-084-0.8270.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5340 - acc: 0.7487 - val_loss: 0.4638 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.82704\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5302 - acc: 0.7542 - val_loss: 0.4570 - val_acc: 0.8309\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.82704 to 0.83089, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-086-0.8309.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5281 - acc: 0.7474 - val_loss: 0.4620 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.83089\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5255 - acc: 0.7542 - val_loss: 0.4551 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.83089\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5276 - acc: 0.7503 - val_loss: 0.4502 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.83089 to 0.83368, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-089-0.8337.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5268 - acc: 0.7533 - val_loss: 0.4544 - val_acc: 0.8309\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.83368\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5273 - acc: 0.7525 - val_loss: 0.4519 - val_acc: 0.8309\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.83368\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5224 - acc: 0.7514 - val_loss: 0.4504 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.83368\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5246 - acc: 0.7528 - val_loss: 0.4538 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.83368\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5217 - acc: 0.7553 - val_loss: 0.4496 - val_acc: 0.8326\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.83368\n",
      "Epoch 95/200\n",
      "169/251 [===================>..........] - ETA: 1s - loss: 0.5119 - acc: 0.7605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5007 - acc: 0.7693 - val_loss: 0.4129 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.85744\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5047 - acc: 0.7636 - val_loss: 0.4085 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.85744 to 0.85814, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-119-0.8581.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4953 - acc: 0.7683 - val_loss: 0.4034 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00120: val_acc improved from 0.85814 to 0.86094, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-120-0.8609.hdf5\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4963 - acc: 0.7693 - val_loss: 0.4029 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.86094 to 0.86338, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-121-0.8634.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4947 - acc: 0.7731 - val_loss: 0.4026 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.86338\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4920 - acc: 0.7711 - val_loss: 0.3988 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.86338\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4925 - acc: 0.7715 - val_loss: 0.3949 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.86338 to 0.86513, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-124-0.8651.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4897 - acc: 0.7739 - val_loss: 0.3920 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.86513 to 0.86618, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-125-0.8662.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4897 - acc: 0.7701 - val_loss: 0.3938 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.86618 to 0.86618, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-126-0.8662.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4921 - acc: 0.7710 - val_loss: 0.3882 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.86618 to 0.86653, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-127-0.8665.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4870 - acc: 0.7732 - val_loss: 0.3906 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.86653 to 0.86758, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-128-0.8676.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4860 - acc: 0.7771 - val_loss: 0.3893 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.86758 to 0.86897, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-129-0.8690.hdf5\n",
      "Epoch 130/200\n",
      "101/251 [===========>..................] - ETA: 3s - loss: 0.5045 - acc: 0.7594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4595 - acc: 0.7894 - val_loss: 0.3580 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.88085\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4575 - acc: 0.7913 - val_loss: 0.3573 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00153: val_acc improved from 0.88085 to 0.88190, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-153-0.8819.hdf5\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4556 - acc: 0.7928 - val_loss: 0.3553 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.88190\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4596 - acc: 0.7898 - val_loss: 0.3565 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.88190\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4599 - acc: 0.7894 - val_loss: 0.3541 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.88190\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4525 - acc: 0.7927 - val_loss: 0.3491 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.88190 to 0.88470, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-157-0.8847.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4580 - acc: 0.7893 - val_loss: 0.3525 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.88470\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4522 - acc: 0.7967 - val_loss: 0.3439 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.88470 to 0.88470, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-159-0.8847.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4586 - acc: 0.7852 - val_loss: 0.3497 - val_acc: 0.8840\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.88470\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4552 - acc: 0.7913 - val_loss: 0.3477 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00161: val_acc improved from 0.88470 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-161-0.8861.hdf5\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4512 - acc: 0.7952 - val_loss: 0.3454 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.88609 to 0.88749, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/1/weights-improvement-162-0.8875.hdf5\n",
      "Epoch 163/200\n",
      "188/251 [=====================>........] - ETA: 1s - loss: 0.4320 - acc: 0.8054"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6819 - acc: 0.6010 - val_loss: 0.6763 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.68798 to 0.71873, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-006-0.7187.hdf5\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6547 - acc: 0.6476 - val_loss: 0.6345 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.71873 to 0.78232, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-007-0.7823.hdf5\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6403 - acc: 0.6640 - val_loss: 0.6217 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.78232 to 0.78372, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-008-0.7837.hdf5\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6311 - acc: 0.6709 - val_loss: 0.6054 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.78372 to 0.78546, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-009-0.7855.hdf5\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6236 - acc: 0.6791 - val_loss: 0.6039 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78546\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6229 - acc: 0.6880 - val_loss: 0.5793 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78546\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6127 - acc: 0.6906 - val_loss: 0.5929 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78546\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6217 - acc: 0.6861 - val_loss: 0.5872 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78546\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6165 - acc: 0.6924 - val_loss: 0.5903 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.78546\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6188 - acc: 0.6898 - val_loss: 0.5887 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.78546\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6147 - acc: 0.6933 - val_loss: 0.5895 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.78546\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6152 - acc: 0.6949 - val_loss: 0.5861 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78546\n",
      "Epoch 18/200\n",
      "112/251 [============>.................] - ETA: 3s - loss: 0.6203 - acc: 0.6829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5727 - acc: 0.7236 - val_loss: 0.5640 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.78546\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5704 - acc: 0.7272 - val_loss: 0.5664 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.78546\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5684 - acc: 0.7259 - val_loss: 0.5649 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.78546\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5661 - acc: 0.7287 - val_loss: 0.5595 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.78546\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5663 - acc: 0.7308 - val_loss: 0.5600 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.78546\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5635 - acc: 0.7318 - val_loss: 0.5561 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.78546\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5584 - acc: 0.7350 - val_loss: 0.5541 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.78546\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5587 - acc: 0.7375 - val_loss: 0.5521 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.78546\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5565 - acc: 0.7359 - val_loss: 0.5488 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.78546\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5537 - acc: 0.7372 - val_loss: 0.5466 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.78546\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5534 - acc: 0.7364 - val_loss: 0.5467 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.78546\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5478 - acc: 0.7408 - val_loss: 0.5365 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.78546\n",
      "Epoch 54/200\n",
      "  4/251 [..............................] - ETA: 5s - loss: 0.4927 - acc: 0.7083"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5125 - acc: 0.7628 - val_loss: 0.4884 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.80538 to 0.80922, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-076-0.8092.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5133 - acc: 0.7595 - val_loss: 0.4884 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.80922 to 0.81342, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-077-0.8134.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5088 - acc: 0.7637 - val_loss: 0.4827 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.81342 to 0.81656, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-078-0.8166.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5076 - acc: 0.7660 - val_loss: 0.4848 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.81656\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5108 - acc: 0.7604 - val_loss: 0.4844 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.81656 to 0.81691, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-080-0.8169.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5101 - acc: 0.7608 - val_loss: 0.4816 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.81691 to 0.81936, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-081-0.8194.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5033 - acc: 0.7708 - val_loss: 0.4793 - val_acc: 0.8229\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.81936 to 0.82285, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-082-0.8229.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5054 - acc: 0.7647 - val_loss: 0.4789 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.82285 to 0.82635, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-083-0.8263.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5065 - acc: 0.7670 - val_loss: 0.4805 - val_acc: 0.8274\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.82635 to 0.82739, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-084-0.8274.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5011 - acc: 0.7678 - val_loss: 0.4715 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.82739 to 0.83508, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-085-0.8351.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5001 - acc: 0.7693 - val_loss: 0.4709 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.83508\n",
      "Epoch 87/200\n",
      "148/251 [================>.............] - ETA: 2s - loss: 0.4969 - acc: 0.7748"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4513 - acc: 0.7914 - val_loss: 0.4120 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.88574\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4472 - acc: 0.7977 - val_loss: 0.4089 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.88574\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4432 - acc: 0.8006 - val_loss: 0.3947 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.88574 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-132-0.8878.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4408 - acc: 0.8000 - val_loss: 0.3934 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.88784\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4438 - acc: 0.7995 - val_loss: 0.3956 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.88784 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-134-0.8878.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4402 - acc: 0.8051 - val_loss: 0.3911 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.88784 to 0.89064, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-135-0.8906.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4382 - acc: 0.8030 - val_loss: 0.3912 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.89064\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4433 - acc: 0.7979 - val_loss: 0.3916 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.89064\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4357 - acc: 0.8071 - val_loss: 0.3908 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.89064 to 0.89133, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-138-0.8913.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4365 - acc: 0.8021 - val_loss: 0.3909 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.89133\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4368 - acc: 0.8006 - val_loss: 0.3893 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.89133\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4357 - acc: 0.8030 - val_loss: 0.3929 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.89133\n",
      "Epoch 142/200\n",
      " 64/251 [======>.......................] - ETA: 4s - loss: 0.3979 - acc: 0.8325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4149 - acc: 0.8138 - val_loss: 0.3597 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.90915\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4119 - acc: 0.8126 - val_loss: 0.3498 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.90915 to 0.90915, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-167-0.9092.hdf5\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4111 - acc: 0.8152 - val_loss: 0.3484 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.90915 to 0.91230, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-168-0.9123.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4075 - acc: 0.8165 - val_loss: 0.3491 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.91230\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4207 - acc: 0.8120 - val_loss: 0.3563 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.91230\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4089 - acc: 0.8175 - val_loss: 0.3492 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.91230\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4100 - acc: 0.8187 - val_loss: 0.3529 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.91230\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4064 - acc: 0.8197 - val_loss: 0.3463 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00173: val_acc improved from 0.91230 to 0.91265, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-173-0.9126.hdf5\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4093 - acc: 0.8150 - val_loss: 0.3499 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.91265 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-174-0.9151.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4052 - acc: 0.8152 - val_loss: 0.3470 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00175: val_acc improved from 0.91509 to 0.91719, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/2/weights-improvement-175-0.9172.hdf5\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4051 - acc: 0.8173 - val_loss: 0.3448 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.91719\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4062 - acc: 0.8153 - val_loss: 0.3421 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.91719\n",
      "Epoch 178/200\n",
      " 46/251 [====>.........................] - ETA: 4s - loss: 0.3271 - acc: 0.8732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3880 - acc: 0.8270 - val_loss: 0.3178 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.92593\n",
      "It has been  0:20:16.551193\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 1000, 26)     0           input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_171 (Conv1D)             (None, 1000, 10)     270         dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_172 (Conv1D)             (None, 1000, 10)     790         dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_173 (Conv1D)             (None, 1000, 10)     1310        dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_174 (Conv1D)             (None, 1000, 10)     2350        dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_175 (Conv1D)             (None, 1000, 10)     3910        dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 5000, 10)     0           conv1d_171[0][0]                 \n",
      "                                                                 conv1d_172[0][0]                 \n",
      "                                                                 conv1d_173[0][0]                 \n",
      "                                                                 conv1d_174[0][0]                 \n",
      "                                                                 conv1d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 500, 10)      0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 500, 314)     3454        max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 500, 314)     0           dense_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 500, 77)      24255       dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 500, 77)      0           dense_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 500, 8)       624         dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 500, 8)       0           dense_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_35 (Flatten)            (None, 4000)         0           dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 2)            8002        flatten_35[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 9s 38ms/step - loss: 0.6887 - acc: 0.6014 - val_loss: 0.6902 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70755, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-001-0.7075.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6988 - acc: 0.5606 - val_loss: 0.6864 - val_acc: 0.7973\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70755 to 0.79734, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-002-0.7973.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6903 - acc: 0.5846 - val_loss: 0.6716 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.79734\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6835 - acc: 0.6168 - val_loss: 0.6249 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79734\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6493 - acc: 0.6573 - val_loss: 0.5574 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79734\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6342 - acc: 0.6732 - val_loss: 0.5370 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79734\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6241 - acc: 0.6821 - val_loss: 0.5180 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79734\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6154 - acc: 0.6877 - val_loss: 0.5160 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79734\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6160 - acc: 0.6901 - val_loss: 0.5049 - val_acc: 0.7970\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79734\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6121 - acc: 0.6954 - val_loss: 0.5080 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79734 to 0.80189, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-010-0.8019.hdf5\n",
      "Epoch 11/200\n",
      "157/251 [=================>............] - ETA: 2s - loss: 0.6098 - acc: 0.7042"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5650 - acc: 0.7342 - val_loss: 0.5073 - val_acc: 0.7666\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.80189\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5631 - acc: 0.7297 - val_loss: 0.5033 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.80189\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5602 - acc: 0.7329 - val_loss: 0.5017 - val_acc: 0.7729\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.80189\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5587 - acc: 0.7334 - val_loss: 0.4972 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.80189\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5562 - acc: 0.7354 - val_loss: 0.4939 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.80189\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5524 - acc: 0.7388 - val_loss: 0.4907 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.80189\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5527 - acc: 0.7367 - val_loss: 0.4899 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.80189\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5498 - acc: 0.7403 - val_loss: 0.4859 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.80189\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5431 - acc: 0.7416 - val_loss: 0.4841 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.80189\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5427 - acc: 0.7443 - val_loss: 0.4818 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.80189\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5406 - acc: 0.7473 - val_loss: 0.4743 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.80189\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5370 - acc: 0.7476 - val_loss: 0.4707 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.80189 to 0.80294, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-065-0.8029.hdf5\n",
      "Epoch 66/200\n",
      "184/251 [====================>.........] - ETA: 1s - loss: 0.5199 - acc: 0.7565- "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4954 - acc: 0.7719 - val_loss: 0.4192 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.84906 to 0.85045, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-090-0.8505.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4927 - acc: 0.7712 - val_loss: 0.4165 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.85045 to 0.85465, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-091-0.8546.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4931 - acc: 0.7736 - val_loss: 0.4185 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.85465\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4898 - acc: 0.7759 - val_loss: 0.4139 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.85465\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4911 - acc: 0.7741 - val_loss: 0.4132 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.85465 to 0.85779, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-094-0.8578.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4892 - acc: 0.7737 - val_loss: 0.4090 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.85779 to 0.85779, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-095-0.8578.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4882 - acc: 0.7706 - val_loss: 0.4122 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.85779\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4869 - acc: 0.7741 - val_loss: 0.4072 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00097: val_acc improved from 0.85779 to 0.86094, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-097-0.8609.hdf5\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4838 - acc: 0.7778 - val_loss: 0.4059 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.86094 to 0.86548, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-098-0.8655.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4842 - acc: 0.7784 - val_loss: 0.4070 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.86548 to 0.86583, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-099-0.8658.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4830 - acc: 0.7781 - val_loss: 0.4039 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.86583 to 0.86862, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-100-0.8686.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4872 - acc: 0.7759 - val_loss: 0.4048 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.86862\n",
      "Epoch 102/200\n",
      "100/251 [==========>...................] - ETA: 3s - loss: 0.5050 - acc: 0.7654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4637 - acc: 0.7883 - val_loss: 0.3774 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.88365\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4541 - acc: 0.7913 - val_loss: 0.3702 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.88365 to 0.88435, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-126-0.8843.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4611 - acc: 0.7908 - val_loss: 0.3771 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.88435 to 0.88470, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-127-0.8847.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4539 - acc: 0.7954 - val_loss: 0.3670 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.88470 to 0.88539, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-128-0.8854.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4564 - acc: 0.7954 - val_loss: 0.3712 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.88539 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-129-0.8864.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4559 - acc: 0.7874 - val_loss: 0.3693 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.88644 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-130-0.8864.hdf5\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4532 - acc: 0.7947 - val_loss: 0.3666 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00131: val_acc improved from 0.88644 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-131-0.8878.hdf5\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4483 - acc: 0.7922 - val_loss: 0.3646 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.88784\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4526 - acc: 0.7919 - val_loss: 0.3679 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.88784 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-133-0.8878.hdf5\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4519 - acc: 0.7931 - val_loss: 0.3639 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.88784 to 0.88819, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-134-0.8882.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4486 - acc: 0.7967 - val_loss: 0.3610 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.88819 to 0.88854, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-135-0.8885.hdf5\n",
      "Epoch 136/200\n",
      "226/251 [==========================>...] - ETA: 0s - loss: 0.4289 - acc: 0.8075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4134 - acc: 0.8128 - val_loss: 0.3127 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.91090\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4183 - acc: 0.8105 - val_loss: 0.3160 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.91090 to 0.91230, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-181-0.9123.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4187 - acc: 0.8104 - val_loss: 0.3189 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.91230\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4165 - acc: 0.8111 - val_loss: 0.3169 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.91230\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4184 - acc: 0.8142 - val_loss: 0.3188 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.91230\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4189 - acc: 0.8119 - val_loss: 0.3140 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.91230\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4135 - acc: 0.8144 - val_loss: 0.3125 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.91230 to 0.91300, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-186-0.9130.hdf5\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4179 - acc: 0.8100 - val_loss: 0.3134 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.91300\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4095 - acc: 0.8178 - val_loss: 0.3076 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00188: val_acc improved from 0.91300 to 0.91335, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-188-0.9133.hdf5\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4136 - acc: 0.8136 - val_loss: 0.3098 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.91335 to 0.91405, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-189-0.9140.hdf5\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4106 - acc: 0.8188 - val_loss: 0.3119 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.91405\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4114 - acc: 0.8170 - val_loss: 0.3056 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.91405 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/3/weights-improvement-191-0.9151.hdf5\n",
      "Epoch 192/200\n",
      " 34/251 [===>..........................] - ETA: 4s - loss: 0.3138 - acc: 0.8725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6132 - acc: 0.6988 - val_loss: 0.4974 - val_acc: 0.7977\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80189\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6133 - acc: 0.6992 - val_loss: 0.4977 - val_acc: 0.7959\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80189\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6111 - acc: 0.7000 - val_loss: 0.4957 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80189\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6101 - acc: 0.7036 - val_loss: 0.4953 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.80189\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.6097 - acc: 0.7030 - val_loss: 0.4956 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.80189\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6084 - acc: 0.7008 - val_loss: 0.4955 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80189\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6077 - acc: 0.7025 - val_loss: 0.4939 - val_acc: 0.7865\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80189\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6062 - acc: 0.7044 - val_loss: 0.4931 - val_acc: 0.7865\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.80189\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6061 - acc: 0.7074 - val_loss: 0.4931 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80189\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6053 - acc: 0.7053 - val_loss: 0.4942 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80189\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6055 - acc: 0.7059 - val_loss: 0.4948 - val_acc: 0.7841\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80189\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6056 - acc: 0.7033 - val_loss: 0.4957 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.80189\n",
      "Epoch 28/200\n",
      "109/251 [============>.................] - ETA: 3s - loss: 0.6127 - acc: 0.6896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5810 - acc: 0.7209 - val_loss: 0.4935 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.80189\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5772 - acc: 0.7243 - val_loss: 0.4903 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.80189\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.5745 - acc: 0.7221 - val_loss: 0.4909 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.80189\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5756 - acc: 0.7192 - val_loss: 0.4897 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.80189\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5737 - acc: 0.7195 - val_loss: 0.4913 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.80189\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5723 - acc: 0.7222 - val_loss: 0.4891 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.80189\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5697 - acc: 0.7243 - val_loss: 0.4924 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.80189\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5661 - acc: 0.7267 - val_loss: 0.4867 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.80189\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5637 - acc: 0.7314 - val_loss: 0.4865 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.80189\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5590 - acc: 0.7330 - val_loss: 0.4825 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.80189\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5568 - acc: 0.7337 - val_loss: 0.4811 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.80189\n",
      "Epoch 61/200\n",
      "241/251 [===========================>..] - ETA: 0s - loss: 0.5510 - acc: 0.7387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4836 - acc: 0.7776 - val_loss: 0.3977 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.88120\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4828 - acc: 0.7770 - val_loss: 0.3979 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.88120\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4767 - acc: 0.7810 - val_loss: 0.3926 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.88120 to 0.88260, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-106-0.8826.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4743 - acc: 0.7807 - val_loss: 0.3909 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.88260\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4739 - acc: 0.7817 - val_loss: 0.3913 - val_acc: 0.8812\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.88260\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4695 - acc: 0.7868 - val_loss: 0.3870 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.88260\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4715 - acc: 0.7885 - val_loss: 0.3872 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.88260 to 0.88435, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-110-0.8843.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4687 - acc: 0.7828 - val_loss: 0.3879 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.88435\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4704 - acc: 0.7842 - val_loss: 0.3846 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.88435 to 0.88609, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-112-0.8861.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4672 - acc: 0.7848 - val_loss: 0.3807 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.88609\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4684 - acc: 0.7859 - val_loss: 0.3848 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.88609 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-114-0.8864.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4712 - acc: 0.7812 - val_loss: 0.3824 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.88644 to 0.88889, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-115-0.8889.hdf5\n",
      "Epoch 116/200\n",
      "153/251 [=================>............] - ETA: 2s - loss: 0.4508 - acc: 0.7965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4424 - acc: 0.7975 - val_loss: 0.3533 - val_acc: 0.8945\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.89762\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4395 - acc: 0.8032 - val_loss: 0.3470 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.89762\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4434 - acc: 0.8040 - val_loss: 0.3506 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.89762\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4451 - acc: 0.7986 - val_loss: 0.3490 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.89762\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4458 - acc: 0.7986 - val_loss: 0.3520 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.89762\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4364 - acc: 0.8026 - val_loss: 0.3435 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.89762\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4432 - acc: 0.7991 - val_loss: 0.3478 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.89762 to 0.89832, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-146-0.8983.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4387 - acc: 0.8024 - val_loss: 0.3456 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.89832\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4359 - acc: 0.8037 - val_loss: 0.3410 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.89832\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4368 - acc: 0.7990 - val_loss: 0.3414 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.89832\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4308 - acc: 0.8059 - val_loss: 0.3388 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.89832\n",
      "Epoch 151/200\n",
      "202/251 [=======================>......] - ETA: 1s - loss: 0.4087 - acc: 0.8155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4206 - acc: 0.8101 - val_loss: 0.3282 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.90252\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4140 - acc: 0.8151 - val_loss: 0.3270 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.90252\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4170 - acc: 0.8088 - val_loss: 0.3225 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.90252 to 0.90391, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-176-0.9039.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4174 - acc: 0.8150 - val_loss: 0.3234 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.90391\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4156 - acc: 0.8102 - val_loss: 0.3175 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.90391\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4098 - acc: 0.8162 - val_loss: 0.3174 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.90391\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4143 - acc: 0.8131 - val_loss: 0.3170 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.90391\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4082 - acc: 0.8178 - val_loss: 0.3100 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.90391 to 0.90461, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-181-0.9046.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4075 - acc: 0.8164 - val_loss: 0.3150 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.90461 to 0.90671, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/4/weights-improvement-182-0.9067.hdf5\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4156 - acc: 0.8167 - val_loss: 0.3260 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.90671\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4135 - acc: 0.8108 - val_loss: 0.3129 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.90671\n",
      "Epoch 185/200\n",
      "236/251 [===========================>..] - ETA: 0s - loss: 0.4081 - acc: 0.8157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6120 - acc: 0.6943 - val_loss: 0.6084 - val_acc: 0.6775\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.77324\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6088 - acc: 0.6978 - val_loss: 0.6061 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.77324\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6100 - acc: 0.6965 - val_loss: 0.6071 - val_acc: 0.6778\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.77324\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6072 - acc: 0.6974 - val_loss: 0.6045 - val_acc: 0.6848\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.77324\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6072 - acc: 0.6993 - val_loss: 0.6072 - val_acc: 0.6737\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.77324\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6063 - acc: 0.6979 - val_loss: 0.6079 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.77324\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6049 - acc: 0.7009 - val_loss: 0.6067 - val_acc: 0.6744\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77324\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6045 - acc: 0.7006 - val_loss: 0.6047 - val_acc: 0.6751\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77324\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6014 - acc: 0.7005 - val_loss: 0.6037 - val_acc: 0.6775\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.77324\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6029 - acc: 0.6984 - val_loss: 0.6053 - val_acc: 0.6737\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.77324\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6025 - acc: 0.7001 - val_loss: 0.6070 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.77324\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6008 - acc: 0.7037 - val_loss: 0.6049 - val_acc: 0.6751\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.77324\n",
      "Epoch 40/200\n",
      "160/251 [==================>...........] - ETA: 2s - loss: 0.5968 - acc: 0.7101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5360 - acc: 0.7481 - val_loss: 0.5452 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.77324\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5404 - acc: 0.7441 - val_loss: 0.5456 - val_acc: 0.7236\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.77324\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5364 - acc: 0.7469 - val_loss: 0.5376 - val_acc: 0.7338\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.77324\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5342 - acc: 0.7475 - val_loss: 0.5378 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.77324\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5332 - acc: 0.7500 - val_loss: 0.5305 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.77324\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5276 - acc: 0.7511 - val_loss: 0.5219 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.77324\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5254 - acc: 0.7551 - val_loss: 0.5190 - val_acc: 0.7523\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.77324\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5234 - acc: 0.7569 - val_loss: 0.5126 - val_acc: 0.7614\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.77324\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5208 - acc: 0.7587 - val_loss: 0.5176 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.77324\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5176 - acc: 0.7579 - val_loss: 0.5131 - val_acc: 0.7638\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.77324\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5169 - acc: 0.7633 - val_loss: 0.5059 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.77324\n",
      "Epoch 75/200\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.4761 - acc: 0.7869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4754 - acc: 0.7832 - val_loss: 0.4265 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.84416 to 0.85360, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-099-0.8536.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4797 - acc: 0.7770 - val_loss: 0.4368 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.85360\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4738 - acc: 0.7836 - val_loss: 0.4299 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00101: val_acc improved from 0.85360 to 0.85395, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-101-0.8539.hdf5\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4734 - acc: 0.7793 - val_loss: 0.4272 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.85395 to 0.85500, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-102-0.8550.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4766 - acc: 0.7810 - val_loss: 0.4304 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.85500 to 0.85570, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-103-0.8557.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4736 - acc: 0.7826 - val_loss: 0.4275 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.85570 to 0.85814, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-104-0.8581.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4690 - acc: 0.7877 - val_loss: 0.4186 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.85814 to 0.86513, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-105-0.8651.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4698 - acc: 0.7856 - val_loss: 0.4217 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.86513\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4713 - acc: 0.7845 - val_loss: 0.4099 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.86513 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-107-0.8693.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4639 - acc: 0.7883 - val_loss: 0.4080 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.86932\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4685 - acc: 0.7843 - val_loss: 0.4141 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.86932\n",
      "Epoch 110/200\n",
      "141/251 [===============>..............] - ETA: 2s - loss: 0.4707 - acc: 0.7829"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4188 - acc: 0.8125 - val_loss: 0.3446 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.90636 to 0.90706, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-154-0.9071.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4196 - acc: 0.8130 - val_loss: 0.3390 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.90706\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4218 - acc: 0.8122 - val_loss: 0.3425 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.90706\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4184 - acc: 0.8108 - val_loss: 0.3420 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.90706\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4173 - acc: 0.8123 - val_loss: 0.3404 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.90706\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.4146 - acc: 0.8136 - val_loss: 0.3314 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.90706\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4122 - acc: 0.8155 - val_loss: 0.3342 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.90706\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4222 - acc: 0.8085 - val_loss: 0.3492 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.90706\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4211 - acc: 0.8084 - val_loss: 0.3446 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.90706\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4170 - acc: 0.8118 - val_loss: 0.3375 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.90706\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4123 - acc: 0.8151 - val_loss: 0.3304 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.90706\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4177 - acc: 0.8122 - val_loss: 0.3413 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.90706\n",
      "Epoch 166/200\n",
      " 64/251 [======>.......................] - ETA: 4s - loss: 0.3480 - acc: 0.8507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3949 - acc: 0.8232 - val_loss: 0.3120 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.91964\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3917 - acc: 0.8243 - val_loss: 0.3089 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.91964\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3942 - acc: 0.8238 - val_loss: 0.3046 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.91964 to 0.92243, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-192-0.9224.hdf5\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3926 - acc: 0.8253 - val_loss: 0.3037 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.92243\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3889 - acc: 0.8296 - val_loss: 0.3014 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.92243 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-194-0.9231.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3939 - acc: 0.8280 - val_loss: 0.2993 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.92313\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 24ms/step - loss: 0.3974 - acc: 0.8232 - val_loss: 0.3066 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.92313\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3885 - acc: 0.8274 - val_loss: 0.2971 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00197: val_acc improved from 0.92313 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-197-0.9238.hdf5\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3865 - acc: 0.8272 - val_loss: 0.2943 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.92383\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3880 - acc: 0.8244 - val_loss: 0.2964 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.92383\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3903 - acc: 0.8245 - val_loss: 0.2920 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00200: val_acc improved from 0.92383 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/5/weights-improvement-200-0.9238.hdf5\n",
      "It has been  0:20:49.293827\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_38 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 1000, 26)     0           input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_186 (Conv1D)             (None, 1000, 10)     270         dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_187 (Conv1D)             (None, 1000, 10)     790         dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_188 (Conv1D)             (None, 1000, 10)     1310        dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_189 (Conv1D)             (None, 1000, 10)     2350        dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_190 (Conv1D)             (None, 1000, 10)     3910        dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 5000, 10)     0           conv1d_186[0][0]                 \n",
      "                                                                 conv1d_187[0][0]                 \n",
      "                                                                 conv1d_188[0][0]                 \n",
      "                                                                 conv1d_189[0][0]                 \n",
      "                                                                 conv1d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 500, 10)      0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 500, 314)     3454        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 500, 314)     0           dense_149[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 500, 77)      24255       dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 500, 77)      0           dense_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 500, 8)       624         dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 500, 8)       0           dense_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_38 (Flatten)            (None, 4000)         0           dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 2)            8002        flatten_38[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "181/251 [====================>.........] - ETA: 2s - loss: 0.6902 - acc: 0.6146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6097 - acc: 0.7013 - val_loss: 0.5410 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.79560\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6087 - acc: 0.7020 - val_loss: 0.5375 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.79560\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6071 - acc: 0.7027 - val_loss: 0.5375 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.79560\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6057 - acc: 0.7022 - val_loss: 0.5375 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79560\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6051 - acc: 0.7039 - val_loss: 0.5356 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79560\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6036 - acc: 0.7059 - val_loss: 0.5367 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.79560\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6032 - acc: 0.7059 - val_loss: 0.5378 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.79560\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6033 - acc: 0.7055 - val_loss: 0.5363 - val_acc: 0.7809\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.79560\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6021 - acc: 0.7080 - val_loss: 0.5358 - val_acc: 0.7816\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.79560\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6005 - acc: 0.7071 - val_loss: 0.5351 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79560\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6010 - acc: 0.7098 - val_loss: 0.5319 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79560\n",
      "Epoch 35/200\n",
      "190/251 [=====================>........] - ETA: 1s - loss: 0.5811 - acc: 0.7204"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5154 - acc: 0.7570 - val_loss: 0.4386 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.82949 to 0.83403, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-079-0.8340.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5142 - acc: 0.7553 - val_loss: 0.4371 - val_acc: 0.8403\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.83403 to 0.84032, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-080-0.8403.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5099 - acc: 0.7610 - val_loss: 0.4387 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.84032\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5124 - acc: 0.7613 - val_loss: 0.4304 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.84032 to 0.84661, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-082-0.8466.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5134 - acc: 0.7572 - val_loss: 0.4363 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.84661\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5111 - acc: 0.7627 - val_loss: 0.4340 - val_acc: 0.8400\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.84661\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5053 - acc: 0.7651 - val_loss: 0.4303 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.84661\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5093 - acc: 0.7648 - val_loss: 0.4292 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.84661 to 0.84731, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-086-0.8473.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5059 - acc: 0.7661 - val_loss: 0.4309 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.84731 to 0.85220, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-087-0.8522.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5068 - acc: 0.7647 - val_loss: 0.4272 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.85220\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5024 - acc: 0.7666 - val_loss: 0.4246 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.85220\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5032 - acc: 0.7652 - val_loss: 0.4292 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.85220\n",
      "Epoch 91/200\n",
      "196/251 [======================>.......] - ETA: 1s - loss: 0.4749 - acc: 0.7849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4736 - acc: 0.7775 - val_loss: 0.3951 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00115: val_acc improved from 0.88190 to 0.88295, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-115-0.8829.hdf5\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4725 - acc: 0.7812 - val_loss: 0.3913 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.88295 to 0.88470, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-116-0.8847.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4724 - acc: 0.7810 - val_loss: 0.3894 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.88470 to 0.88574, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-117-0.8857.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4709 - acc: 0.7815 - val_loss: 0.3894 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00118: val_acc improved from 0.88574 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-118-0.8878.hdf5\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4644 - acc: 0.7864 - val_loss: 0.3851 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00119: val_acc improved from 0.88784 to 0.88889, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-119-0.8889.hdf5\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4721 - acc: 0.7811 - val_loss: 0.3878 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.88889\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4669 - acc: 0.7878 - val_loss: 0.3871 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.88889\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4662 - acc: 0.7855 - val_loss: 0.3820 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.88889\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4630 - acc: 0.7868 - val_loss: 0.3835 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.88889\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4633 - acc: 0.7844 - val_loss: 0.3797 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.88889\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4635 - acc: 0.7879 - val_loss: 0.3812 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.88889 to 0.89099, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-125-0.8910.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4583 - acc: 0.7873 - val_loss: 0.3738 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.89099\n",
      "Epoch 127/200\n",
      " 37/251 [===>..........................] - ETA: 4s - loss: 0.3669 - acc: 0.8564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4418 - acc: 0.7988 - val_loss: 0.3520 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.90776 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-149-0.9095.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4460 - acc: 0.8000 - val_loss: 0.3529 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.90950\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4358 - acc: 0.8028 - val_loss: 0.3468 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.90950\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4411 - acc: 0.7974 - val_loss: 0.3528 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.90950\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4400 - acc: 0.7991 - val_loss: 0.3446 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.90950\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4381 - acc: 0.7980 - val_loss: 0.3422 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.90950 to 0.91195, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-154-0.9119.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4349 - acc: 0.8000 - val_loss: 0.3431 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.91195\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4296 - acc: 0.8057 - val_loss: 0.3331 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.91195 to 0.91579, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/6/weights-improvement-156-0.9158.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4354 - acc: 0.7987 - val_loss: 0.3432 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.91579\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4342 - acc: 0.8040 - val_loss: 0.3356 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.91579\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4322 - acc: 0.8048 - val_loss: 0.3382 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.91579\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4315 - acc: 0.8064 - val_loss: 0.3345 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.91579\n",
      "Epoch 161/200\n",
      " 52/251 [=====>........................] - ETA: 4s - loss: 0.3433 - acc: 0.8622"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6758 - acc: 0.6186 - val_loss: 0.6300 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77987\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6620 - acc: 0.6420 - val_loss: 0.6095 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.77987 to 0.79036, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-005-0.7904.hdf5\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6332 - acc: 0.6782 - val_loss: 0.5582 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79036\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6208 - acc: 0.6889 - val_loss: 0.5337 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79036\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6160 - acc: 0.6904 - val_loss: 0.5339 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.79036 to 0.79560, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-008-0.7956.hdf5\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6152 - acc: 0.6948 - val_loss: 0.5308 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.79560 to 0.80084, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-009-0.8008.hdf5\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6138 - acc: 0.6961 - val_loss: 0.5293 - val_acc: 0.8019\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.80084 to 0.80189, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-010-0.8019.hdf5\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6120 - acc: 0.6971 - val_loss: 0.5310 - val_acc: 0.7984\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80189\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6123 - acc: 0.7017 - val_loss: 0.5299 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.80189\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6116 - acc: 0.7002 - val_loss: 0.5342 - val_acc: 0.7918\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80189\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6111 - acc: 0.6996 - val_loss: 0.5316 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80189\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6106 - acc: 0.7034 - val_loss: 0.5338 - val_acc: 0.7911\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80189\n",
      "Epoch 16/200\n",
      " 82/251 [========>.....................] - ETA: 3s - loss: 0.6149 - acc: 0.6879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5943 - acc: 0.7123 - val_loss: 0.5438 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.80189\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5923 - acc: 0.7137 - val_loss: 0.5419 - val_acc: 0.7537\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80189\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5922 - acc: 0.7137 - val_loss: 0.5433 - val_acc: 0.7512\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.80189\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5921 - acc: 0.7125 - val_loss: 0.5434 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.80189\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5910 - acc: 0.7144 - val_loss: 0.5428 - val_acc: 0.7502\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.80189\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5892 - acc: 0.7161 - val_loss: 0.5427 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80189\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5911 - acc: 0.7129 - val_loss: 0.5431 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.80189\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5896 - acc: 0.7162 - val_loss: 0.5450 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.80189\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5873 - acc: 0.7143 - val_loss: 0.5413 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.80189\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5873 - acc: 0.7147 - val_loss: 0.5422 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.80189\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5850 - acc: 0.7174 - val_loss: 0.5422 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.80189\n",
      "Epoch 50/200\n",
      "144/251 [================>.............] - ETA: 2s - loss: 0.5847 - acc: 0.7133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5427 - acc: 0.7458 - val_loss: 0.5008 - val_acc: 0.7925\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.80189\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5383 - acc: 0.7489 - val_loss: 0.5040 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.80189\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5400 - acc: 0.7469 - val_loss: 0.4951 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.80189\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5342 - acc: 0.7515 - val_loss: 0.4990 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.80189\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5323 - acc: 0.7547 - val_loss: 0.4964 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.80189 to 0.80398, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-075-0.8040.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5301 - acc: 0.7517 - val_loss: 0.4952 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.80398 to 0.80853, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-076-0.8085.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5261 - acc: 0.7569 - val_loss: 0.4888 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.80853 to 0.81167, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-077-0.8117.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5276 - acc: 0.7528 - val_loss: 0.4888 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.81167 to 0.81167, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-078-0.8117.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5272 - acc: 0.7554 - val_loss: 0.4838 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.81167 to 0.81342, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-079-0.8134.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5238 - acc: 0.7562 - val_loss: 0.4828 - val_acc: 0.8155\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.81342 to 0.81551, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-080-0.8155.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5253 - acc: 0.7510 - val_loss: 0.4874 - val_acc: 0.8124\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.81551\n",
      "Epoch 82/200\n",
      "211/251 [========================>.....] - ETA: 0s - loss: 0.4874 - acc: 0.7830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4739 - acc: 0.7823 - val_loss: 0.4179 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.86827 to 0.86897, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-124-0.8690.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4722 - acc: 0.7840 - val_loss: 0.4216 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.86897\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4693 - acc: 0.7846 - val_loss: 0.4208 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.86897\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4684 - acc: 0.7860 - val_loss: 0.4195 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.86897\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4662 - acc: 0.7860 - val_loss: 0.4130 - val_acc: 0.8697\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.86897 to 0.86967, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-128-0.8697.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4691 - acc: 0.7863 - val_loss: 0.4042 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.86967 to 0.87317, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-129-0.8732.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4642 - acc: 0.7888 - val_loss: 0.4039 - val_acc: 0.8770\n",
      "\n",
      "Epoch 00130: val_acc improved from 0.87317 to 0.87701, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-130-0.8770.hdf5\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4638 - acc: 0.7865 - val_loss: 0.4058 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.87701\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4596 - acc: 0.7859 - val_loss: 0.4001 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.87701\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4635 - acc: 0.7880 - val_loss: 0.4018 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.87701 to 0.88155, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-133-0.8816.hdf5\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4663 - acc: 0.7882 - val_loss: 0.4067 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.88155\n",
      "Epoch 135/200\n",
      "220/251 [=========================>....] - ETA: 0s - loss: 0.4153 - acc: 0.8160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4428 - acc: 0.7977 - val_loss: 0.3736 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.89832 to 0.89832, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-159-0.8983.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4418 - acc: 0.7956 - val_loss: 0.3735 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00160: val_acc improved from 0.89832 to 0.90287, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-160-0.9029.hdf5\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4429 - acc: 0.7981 - val_loss: 0.3811 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.90287\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4325 - acc: 0.8045 - val_loss: 0.3694 - val_acc: 0.9039\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.90287 to 0.90391, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-162-0.9039.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4365 - acc: 0.8020 - val_loss: 0.3783 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.90391\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4364 - acc: 0.8003 - val_loss: 0.3739 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00164: val_acc improved from 0.90391 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-164-0.9043.hdf5\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4359 - acc: 0.8067 - val_loss: 0.3721 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.90426\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4355 - acc: 0.8037 - val_loss: 0.3649 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.90426 to 0.90601, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-166-0.9060.hdf5\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4304 - acc: 0.8071 - val_loss: 0.3621 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.90601\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4300 - acc: 0.8073 - val_loss: 0.3675 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.90601\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4255 - acc: 0.8100 - val_loss: 0.3608 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.90601\n",
      "Epoch 170/200\n",
      "125/251 [=============>................] - ETA: 2s - loss: 0.4455 - acc: 0.7876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4187 - acc: 0.8077 - val_loss: 0.3513 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.91300\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4203 - acc: 0.8099 - val_loss: 0.3435 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00192: val_acc improved from 0.91300 to 0.91300, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-192-0.9130.hdf5\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4122 - acc: 0.8144 - val_loss: 0.3470 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.91300\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4107 - acc: 0.8153 - val_loss: 0.3499 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.91300\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4160 - acc: 0.8135 - val_loss: 0.3464 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00195: val_acc improved from 0.91300 to 0.91440, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-195-0.9144.hdf5\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4173 - acc: 0.8105 - val_loss: 0.3492 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.91440\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4165 - acc: 0.8130 - val_loss: 0.3455 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.91440\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4128 - acc: 0.8144 - val_loss: 0.3453 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.91440 to 0.91579, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/7/weights-improvement-198-0.9158.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4114 - acc: 0.8136 - val_loss: 0.3399 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.91579\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4139 - acc: 0.8142 - val_loss: 0.3433 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.91579\n",
      "It has been  0:21:09.169113\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_40 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 1000, 26)     0           input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_196 (Conv1D)             (None, 1000, 10)     270         dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_197 (Conv1D)             (None, 1000, 10)     790         dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_198 (Conv1D)             (None, 1000, 10)     1310        dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_199 (Conv1D)             (None, 1000, 10)     2350        dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_200 (Conv1D)             (None, 1000, 10)     3910        dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 5000, 10)     0           conv1d_196[0][0]                 \n",
      "                                                                 conv1d_197[0][0]                 \n",
      "                                                                 conv1d_198[0][0]                 \n",
      "                                                                 conv1d_199[0][0]                 \n",
      "                                                                 conv1d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 500, 10)      0           concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 500, 314)     3454        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 500, 314)     0           dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 500, 77)      24255       dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 500, 77)      0           dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 500, 8)       624         dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 500, 8)       0           dense_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 4000)         0           dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 2)            8002        flatten_40[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 10s 40ms/step - loss: 0.6916 - acc: 0.5973 - val_loss: 0.6935 - val_acc: 0.3235\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.32355, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-001-0.3235.hdf5\n",
      "Epoch 2/200\n",
      "199/251 [======================>.......] - ETA: 1s - loss: 0.6835 - acc: 0.5777"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5962 - acc: 0.7086 - val_loss: 0.5052 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.79909\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5972 - acc: 0.7103 - val_loss: 0.5053 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.79909\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5952 - acc: 0.7106 - val_loss: 0.5044 - val_acc: 0.7676\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.79909\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5951 - acc: 0.7086 - val_loss: 0.5041 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.79909\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5941 - acc: 0.7112 - val_loss: 0.5047 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.79909\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5937 - acc: 0.7119 - val_loss: 0.5035 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.79909\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5927 - acc: 0.7115 - val_loss: 0.5019 - val_acc: 0.7680\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.79909\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5933 - acc: 0.7092 - val_loss: 0.5042 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.79909\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5918 - acc: 0.7112 - val_loss: 0.5030 - val_acc: 0.7666\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.79909\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5923 - acc: 0.7114 - val_loss: 0.5018 - val_acc: 0.7694\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.79909\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5893 - acc: 0.7115 - val_loss: 0.5023 - val_acc: 0.7683\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.79909\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5899 - acc: 0.7115 - val_loss: 0.5011 - val_acc: 0.7690\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.79909\n",
      "Epoch 58/200\n",
      "106/251 [===========>..................] - ETA: 3s - loss: 0.6040 - acc: 0.6882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5534 - acc: 0.7359 - val_loss: 0.4756 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.80224\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5479 - acc: 0.7387 - val_loss: 0.4724 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.80224 to 0.80713, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-082-0.8071.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5502 - acc: 0.7385 - val_loss: 0.4735 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.80713\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5472 - acc: 0.7373 - val_loss: 0.4711 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.80713 to 0.80922, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-084-0.8092.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5455 - acc: 0.7428 - val_loss: 0.4693 - val_acc: 0.8106\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.80922 to 0.81062, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-085-0.8106.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5445 - acc: 0.7399 - val_loss: 0.4687 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00086: val_acc improved from 0.81062 to 0.81272, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-086-0.8127.hdf5\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5454 - acc: 0.7402 - val_loss: 0.4700 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.81272\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5429 - acc: 0.7435 - val_loss: 0.4669 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.81272\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5429 - acc: 0.7438 - val_loss: 0.4657 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.81272\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5408 - acc: 0.7445 - val_loss: 0.4636 - val_acc: 0.8138\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.81272 to 0.81377, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-090-0.8138.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5419 - acc: 0.7435 - val_loss: 0.4644 - val_acc: 0.8159\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.81377 to 0.81586, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-091-0.8159.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5388 - acc: 0.7419 - val_loss: 0.4616 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.81586 to 0.81691, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-092-0.8169.hdf5\n",
      "Epoch 93/200\n",
      "192/251 [=====================>........] - ETA: 1s - loss: 0.5206 - acc: 0.7595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5088 - acc: 0.7673 - val_loss: 0.4298 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.84941 to 0.85150, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-116-0.8515.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5067 - acc: 0.7678 - val_loss: 0.4280 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.85150\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5096 - acc: 0.7681 - val_loss: 0.4297 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.85150\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5093 - acc: 0.7629 - val_loss: 0.4294 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.85150\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5069 - acc: 0.7651 - val_loss: 0.4247 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.85150\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5049 - acc: 0.7683 - val_loss: 0.4266 - val_acc: 0.8522\n",
      "\n",
      "Epoch 00121: val_acc improved from 0.85150 to 0.85220, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-121-0.8522.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5049 - acc: 0.7677 - val_loss: 0.4222 - val_acc: 0.8557\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.85220 to 0.85570, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-122-0.8557.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5068 - acc: 0.7666 - val_loss: 0.4258 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.85570\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5076 - acc: 0.7657 - val_loss: 0.4251 - val_acc: 0.8536\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.85570\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5005 - acc: 0.7734 - val_loss: 0.4200 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.85570 to 0.85954, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-125-0.8595.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5007 - acc: 0.7708 - val_loss: 0.4203 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.85954\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5054 - acc: 0.7697 - val_loss: 0.4208 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.85954 to 0.85954, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-127-0.8595.hdf5\n",
      "Epoch 128/200\n",
      " 61/251 [======>.......................] - ETA: 4s - loss: 0.4385 - acc: 0.8212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4487 - acc: 0.8015 - val_loss: 0.3520 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.89273\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4492 - acc: 0.7947 - val_loss: 0.3533 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.89273\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4450 - acc: 0.7989 - val_loss: 0.3468 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00174: val_acc improved from 0.89273 to 0.89308, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-174-0.8931.hdf5\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4404 - acc: 0.8037 - val_loss: 0.3448 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00175: val_acc improved from 0.89308 to 0.89413, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-175-0.8941.hdf5\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4416 - acc: 0.8000 - val_loss: 0.3420 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.89413 to 0.89483, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-176-0.8948.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4430 - acc: 0.7992 - val_loss: 0.3453 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.89483\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4360 - acc: 0.8088 - val_loss: 0.3423 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.89483 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-178-0.8969.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4405 - acc: 0.8023 - val_loss: 0.3457 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.89693\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4415 - acc: 0.8043 - val_loss: 0.3443 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.89693\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4445 - acc: 0.7965 - val_loss: 0.3441 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.89693\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4360 - acc: 0.8053 - val_loss: 0.3402 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00182: val_acc improved from 0.89693 to 0.89902, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-182-0.8990.hdf5\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4350 - acc: 0.8052 - val_loss: 0.3363 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.89902 to 0.89937, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/8/weights-improvement-183-0.8994.hdf5\n",
      "Epoch 184/200\n",
      "103/251 [===========>..................] - ETA: 3s - loss: 0.4676 - acc: 0.7869"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6143 - acc: 0.6882 - val_loss: 0.5502 - val_acc: 0.7904\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80119\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6239 - acc: 0.6876 - val_loss: 0.5417 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80119\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6155 - acc: 0.6929 - val_loss: 0.5495 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.80119 to 0.80259, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-010-0.8026.hdf5\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6216 - acc: 0.6905 - val_loss: 0.5444 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.80259\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6142 - acc: 0.6983 - val_loss: 0.5460 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80259 to 0.80294, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-012-0.8029.hdf5\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6167 - acc: 0.6952 - val_loss: 0.5444 - val_acc: 0.8022\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.80294\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6140 - acc: 0.6971 - val_loss: 0.5452 - val_acc: 0.7966\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.80294\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6141 - acc: 0.7008 - val_loss: 0.5416 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.80294\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6127 - acc: 0.7014 - val_loss: 0.5471 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.80294\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6139 - acc: 0.7015 - val_loss: 0.5459 - val_acc: 0.7893\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.80294\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6102 - acc: 0.7024 - val_loss: 0.5472 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.80294\n",
      "Epoch 19/200\n",
      " 84/251 [=========>....................] - ETA: 3s - loss: 0.6088 - acc: 0.6978"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5942 - acc: 0.7142 - val_loss: 0.5672 - val_acc: 0.7565\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80294\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5908 - acc: 0.7146 - val_loss: 0.5678 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.80294\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5910 - acc: 0.7152 - val_loss: 0.5660 - val_acc: 0.7526\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.80294\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5909 - acc: 0.7182 - val_loss: 0.5699 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.80294\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5905 - acc: 0.7151 - val_loss: 0.5658 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80294\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5869 - acc: 0.7153 - val_loss: 0.5710 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.80294\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5873 - acc: 0.7174 - val_loss: 0.5705 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.80294\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5845 - acc: 0.7170 - val_loss: 0.5710 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.80294\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5849 - acc: 0.7165 - val_loss: 0.5700 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.80294\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5817 - acc: 0.7189 - val_loss: 0.5663 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.80294\n",
      "Epoch 50/200\n",
      "242/251 [===========================>..] - ETA: 0s - loss: 0.5780 - acc: 0.7212"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5551 - acc: 0.7321 - val_loss: 0.5402 - val_acc: 0.7512\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.80294\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5512 - acc: 0.7341 - val_loss: 0.5506 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.80294\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5524 - acc: 0.7384 - val_loss: 0.5341 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.80294\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5493 - acc: 0.7399 - val_loss: 0.5449 - val_acc: 0.7428\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.80294\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5474 - acc: 0.7428 - val_loss: 0.5355 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.80294\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5472 - acc: 0.7421 - val_loss: 0.5315 - val_acc: 0.7558\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.80294\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5421 - acc: 0.7472 - val_loss: 0.5365 - val_acc: 0.7565\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.80294\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5411 - acc: 0.7462 - val_loss: 0.5262 - val_acc: 0.7645\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.80294\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5389 - acc: 0.7462 - val_loss: 0.5288 - val_acc: 0.7645\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.80294\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5362 - acc: 0.7470 - val_loss: 0.5179 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.80294\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5342 - acc: 0.7483 - val_loss: 0.5191 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.80294\n",
      "Epoch 75/200\n",
      " 13/251 [>.............................] - ETA: 5s - loss: 0.4865 - acc: 0.7778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4976 - acc: 0.7684 - val_loss: 0.4587 - val_acc: 0.8354\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.83962\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4993 - acc: 0.7683 - val_loss: 0.4566 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00098: val_acc improved from 0.83962 to 0.83962, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-098-0.8396.hdf5\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4954 - acc: 0.7702 - val_loss: 0.4494 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.83962 to 0.84731, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-099-0.8473.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4921 - acc: 0.7735 - val_loss: 0.4478 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.84731\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4928 - acc: 0.7687 - val_loss: 0.4465 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.84731\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4920 - acc: 0.7732 - val_loss: 0.4457 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.84731 to 0.85150, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-102-0.8515.hdf5\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4931 - acc: 0.7725 - val_loss: 0.4438 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.85150\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4882 - acc: 0.7750 - val_loss: 0.4406 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.85150 to 0.85465, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-104-0.8546.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4864 - acc: 0.7748 - val_loss: 0.4365 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.85465 to 0.85674, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-105-0.8567.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4852 - acc: 0.7732 - val_loss: 0.4329 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00106: val_acc improved from 0.85674 to 0.85814, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-106-0.8581.hdf5\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4852 - acc: 0.7767 - val_loss: 0.4399 - val_acc: 0.8581\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.85814\n",
      "Epoch 108/200\n",
      " 58/251 [=====>........................] - ETA: 4s - loss: 0.4097 - acc: 0.8279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4346 - acc: 0.7993 - val_loss: 0.3552 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.89727\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4336 - acc: 0.8057 - val_loss: 0.3500 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.89727 to 0.89937, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-158-0.8994.hdf5\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4301 - acc: 0.8046 - val_loss: 0.3476 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.89937 to 0.89972, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-159-0.8997.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4351 - acc: 0.8006 - val_loss: 0.3547 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.89972\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4308 - acc: 0.8043 - val_loss: 0.3502 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.89972\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4338 - acc: 0.8049 - val_loss: 0.3494 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00162: val_acc improved from 0.89972 to 0.90042, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-162-0.9004.hdf5\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4314 - acc: 0.8033 - val_loss: 0.3493 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.90042 to 0.90287, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-163-0.9029.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4324 - acc: 0.8025 - val_loss: 0.3521 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.90287\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4310 - acc: 0.8074 - val_loss: 0.3517 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.90287\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4296 - acc: 0.8030 - val_loss: 0.3519 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.90287\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4252 - acc: 0.8077 - val_loss: 0.3448 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.90287 to 0.90461, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-167-0.9046.hdf5\n",
      "Epoch 168/200\n",
      "124/251 [=============>................] - ETA: 2s - loss: 0.4310 - acc: 0.7976"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4187 - acc: 0.8101 - val_loss: 0.3333 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.90741 to 0.90741, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-181-0.9074.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4157 - acc: 0.8142 - val_loss: 0.3304 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.90741\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4147 - acc: 0.8121 - val_loss: 0.3307 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.90741\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4160 - acc: 0.8137 - val_loss: 0.3337 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.90741\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4136 - acc: 0.8111 - val_loss: 0.3297 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.90741\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4170 - acc: 0.8141 - val_loss: 0.3328 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.90741 to 0.90811, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-186-0.9081.hdf5\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4129 - acc: 0.8147 - val_loss: 0.3293 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.90811\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4110 - acc: 0.8159 - val_loss: 0.3277 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.90811\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4120 - acc: 0.8162 - val_loss: 0.3313 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00189: val_acc improved from 0.90811 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-189-0.9095.hdf5\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4157 - acc: 0.8113 - val_loss: 0.3287 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.90950 to 0.90950, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-190-0.9095.hdf5\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4160 - acc: 0.8119 - val_loss: 0.3242 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00191: val_acc improved from 0.90950 to 0.90985, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/strf_padding/9/weights-improvement-191-0.9099.hdf5\n",
      "Epoch 192/200\n",
      "177/251 [====================>.........] - ETA: 1s - loss: 0.3965 - acc: 0.8234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6080 - acc: 0.7022 - val_loss: 0.5923 - val_acc: 0.7334\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.77114\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6072 - acc: 0.7033 - val_loss: 0.5905 - val_acc: 0.7299\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.77114\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6050 - acc: 0.7050 - val_loss: 0.5873 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77114\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6053 - acc: 0.7044 - val_loss: 0.5856 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.77114\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.6005 - acc: 0.7069 - val_loss: 0.5821 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.77114\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5981 - acc: 0.7104 - val_loss: 0.5794 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.77114\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5984 - acc: 0.7075 - val_loss: 0.5767 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.77114\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5974 - acc: 0.7086 - val_loss: 0.5760 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.77114\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5958 - acc: 0.7086 - val_loss: 0.5748 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.77114\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5918 - acc: 0.7106 - val_loss: 0.5674 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.77114\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5899 - acc: 0.7116 - val_loss: 0.5661 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.77114\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5889 - acc: 0.7130 - val_loss: 0.5624 - val_acc: 0.7435\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.77114\n",
      "Epoch 28/200\n",
      "108/251 [===========>..................] - ETA: 3s - loss: 0.6020 - acc: 0.6840"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_acc improved from 0.92103 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-081-0.9231.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4290 - acc: 0.8059 - val_loss: 0.3099 - val_acc: 0.9252\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.92313 to 0.92523, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-082-0.9252.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4251 - acc: 0.8106 - val_loss: 0.3061 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00083: val_acc improved from 0.92523 to 0.92558, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-083-0.9256.hdf5\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4237 - acc: 0.8074 - val_loss: 0.3030 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.92558 to 0.92802, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-084-0.9280.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4212 - acc: 0.8103 - val_loss: 0.2982 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.92802\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4157 - acc: 0.8127 - val_loss: 0.3123 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.92802\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4197 - acc: 0.8109 - val_loss: 0.2992 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.92802\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4207 - acc: 0.8103 - val_loss: 0.3067 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.92802\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4181 - acc: 0.8144 - val_loss: 0.3042 - val_acc: 0.9266\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.92802\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4103 - acc: 0.8165 - val_loss: 0.2999 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.92802\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4164 - acc: 0.8117 - val_loss: 0.3004 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.92802\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4134 - acc: 0.8158 - val_loss: 0.2986 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.92802 to 0.92872, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-092-0.9287.hdf5\n",
      "Epoch 93/200\n",
      "113/251 [============>.................] - ETA: 3s - loss: 0.4215 - acc: 0.8096"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3968 - acc: 0.8237 - val_loss: 0.2808 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93816\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3884 - acc: 0.8291 - val_loss: 0.2702 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93816\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3915 - acc: 0.8258 - val_loss: 0.2697 - val_acc: 0.9361\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93816\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3871 - acc: 0.8334 - val_loss: 0.2602 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.93816 to 0.93920, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-110-0.9392.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3859 - acc: 0.8293 - val_loss: 0.2573 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00111: val_acc improved from 0.93920 to 0.94060, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-111-0.9406.hdf5\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3928 - acc: 0.8244 - val_loss: 0.2622 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.94060\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3873 - acc: 0.8320 - val_loss: 0.2583 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.94060\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3802 - acc: 0.8365 - val_loss: 0.2493 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.94060\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3807 - acc: 0.8344 - val_loss: 0.2536 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.94060\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3754 - acc: 0.8316 - val_loss: 0.2516 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.94060 to 0.94270, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-116-0.9427.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3763 - acc: 0.8344 - val_loss: 0.2567 - val_acc: 0.9423\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.94270\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3768 - acc: 0.8330 - val_loss: 0.2608 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.94270\n",
      "Epoch 119/200\n",
      "100/251 [==========>...................] - ETA: 3s - loss: 0.3841 - acc: 0.8278"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3519 - acc: 0.8447 - val_loss: 0.2247 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95807\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3540 - acc: 0.8458 - val_loss: 0.2235 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95807\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3517 - acc: 0.8489 - val_loss: 0.2277 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00145: val_acc improved from 0.95807 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-145-0.9595.hdf5\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3433 - acc: 0.8524 - val_loss: 0.2127 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95947\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3468 - acc: 0.8507 - val_loss: 0.2198 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.95947 to 0.96087, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-147-0.9609.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3561 - acc: 0.8470 - val_loss: 0.2336 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.96087\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3454 - acc: 0.8493 - val_loss: 0.2187 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.96087 to 0.96157, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-149-0.9616.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3449 - acc: 0.8537 - val_loss: 0.2126 - val_acc: 0.9616\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.96157\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3451 - acc: 0.8506 - val_loss: 0.2207 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.96157 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/0/weights-improvement-151-0.9619.hdf5\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3456 - acc: 0.8493 - val_loss: 0.2114 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.96191\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3430 - acc: 0.8509 - val_loss: 0.2123 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.96191\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3428 - acc: 0.8535 - val_loss: 0.2235 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.96191\n",
      "Epoch 155/200\n",
      "127/251 [==============>...............] - ETA: 2s - loss: 0.3566 - acc: 0.8397"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6211 - acc: 0.6932 - val_loss: 0.6294 - val_acc: 0.7324\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77079\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6197 - acc: 0.6949 - val_loss: 0.6242 - val_acc: 0.7331\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77079\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6187 - acc: 0.6963 - val_loss: 0.6191 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77079\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6179 - acc: 0.7005 - val_loss: 0.6157 - val_acc: 0.7348\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.77079\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6159 - acc: 0.6986 - val_loss: 0.6149 - val_acc: 0.7352\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.77079\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6143 - acc: 0.6979 - val_loss: 0.6100 - val_acc: 0.7379\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.77079\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6131 - acc: 0.7009 - val_loss: 0.6082 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.77079\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6115 - acc: 0.7019 - val_loss: 0.6039 - val_acc: 0.7404\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.77079\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6109 - acc: 0.7002 - val_loss: 0.6009 - val_acc: 0.7481\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.77079\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6086 - acc: 0.7039 - val_loss: 0.5989 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.77079\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6069 - acc: 0.7047 - val_loss: 0.5937 - val_acc: 0.7439\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77079\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6061 - acc: 0.7016 - val_loss: 0.5917 - val_acc: 0.7484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5853 - acc: 0.7186 - val_loss: 0.5598 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.77079\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5823 - acc: 0.7221 - val_loss: 0.5575 - val_acc: 0.7635\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.77079\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5832 - acc: 0.7188 - val_loss: 0.5579 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.77079\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5807 - acc: 0.7220 - val_loss: 0.5522 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.77079\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5783 - acc: 0.7239 - val_loss: 0.5514 - val_acc: 0.7739\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.77079 to 0.77393, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-038-0.7739.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5734 - acc: 0.7223 - val_loss: 0.5441 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.77393 to 0.77918, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-039-0.7792.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5739 - acc: 0.7256 - val_loss: 0.5426 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.77918 to 0.78512, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-040-0.7851.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5699 - acc: 0.7271 - val_loss: 0.5351 - val_acc: 0.7876\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.78512 to 0.78756, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-041-0.7876.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5664 - acc: 0.7287 - val_loss: 0.5307 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.78756 to 0.78826, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-042-0.7883.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5652 - acc: 0.7295 - val_loss: 0.5268 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.78826 to 0.79385, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-043-0.7939.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5575 - acc: 0.7344 - val_loss: 0.5177 - val_acc: 0.8043\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.79385 to 0.80433, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-044-0.8043.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5547 - acc: 0.7354 - val_loss: 0.5112 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.80433 to 0.81342, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-045-0.8134.hdf5\n",
      "Epoch 46/200\n",
      "207/251 [=======================>......] - ETA: 1s - loss: 0.5284 - acc: 0.7588"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4944 - acc: 0.7731 - val_loss: 0.4203 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.88400 to 0.88784, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-070-0.8878.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4923 - acc: 0.7725 - val_loss: 0.4145 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.88784 to 0.88889, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-071-0.8889.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4892 - acc: 0.7792 - val_loss: 0.4175 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00072: val_acc improved from 0.88889 to 0.88994, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-072-0.8899.hdf5\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4919 - acc: 0.7751 - val_loss: 0.4152 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88994\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4891 - acc: 0.7716 - val_loss: 0.4151 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00074: val_acc improved from 0.88994 to 0.89273, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-074-0.8927.hdf5\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4848 - acc: 0.7801 - val_loss: 0.4064 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.89273\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4813 - acc: 0.7798 - val_loss: 0.3999 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.89273 to 0.89413, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-076-0.8941.hdf5\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4810 - acc: 0.7790 - val_loss: 0.4066 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.89413 to 0.89832, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-077-0.8983.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4790 - acc: 0.7788 - val_loss: 0.4065 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.89832 to 0.89867, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-078-0.8987.hdf5\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4764 - acc: 0.7822 - val_loss: 0.4004 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89867 to 0.90217, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-079-0.9022.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4750 - acc: 0.7813 - val_loss: 0.3978 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.90217\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4726 - acc: 0.7824 - val_loss: 0.3885 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.90217\n",
      "Epoch 82/200\n",
      "114/251 [============>.................] - ETA: 3s - loss: 0.4835 - acc: 0.7693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3895 - acc: 0.8291 - val_loss: 0.2891 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00135: val_acc improved from 0.93606 to 0.93816, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-135-0.9382.hdf5\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3880 - acc: 0.8293 - val_loss: 0.2844 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.93816\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3873 - acc: 0.8269 - val_loss: 0.2884 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.93816 to 0.93850, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-137-0.9385.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3860 - acc: 0.8261 - val_loss: 0.2783 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.93850 to 0.93955, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-138-0.9396.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3862 - acc: 0.8316 - val_loss: 0.2883 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.93955 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-139-0.9403.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3843 - acc: 0.8274 - val_loss: 0.2799 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.94025\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3877 - acc: 0.8287 - val_loss: 0.2890 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.94025 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-141-0.9413.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3770 - acc: 0.8368 - val_loss: 0.2803 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.94130\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3824 - acc: 0.8310 - val_loss: 0.2761 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.94130\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3799 - acc: 0.8330 - val_loss: 0.2746 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.94130\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3743 - acc: 0.8382 - val_loss: 0.2595 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.94130\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3746 - acc: 0.8360 - val_loss: 0.2624 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.94130 to 0.94200, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-146-0.9420.hdf5\n",
      "Epoch 147/200\n",
      " 31/251 [==>...........................] - ETA: 5s - loss: 0.2898 - acc: 0.8853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3557 - acc: 0.8445 - val_loss: 0.2475 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.95143\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3649 - acc: 0.8412 - val_loss: 0.2573 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.95143\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3547 - acc: 0.8462 - val_loss: 0.2490 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.95143\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3622 - acc: 0.8438 - val_loss: 0.2545 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.95143\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3571 - acc: 0.8440 - val_loss: 0.2501 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.95143\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3560 - acc: 0.8412 - val_loss: 0.2488 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00166: val_acc improved from 0.95143 to 0.95178, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-166-0.9518.hdf5\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3562 - acc: 0.8451 - val_loss: 0.2441 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.95178\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3544 - acc: 0.8453 - val_loss: 0.2482 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.95178\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3532 - acc: 0.8445 - val_loss: 0.2402 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00169: val_acc improved from 0.95178 to 0.95318, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-169-0.9532.hdf5\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3563 - acc: 0.8437 - val_loss: 0.2479 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.95318\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3587 - acc: 0.8457 - val_loss: 0.2538 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.95318\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3505 - acc: 0.8477 - val_loss: 0.2362 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.95318 to 0.95458, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-172-0.9546.hdf5\n",
      "Epoch 173/200\n",
      " 97/251 [==========>...................] - ETA: 3s - loss: 0.3481 - acc: 0.8484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3317 - acc: 0.8569 - val_loss: 0.2121 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.95842\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3337 - acc: 0.8560 - val_loss: 0.2184 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.95842 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/1/weights-improvement-198-0.9595.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3293 - acc: 0.8611 - val_loss: 0.2173 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.95947\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3296 - acc: 0.8571 - val_loss: 0.2142 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.95947\n",
      "It has been  0:21:12.729493\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           (None, 1000, 26)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 1000, 26)     0           input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_216 (Conv1D)             (None, 1000, 10)     270         dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_217 (Conv1D)             (None, 1000, 10)     790         dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_218 (Conv1D)             (None, 1000, 10)     1310        dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_219 (Conv1D)             (None, 1000, 10)     2350        dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_220 (Conv1D)             (None, 1000, 10)     3910        dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 5000, 10)     0           conv1d_216[0][0]                 \n",
      "                                                                 conv1d_217[0][0]                 \n",
      "                                                                 conv1d_218[0][0]                 \n",
      "                                                                 conv1d_219[0][0]                 \n",
      "                                                                 conv1d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 500, 10)      0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_173 (Dense)               (None, 500, 314)     3454        max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 500, 314)     0           dense_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 500, 77)      24255       dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_175 (Dropout)           (None, 500, 77)      0           dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 500, 8)       624         dropout_175[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 500, 8)       0           dense_175[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 4000)         0           dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_176 (Dense)               (None, 2)            8002        flatten_44[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,965\n",
      "Trainable params: 44,965\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 10s 42ms/step - loss: 0.6818 - acc: 0.6170 - val_loss: 0.6917 - val_acc: 0.7442\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74423, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-001-0.7442.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6612 - acc: 0.6259 - val_loss: 0.6846 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.74423\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6489 - acc: 0.6543 - val_loss: 0.6722 - val_acc: 0.6827\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.74423\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6369 - acc: 0.6813 - val_loss: 0.6539 - val_acc: 0.7135\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.74423\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6290 - acc: 0.6857 - val_loss: 0.6444 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74423\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6259 - acc: 0.6902 - val_loss: 0.6373 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74423\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6231 - acc: 0.6940 - val_loss: 0.6332 - val_acc: 0.7166\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.74423\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.6209 - acc: 0.6960 - val_loss: 0.6273 - val_acc: 0.7177\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74423\n",
      "Epoch 9/200\n",
      " 24/251 [=>............................] - ETA: 5s - loss: 0.5878 - acc: 0.7454"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5756 - acc: 0.7271 - val_loss: 0.5540 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.75891 to 0.76415, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-038-0.7642.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5746 - acc: 0.7284 - val_loss: 0.5528 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.76415 to 0.76520, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-039-0.7652.hdf5\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5706 - acc: 0.7257 - val_loss: 0.5483 - val_acc: 0.7704\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.76520 to 0.77044, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-040-0.7704.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5674 - acc: 0.7291 - val_loss: 0.5443 - val_acc: 0.7830\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.77044 to 0.78302, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-041-0.7830.hdf5\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5645 - acc: 0.7334 - val_loss: 0.5370 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.78302 to 0.79315, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-042-0.7932.hdf5\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5634 - acc: 0.7330 - val_loss: 0.5350 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.79315 to 0.80154, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-043-0.8015.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5592 - acc: 0.7371 - val_loss: 0.5345 - val_acc: 0.8029\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.80154 to 0.80294, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-044-0.8029.hdf5\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5556 - acc: 0.7387 - val_loss: 0.5226 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.80294 to 0.81132, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-045-0.8113.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5511 - acc: 0.7426 - val_loss: 0.5218 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00046: val_acc improved from 0.81132 to 0.81656, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-046-0.8166.hdf5\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5516 - acc: 0.7410 - val_loss: 0.5139 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.81656 to 0.82704, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-047-0.8270.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5487 - acc: 0.7446 - val_loss: 0.5164 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.82704\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5444 - acc: 0.7452 - val_loss: 0.5072 - val_acc: 0.8361\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.82704 to 0.83613, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-049-0.8361.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5386 - acc: 0.7489 - val_loss: 0.5046 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.83613 to 0.83788, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-050-0.8379.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5391 - acc: 0.7490 - val_loss: 0.5081 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.83788\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5350 - acc: 0.7523 - val_loss: 0.4946 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.83788 to 0.84906, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-052-0.8491.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5328 - acc: 0.7520 - val_loss: 0.4921 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.84906 to 0.85080, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-053-0.8508.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5353 - acc: 0.7476 - val_loss: 0.4920 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00054: val_acc improved from 0.85080 to 0.85325, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-054-0.8532.hdf5\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5276 - acc: 0.7569 - val_loss: 0.4813 - val_acc: 0.8609\n",
      "\n",
      "Epoch 00055: val_acc improved from 0.85325 to 0.86094, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-055-0.8609.hdf5\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5260 - acc: 0.7553 - val_loss: 0.4807 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86094\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5227 - acc: 0.7598 - val_loss: 0.4779 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00057: val_acc improved from 0.86094 to 0.86303, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-057-0.8630.hdf5\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5204 - acc: 0.7624 - val_loss: 0.4719 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.86303 to 0.86688, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-058-0.8669.hdf5\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5192 - acc: 0.7614 - val_loss: 0.4709 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.86688\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5143 - acc: 0.7620 - val_loss: 0.4652 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.86688 to 0.86862, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-060-0.8686.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5130 - acc: 0.7651 - val_loss: 0.4660 - val_acc: 0.8728\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.86862 to 0.87282, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-061-0.8728.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5131 - acc: 0.7663 - val_loss: 0.4666 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.87282 to 0.87317, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-062-0.8732.hdf5\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5103 - acc: 0.7682 - val_loss: 0.4586 - val_acc: 0.8739\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87317 to 0.87386, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-063-0.8739.hdf5\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5053 - acc: 0.7682 - val_loss: 0.4515 - val_acc: 0.8767\n",
      "\n",
      "Epoch 00064: val_acc improved from 0.87386 to 0.87666, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-064-0.8767.hdf5\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.5022 - acc: 0.7691 - val_loss: 0.4469 - val_acc: 0.8795\n",
      "\n",
      "Epoch 00065: val_acc improved from 0.87666 to 0.87945, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-065-0.8795.hdf5\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.5033 - acc: 0.7719 - val_loss: 0.4425 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.87945 to 0.88155, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-066-0.8816.hdf5\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4995 - acc: 0.7667 - val_loss: 0.4314 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.88155 to 0.88260, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-067-0.8826.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4983 - acc: 0.7740 - val_loss: 0.4281 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00068: val_acc improved from 0.88260 to 0.88365, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-068-0.8836.hdf5\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4940 - acc: 0.7741 - val_loss: 0.4200 - val_acc: 0.8833\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.88365\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4957 - acc: 0.7719 - val_loss: 0.4278 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.88365 to 0.88644, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-070-0.8864.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4880 - acc: 0.7778 - val_loss: 0.4218 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00071: val_acc improved from 0.88644 to 0.88714, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-071-0.8871.hdf5\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4881 - acc: 0.7762 - val_loss: 0.4130 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88714\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4845 - acc: 0.7787 - val_loss: 0.4065 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88714\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4844 - acc: 0.7762 - val_loss: 0.4016 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88714\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4798 - acc: 0.7811 - val_loss: 0.3989 - val_acc: 0.8903\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.88714 to 0.89029, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-075-0.8903.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4771 - acc: 0.7849 - val_loss: 0.4031 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.89029\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4796 - acc: 0.7833 - val_loss: 0.4126 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00077: val_acc improved from 0.89029 to 0.89238, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-077-0.8924.hdf5\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4725 - acc: 0.7810 - val_loss: 0.3973 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.89238\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4722 - acc: 0.7848 - val_loss: 0.3922 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00079: val_acc improved from 0.89238 to 0.89378, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-079-0.8938.hdf5\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4709 - acc: 0.7855 - val_loss: 0.3952 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.89378 to 0.89483, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-080-0.8948.hdf5\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4664 - acc: 0.7873 - val_loss: 0.3816 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.89483\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4678 - acc: 0.7866 - val_loss: 0.3907 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.89483 to 0.89658, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-082-0.8966.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4613 - acc: 0.7914 - val_loss: 0.3845 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.89658\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4650 - acc: 0.7926 - val_loss: 0.3839 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.89658 to 0.89693, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-084-0.8969.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4546 - acc: 0.7966 - val_loss: 0.3685 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.89693 to 0.90007, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-085-0.9001.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4582 - acc: 0.7922 - val_loss: 0.3707 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.90007\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4514 - acc: 0.7981 - val_loss: 0.3688 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00087: val_acc improved from 0.90007 to 0.90077, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-087-0.9008.hdf5\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4542 - acc: 0.7946 - val_loss: 0.3672 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.90077 to 0.90182, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-088-0.9018.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4514 - acc: 0.7997 - val_loss: 0.3614 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.90182 to 0.90356, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-089-0.9036.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4499 - acc: 0.8018 - val_loss: 0.3571 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.90356\n",
      "Epoch 91/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4484 - acc: 0.7968 - val_loss: 0.3633 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00091: val_acc improved from 0.90356 to 0.90426, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-091-0.9043.hdf5\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4456 - acc: 0.7990 - val_loss: 0.3563 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00092: val_acc improved from 0.90426 to 0.90636, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-092-0.9064.hdf5\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4480 - acc: 0.7936 - val_loss: 0.3573 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.90636 to 0.90706, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-093-0.9071.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4422 - acc: 0.8027 - val_loss: 0.3538 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.90706\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4421 - acc: 0.8015 - val_loss: 0.3437 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.90706 to 0.90811, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-095-0.9081.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4397 - acc: 0.8023 - val_loss: 0.3514 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.90811 to 0.91090, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-096-0.9109.hdf5\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4379 - acc: 0.8024 - val_loss: 0.3387 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.91090\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4382 - acc: 0.8001 - val_loss: 0.3472 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.91090\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4362 - acc: 0.8076 - val_loss: 0.3425 - val_acc: 0.9116\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.91090 to 0.91160, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-099-0.9116.hdf5\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4382 - acc: 0.8029 - val_loss: 0.3462 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00100: val_acc improved from 0.91160 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-100-0.9151.hdf5\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4343 - acc: 0.8067 - val_loss: 0.3418 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.91509\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4329 - acc: 0.8049 - val_loss: 0.3329 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.91509\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4290 - acc: 0.8080 - val_loss: 0.3270 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00103: val_acc improved from 0.91509 to 0.91824, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-103-0.9182.hdf5\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4277 - acc: 0.8078 - val_loss: 0.3299 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00104: val_acc improved from 0.91824 to 0.91894, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-104-0.9189.hdf5\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4263 - acc: 0.8067 - val_loss: 0.3203 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.91894\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4264 - acc: 0.8119 - val_loss: 0.3184 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.91894\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4266 - acc: 0.8072 - val_loss: 0.3251 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00107: val_acc improved from 0.91894 to 0.92173, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-107-0.9217.hdf5\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4179 - acc: 0.8124 - val_loss: 0.3149 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.92173\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4194 - acc: 0.8107 - val_loss: 0.3174 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.92173 to 0.92313, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-109-0.9231.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4175 - acc: 0.8174 - val_loss: 0.3139 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.92313\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4190 - acc: 0.8140 - val_loss: 0.3147 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.92313\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4158 - acc: 0.8104 - val_loss: 0.3122 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.92313 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-112-0.9235.hdf5\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 7s 26ms/step - loss: 0.4113 - acc: 0.8193 - val_loss: 0.3026 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.92348 to 0.92593, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-113-0.9259.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4137 - acc: 0.8163 - val_loss: 0.3052 - val_acc: 0.9284\n",
      "\n",
      "Epoch 00114: val_acc improved from 0.92593 to 0.92837, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-114-0.9284.hdf5\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4122 - acc: 0.8155 - val_loss: 0.3053 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.92837\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4175 - acc: 0.8124 - val_loss: 0.3039 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.92837\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4052 - acc: 0.8204 - val_loss: 0.2967 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.92837 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-117-0.9315.hdf5\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4109 - acc: 0.8151 - val_loss: 0.3018 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93152\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4092 - acc: 0.8167 - val_loss: 0.2936 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93152\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4102 - acc: 0.8169 - val_loss: 0.2973 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93152\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4043 - acc: 0.8206 - val_loss: 0.2971 - val_acc: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00121: val_acc improved from 0.93152 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-121-0.9322.hdf5\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4024 - acc: 0.8207 - val_loss: 0.2891 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93222\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4010 - acc: 0.8230 - val_loss: 0.2949 - val_acc: 0.9308\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.93222\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.4051 - acc: 0.8186 - val_loss: 0.2890 - val_acc: 0.9298\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93222\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3990 - acc: 0.8243 - val_loss: 0.2886 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00125: val_acc improved from 0.93222 to 0.93222, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-125-0.9322.hdf5\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3963 - acc: 0.8253 - val_loss: 0.2808 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.93222\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.4029 - acc: 0.8217 - val_loss: 0.2899 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00127: val_acc improved from 0.93222 to 0.93326, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-127-0.9333.hdf5\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3980 - acc: 0.8254 - val_loss: 0.2853 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00128: val_acc improved from 0.93326 to 0.93431, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-128-0.9343.hdf5\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3932 - acc: 0.8272 - val_loss: 0.2882 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.93431\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3941 - acc: 0.8268 - val_loss: 0.2781 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.93431\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3959 - acc: 0.8246 - val_loss: 0.2767 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.93431\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3909 - acc: 0.8282 - val_loss: 0.2717 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00132: val_acc improved from 0.93431 to 0.93466, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-132-0.9347.hdf5\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3893 - acc: 0.8308 - val_loss: 0.2693 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00133: val_acc improved from 0.93466 to 0.93571, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-133-0.9357.hdf5\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3906 - acc: 0.8273 - val_loss: 0.2759 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.93571\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3896 - acc: 0.8316 - val_loss: 0.2723 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.93571\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3892 - acc: 0.8265 - val_loss: 0.2754 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.93571\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3819 - acc: 0.8305 - val_loss: 0.2694 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.93571\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3867 - acc: 0.8327 - val_loss: 0.2727 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.93571\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3845 - acc: 0.8302 - val_loss: 0.2803 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.93571 to 0.93885, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-139-0.9389.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3860 - acc: 0.8311 - val_loss: 0.2682 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.93885\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3794 - acc: 0.8349 - val_loss: 0.2632 - val_acc: 0.9368\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.93885\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3827 - acc: 0.8330 - val_loss: 0.2641 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.93885\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3823 - acc: 0.8319 - val_loss: 0.2626 - val_acc: 0.9378\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.93885\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3801 - acc: 0.8334 - val_loss: 0.2604 - val_acc: 0.9364\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.93885\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3849 - acc: 0.8288 - val_loss: 0.2648 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00145: val_acc improved from 0.93885 to 0.93920, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-145-0.9392.hdf5\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3803 - acc: 0.8338 - val_loss: 0.2691 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.93920\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3834 - acc: 0.8328 - val_loss: 0.2653 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.93920 to 0.94025, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-147-0.9403.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3806 - acc: 0.8301 - val_loss: 0.2593 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00148: val_acc improved from 0.94025 to 0.94130, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-148-0.9413.hdf5\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3747 - acc: 0.8373 - val_loss: 0.2608 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.94130\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3752 - acc: 0.8339 - val_loss: 0.2567 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.94130\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3759 - acc: 0.8358 - val_loss: 0.2593 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00151: val_acc improved from 0.94130 to 0.94270, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-151-0.9427.hdf5\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3719 - acc: 0.8374 - val_loss: 0.2499 - val_acc: 0.9427\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.94270\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3723 - acc: 0.8375 - val_loss: 0.2511 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.94270\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3711 - acc: 0.8386 - val_loss: 0.2567 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.94270 to 0.94305, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-154-0.9430.hdf5\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3652 - acc: 0.8383 - val_loss: 0.2426 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00155: val_acc improved from 0.94305 to 0.94340, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-155-0.9434.hdf5\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3736 - acc: 0.8362 - val_loss: 0.2507 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00156: val_acc improved from 0.94340 to 0.94584, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-156-0.9458.hdf5\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3743 - acc: 0.8358 - val_loss: 0.2513 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00157: val_acc improved from 0.94584 to 0.94619, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-157-0.9462.hdf5\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3687 - acc: 0.8378 - val_loss: 0.2531 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00158: val_acc did not improve from 0.94619\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3721 - acc: 0.8404 - val_loss: 0.2583 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.94619 to 0.94724, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-159-0.9472.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3687 - acc: 0.8415 - val_loss: 0.2469 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.94724\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3674 - acc: 0.8391 - val_loss: 0.2471 - val_acc: 0.9437\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.94724\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3707 - acc: 0.8342 - val_loss: 0.2485 - val_acc: 0.9444\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.94724\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3659 - acc: 0.8400 - val_loss: 0.2511 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.94724\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3653 - acc: 0.8360 - val_loss: 0.2436 - val_acc: 0.9455\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.94724\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3642 - acc: 0.8399 - val_loss: 0.2409 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.94724\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3654 - acc: 0.8409 - val_loss: 0.2459 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.94724\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3591 - acc: 0.8457 - val_loss: 0.2386 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.94724\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3566 - acc: 0.8465 - val_loss: 0.2399 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00168: val_acc improved from 0.94724 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-168-0.9479.hdf5\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3659 - acc: 0.8441 - val_loss: 0.2427 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.94794\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3574 - acc: 0.8426 - val_loss: 0.2341 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.94794\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3623 - acc: 0.8454 - val_loss: 0.2429 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.94794 to 0.94794, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-171-0.9479.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3617 - acc: 0.8420 - val_loss: 0.2418 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00172: val_acc improved from 0.94794 to 0.94934, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-172-0.9493.hdf5\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3585 - acc: 0.8457 - val_loss: 0.2411 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.94934\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3577 - acc: 0.8465 - val_loss: 0.2366 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.94934\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3629 - acc: 0.8402 - val_loss: 0.2395 - val_acc: 0.9465\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.94934\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3587 - acc: 0.8441 - val_loss: 0.2374 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.94934\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3568 - acc: 0.8493 - val_loss: 0.2400 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00177: val_acc improved from 0.94934 to 0.94969, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-177-0.9497.hdf5\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3561 - acc: 0.8470 - val_loss: 0.2305 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.94969\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3608 - acc: 0.8430 - val_loss: 0.2354 - val_acc: 0.9486\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.94969\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3517 - acc: 0.8437 - val_loss: 0.2322 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00180: val_acc improved from 0.94969 to 0.95003, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-180-0.9500.hdf5\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3476 - acc: 0.8484 - val_loss: 0.2250 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.95003\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3573 - acc: 0.8445 - val_loss: 0.2361 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.95003\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3541 - acc: 0.8490 - val_loss: 0.2291 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00183: val_acc improved from 0.95003 to 0.95003, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-183-0.9500.hdf5\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3473 - acc: 0.8471 - val_loss: 0.2278 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.95003\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3471 - acc: 0.8488 - val_loss: 0.2225 - val_acc: 0.9497\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.95003\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3486 - acc: 0.8492 - val_loss: 0.2224 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00186: val_acc improved from 0.95003 to 0.95108, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/stack_conv/10filts_sizeJurtz/task1/ext_padding/2/weights-improvement-186-0.9511.hdf5\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 6s 25ms/step - loss: 0.3495 - acc: 0.8513 - val_loss: 0.2267 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.95108\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 6s 26ms/step - loss: 0.3467 - acc: 0.8509 - val_loss: 0.2202 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.95108\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/251 [==================>...........] - ETA: 1s - loss: 0.3352 - acc: 0.8551"
     ]
    }
   ],
   "source": [
    "for model_type in list_paddings:\n",
    "    generators = generators_dict[model_type]\n",
    "    for idx,i in enumerate(generators):\n",
    "        if model_type == \"aug_padding\":\n",
    "            i_train, i_val, i_test = k_aug_indices[idx]\n",
    "        else: \n",
    "            i_train, i_val, i_test = splitting_sets[idx]\n",
    "        len_train, len_val, len_test = len(i_train), len(i_val), len(i_test)\n",
    "        train_generator, val_generator = i\n",
    "        model_training(model_type, folder, task, idx, callbacks_list, train_generator, val_generator,\n",
    "                        architecture, max_lenn, dict_size, batch_size,\n",
    "                        n_neur, n_class, drop_per, drop_hid, final_act, epochss, \n",
    "                        len_train, len_val, \n",
    "                        n_filt = n_filt, kernel_size=kernel_size, pool_size=pool_size,\n",
    "                      nhid=n_hid, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
