{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, absolute_import\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela/padding_EBI/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "#from src.Target import Target\n",
    "\n",
    "np.random.seed(8)\n",
    "random.seed(8)\n",
    "\n",
    "from src.preprocessing import *\n",
    "from src.model_architecture import *\n",
    "from src.training_model import *\n",
    "from src.postprocessing import *\n",
    "from src.comparing_results import *\n",
    "#from src.callbacks import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_paddings = ['post_padding', 'pre_padding', 'mid_padding', 'stretch_padding', 'ext_padding', \n",
    "                 'rdm_padding', 'aug_padding']\n",
    "list_padding_short = ['post_padding', 'pre_padding', 'mid_padding', 'stretch_padding', 'ext_padding', \n",
    "                 'rdm_padding']\n",
    "#hierarchy of folders: annotation/dataset/architecture/n_neurs/task/padding\n",
    "folder = 'EC_number/archaea/3denses/bio_neurons/'\n",
    "column = \"EC number\"\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "dicti = creating_dict()\n",
    "\n",
    "max_lenn = 1000\n",
    "\n",
    "n_class = 2 #number of classes to output\n",
    "drop_per = 0.2 #Input dropout \n",
    "n_neur = [314,77, 8]\n",
    "drop_hid = 0.5\n",
    "dict_size = len(dicti)\n",
    "\n",
    "batch_size = 54\n",
    "epochss = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: (9159, 505)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4aacc40e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_idcs_aug = os.path.join(absPath, 'data/', folder, 'idcs_aug_split.pickle')\n",
    "\n",
    "with open(file_idcs_aug, \"rb\") as input_file:\n",
    "    k_aug_indices = pickle.load(input_file)\n",
    "    \n",
    "file_idcs = os.path.join(absPath, 'data/', folder, 'idcs_split.pickle')\n",
    "\n",
    "with open(file_idcs, \"rb\") as input_file:\n",
    "    splitting_sets = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Deep Learning model  - Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 21:03:15.824917 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0711 21:03:15.836894 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0711 21:03:15.838696 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0711 21:03:15.844447 139960592238336 deprecation.py:506] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0711 21:03:15.860897 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0711 21:03:16.091303 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0711 21:03:16.098016 139960592238336 deprecation_wrapper.py:119] From /home/angela/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 26000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 314)               8164314   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 314)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 77)                24255     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 624       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 8,189,211\n",
      "Trainable params: 8,189,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = building_3dense_model_task1(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, 'softmax', folder)\n",
    "\n",
    "generators_dict = {} \n",
    "for model_type in list_paddings:\n",
    "    generators_dict[model_type] = trainval_generators(splitting_sets, k_aug_indices, model_type, \n",
    "                                                      folder, batch_size, 'labels_task1', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 26000)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 314)               8164314   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 314)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 77)                24255     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 624       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 8,189,211\n",
      "Trainable params: 8,189,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 17s 68ms/step - loss: 0.7272 - acc: 0.5230 - val_loss: 0.6692 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74563, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-001-0.7456.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6886 - acc: 0.5646 - val_loss: 0.6304 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.74563 to 0.75961, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-002-0.7596.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6884 - acc: 0.5762 - val_loss: 0.6046 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.75961 to 0.78232, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-003-0.7823.hdf5\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6760 - acc: 0.5799 - val_loss: 0.6121 - val_acc: 0.7264\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78232\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6754 - acc: 0.5833 - val_loss: 0.6350 - val_acc: 0.7928\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.78232 to 0.79280, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-005-0.7928.hdf5\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6662 - acc: 0.5840 - val_loss: 0.6109 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79280\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6633 - acc: 0.5872 - val_loss: 0.6136 - val_acc: 0.7103\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79280\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6497 - acc: 0.6057 - val_loss: 0.5952 - val_acc: 0.7757\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79280\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6428 - acc: 0.6174 - val_loss: 0.5644 - val_acc: 0.7383\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79280\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6393 - acc: 0.6287 - val_loss: 0.5660 - val_acc: 0.7163\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79280\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6283 - acc: 0.6197 - val_loss: 0.5992 - val_acc: 0.7103\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.79280\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6391 - acc: 0.6125 - val_loss: 0.5777 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.79280\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6167 - acc: 0.6602 - val_loss: 0.5487 - val_acc: 0.7086\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.79280\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6078 - acc: 0.6462 - val_loss: 0.5663 - val_acc: 0.7163\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.79280\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5917 - acc: 0.6716 - val_loss: 0.5646 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.79280\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.6146 - acc: 0.6517 - val_loss: 0.5932 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.79280\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5764 - acc: 0.6957 - val_loss: 0.5520 - val_acc: 0.7184\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79280\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5715 - acc: 0.6987 - val_loss: 0.5519 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.79280\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5698 - acc: 0.6937 - val_loss: 0.5391 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.79280\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5474 - acc: 0.7157 - val_loss: 0.5688 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.79280\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5467 - acc: 0.6912 - val_loss: 0.5343 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79280\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5421 - acc: 0.7174 - val_loss: 0.5407 - val_acc: 0.7229\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79280\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5447 - acc: 0.6920 - val_loss: 0.5206 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.79280\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5143 - acc: 0.7165 - val_loss: 0.4836 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.79280\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5154 - acc: 0.7162 - val_loss: 0.4933 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.79280\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5341 - acc: 0.7218 - val_loss: 0.4947 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.79280\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4911 - acc: 0.7416 - val_loss: 0.4518 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79280\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.5079 - acc: 0.7513 - val_loss: 0.5073 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.79280\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4755 - acc: 0.7629 - val_loss: 0.4728 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.79280\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4852 - acc: 0.7654 - val_loss: 0.4566 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.79280\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4594 - acc: 0.7658 - val_loss: 0.4697 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.79280\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4470 - acc: 0.7731 - val_loss: 0.4712 - val_acc: 0.7282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_acc did not improve from 0.79280\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4614 - acc: 0.7684 - val_loss: 0.4846 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.79280\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4493 - acc: 0.7809 - val_loss: 0.4481 - val_acc: 0.7345\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.79280\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4387 - acc: 0.7809 - val_loss: 0.4194 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.79280\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4208 - acc: 0.7979 - val_loss: 0.3780 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.79280 to 0.82669, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-036-0.8267.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4252 - acc: 0.8027 - val_loss: 0.4104 - val_acc: 0.7921\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82669\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4074 - acc: 0.8090 - val_loss: 0.3758 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82669\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4133 - acc: 0.8087 - val_loss: 0.3663 - val_acc: 0.8239\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.82669\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.4005 - acc: 0.8228 - val_loss: 0.3100 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.82669 to 0.86443, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-040-0.8644.hdf5\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3887 - acc: 0.8256 - val_loss: 0.3967 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.86443\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3855 - acc: 0.8190 - val_loss: 0.2869 - val_acc: 0.8438\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.86443\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3975 - acc: 0.8279 - val_loss: 0.3538 - val_acc: 0.7757\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.86443\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3754 - acc: 0.8364 - val_loss: 0.2954 - val_acc: 0.8410\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.86443\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3772 - acc: 0.8379 - val_loss: 0.3433 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.86443\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3620 - acc: 0.8396 - val_loss: 0.2965 - val_acc: 0.8176\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86443\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3592 - acc: 0.8373 - val_loss: 0.3070 - val_acc: 0.8270\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86443\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3543 - acc: 0.8446 - val_loss: 0.2862 - val_acc: 0.8505\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86443\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3480 - acc: 0.8447 - val_loss: 0.2434 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.86443 to 0.91544, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-049-0.9154.hdf5\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3660 - acc: 0.8401 - val_loss: 0.3367 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.91544\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3619 - acc: 0.8380 - val_loss: 0.2401 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.91544\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3534 - acc: 0.8539 - val_loss: 0.2873 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.91544\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3440 - acc: 0.8510 - val_loss: 0.2103 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00053: val_acc improved from 0.91544 to 0.92697, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-053-0.9270.hdf5\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3462 - acc: 0.8526 - val_loss: 0.2452 - val_acc: 0.8606\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.92697\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3295 - acc: 0.8609 - val_loss: 0.2497 - val_acc: 0.8463\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.92697\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3302 - acc: 0.8558 - val_loss: 0.2041 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.92697\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3270 - acc: 0.8565 - val_loss: 0.2760 - val_acc: 0.8330\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.92697\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3425 - acc: 0.8528 - val_loss: 0.2503 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.92697\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3349 - acc: 0.8605 - val_loss: 0.2460 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.92697\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3131 - acc: 0.8637 - val_loss: 0.2316 - val_acc: 0.8735\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.92697\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3212 - acc: 0.8592 - val_loss: 0.2595 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.92697\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3181 - acc: 0.8623 - val_loss: 0.2366 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.92697\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3187 - acc: 0.8561 - val_loss: 0.2007 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.92697\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3144 - acc: 0.8615 - val_loss: 0.2248 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.92697\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3114 - acc: 0.8664 - val_loss: 0.2897 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.92697\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3176 - acc: 0.8643 - val_loss: 0.2047 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.92697\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3053 - acc: 0.8662 - val_loss: 0.2224 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.92697\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2986 - acc: 0.8705 - val_loss: 0.2033 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.92697\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2949 - acc: 0.8738 - val_loss: 0.1777 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.92697\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 16s 66ms/step - loss: 0.3210 - acc: 0.8609 - val_loss: 0.2133 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.92697\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2942 - acc: 0.8769 - val_loss: 0.1646 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.92697\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3013 - acc: 0.8709 - val_loss: 0.2014 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.92697\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3076 - acc: 0.8704 - val_loss: 0.2209 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.92697\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2885 - acc: 0.8716 - val_loss: 0.1916 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.92697\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3018 - acc: 0.8741 - val_loss: 0.1531 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.92697\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2924 - acc: 0.8693 - val_loss: 0.1636 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.92697\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2838 - acc: 0.8746 - val_loss: 0.1806 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.92697\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.3004 - acc: 0.8702 - val_loss: 0.2317 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.92697\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2871 - acc: 0.8772 - val_loss: 0.1807 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.92697\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2908 - acc: 0.8755 - val_loss: 0.1959 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.92697\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2879 - acc: 0.8666 - val_loss: 0.2214 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.92697\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2799 - acc: 0.8750 - val_loss: 0.1612 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.92697 to 0.92802, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-082-0.9280.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2776 - acc: 0.8812 - val_loss: 0.1715 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.92802\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2852 - acc: 0.8761 - val_loss: 0.2357 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.92802\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 16s 66ms/step - loss: 0.3015 - acc: 0.8761 - val_loss: 0.1616 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.92802\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2747 - acc: 0.8768 - val_loss: 0.2012 - val_acc: 0.8456\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.92802\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2923 - acc: 0.8674 - val_loss: 0.1609 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.92802\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2836 - acc: 0.8784 - val_loss: 0.1677 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.92802\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2858 - acc: 0.8744 - val_loss: 0.1433 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00089: val_acc improved from 0.92802 to 0.93012, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-089-0.9301.hdf5\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2881 - acc: 0.8810 - val_loss: 0.1796 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93012\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2621 - acc: 0.8884 - val_loss: 0.1493 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.93012\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2647 - acc: 0.8860 - val_loss: 0.1429 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.93012\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2694 - acc: 0.8774 - val_loss: 0.1777 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.93012\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2718 - acc: 0.8744 - val_loss: 0.1518 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93012\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 16s 66ms/step - loss: 0.2593 - acc: 0.8878 - val_loss: 0.1553 - val_acc: 0.8955\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93012\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2571 - acc: 0.8890 - val_loss: 0.1487 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.93012\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2540 - acc: 0.8876 - val_loss: 0.1345 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93012\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2616 - acc: 0.8820 - val_loss: 0.1327 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93012\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2639 - acc: 0.8821 - val_loss: 0.1915 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93012\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2549 - acc: 0.8897 - val_loss: 0.1429 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93012\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2614 - acc: 0.8862 - val_loss: 0.1447 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.93012\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2557 - acc: 0.8905 - val_loss: 0.1454 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.93012\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2587 - acc: 0.8845 - val_loss: 0.1489 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.93012\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2624 - acc: 0.8868 - val_loss: 0.1407 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.93012\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2594 - acc: 0.8909 - val_loss: 0.1300 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93012\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2516 - acc: 0.8867 - val_loss: 0.1274 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.93012\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2587 - acc: 0.8862 - val_loss: 0.1255 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93012\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2594 - acc: 0.8858 - val_loss: 0.1517 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93012\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2585 - acc: 0.8899 - val_loss: 0.1189 - val_acc: 0.9315\n",
      "\n",
      "Epoch 00109: val_acc improved from 0.93012 to 0.93152, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-109-0.9315.hdf5\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2525 - acc: 0.8901 - val_loss: 0.1416 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.93152\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2528 - acc: 0.8896 - val_loss: 0.1219 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.93152\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2542 - acc: 0.8864 - val_loss: 0.1548 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.93152\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2495 - acc: 0.8910 - val_loss: 0.1237 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.93152 to 0.93501, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-113-0.9350.hdf5\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2415 - acc: 0.8954 - val_loss: 0.1159 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.93501\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2460 - acc: 0.8879 - val_loss: 0.1416 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.93501\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2686 - acc: 0.8870 - val_loss: 0.1640 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93501\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2531 - acc: 0.8862 - val_loss: 0.1528 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.93501\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2450 - acc: 0.8904 - val_loss: 0.1225 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93501\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2498 - acc: 0.8905 - val_loss: 0.1504 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93501\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2483 - acc: 0.8902 - val_loss: 0.1574 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93501\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2372 - acc: 0.8933 - val_loss: 0.1177 - val_acc: 0.9347\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93501\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 17s 66ms/step - loss: 0.2347 - acc: 0.8946 - val_loss: 0.1142 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00122: val_acc improved from 0.93501 to 0.93536, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/post_padding/0/weights-improvement-122-0.9354.hdf5\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.6282 - acc: 0.6469 - val_loss: 0.6172 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82425\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6084 - acc: 0.6775 - val_loss: 0.6447 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82425\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6031 - acc: 0.6817 - val_loss: 0.5651 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.82425 to 0.82565, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-015-0.8256.hdf5\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.5987 - acc: 0.6916 - val_loss: 0.6191 - val_acc: 0.8281\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.82565 to 0.82809, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-016-0.8281.hdf5\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6134 - acc: 0.6920 - val_loss: 0.6068 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82809\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5981 - acc: 0.6892 - val_loss: 0.5554 - val_acc: 0.7855\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82809\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5720 - acc: 0.7022 - val_loss: 0.5665 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82809\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.5606 - acc: 0.7254 - val_loss: 0.5612 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82809\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5519 - acc: 0.7130 - val_loss: 0.5105 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82809\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 0.5432 - acc: 0.7264 - val_loss: 0.5505 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82809\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5379 - acc: 0.7305 - val_loss: 0.5079 - val_acc: 0.8078\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.82809\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 0.5392 - acc: 0.7419 - val_loss: 0.5101 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.82809\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5176 - acc: 0.7407 - val_loss: 0.4932 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82809\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.5131 - acc: 0.7488 - val_loss: 0.4743 - val_acc: 0.7715\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82809\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4900 - acc: 0.7635 - val_loss: 0.4353 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82809\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4869 - acc: 0.7618 - val_loss: 0.4896 - val_acc: 0.7292\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82809\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4846 - acc: 0.7677 - val_loss: 0.4545 - val_acc: 0.8099\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82809\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4770 - acc: 0.7756 - val_loss: 0.4352 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82809\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4525 - acc: 0.7932 - val_loss: 0.4327 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.82809 to 0.83788, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-031-0.8379.hdf5\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.4605 - acc: 0.7936 - val_loss: 0.4118 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.83788\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4472 - acc: 0.7925 - val_loss: 0.3968 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.83788 to 0.84067, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-033-0.8407.hdf5\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4459 - acc: 0.7953 - val_loss: 0.4433 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.84067\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4428 - acc: 0.7822 - val_loss: 0.3796 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.84067 to 0.84871, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-035-0.8487.hdf5\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4342 - acc: 0.7948 - val_loss: 0.3873 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.84871 to 0.89413, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-036-0.8941.hdf5\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4372 - acc: 0.8043 - val_loss: 0.3878 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89413\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 0.4210 - acc: 0.8021 - val_loss: 0.3362 - val_acc: 0.8442\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89413\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4120 - acc: 0.8113 - val_loss: 0.2861 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89413\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.4222 - acc: 0.8062 - val_loss: 0.3439 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89413\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.4160 - acc: 0.8091 - val_loss: 0.3331 - val_acc: 0.8302\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.89413\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3995 - acc: 0.8143 - val_loss: 0.3001 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89413\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3897 - acc: 0.8232 - val_loss: 0.2605 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89413\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 0.3965 - acc: 0.8220 - val_loss: 0.3236 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89413\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3905 - acc: 0.8232 - val_loss: 0.2840 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89413\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3886 - acc: 0.8237 - val_loss: 0.3411 - val_acc: 0.8026\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89413\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3910 - acc: 0.8200 - val_loss: 0.2798 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89413\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3799 - acc: 0.8283 - val_loss: 0.2562 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89413\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3789 - acc: 0.8314 - val_loss: 0.2447 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89413\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3812 - acc: 0.8147 - val_loss: 0.2455 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00050: val_acc improved from 0.89413 to 0.90811, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-050-0.9081.hdf5\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3915 - acc: 0.8229 - val_loss: 0.2539 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.90811\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3714 - acc: 0.8236 - val_loss: 0.2470 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.90811\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3681 - acc: 0.8274 - val_loss: 0.2612 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.90811\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3578 - acc: 0.8347 - val_loss: 0.2478 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.90811\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3713 - acc: 0.8378 - val_loss: 0.2600 - val_acc: 0.8487\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.90811\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3510 - acc: 0.8420 - val_loss: 0.2248 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.90811\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3544 - acc: 0.8347 - val_loss: 0.2346 - val_acc: 0.8892\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.90811\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3557 - acc: 0.8378 - val_loss: 0.2236 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.90811\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3409 - acc: 0.8465 - val_loss: 0.2191 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.90811\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3524 - acc: 0.8336 - val_loss: 0.2485 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.90811\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3537 - acc: 0.8383 - val_loss: 0.2106 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.90811\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3292 - acc: 0.8479 - val_loss: 0.2591 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.90811\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3366 - acc: 0.8435 - val_loss: 0.2129 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.90811\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 0.3293 - acc: 0.8497 - val_loss: 0.2619 - val_acc: 0.8578\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.90811\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3456 - acc: 0.8431 - val_loss: 0.2342 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.90811\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 0.3351 - acc: 0.8482 - val_loss: 0.2244 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.90811\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3311 - acc: 0.8539 - val_loss: 0.2480 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.90811\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3307 - acc: 0.8522 - val_loss: 0.2096 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.90811\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3369 - acc: 0.8463 - val_loss: 0.2284 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.90811\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3377 - acc: 0.8509 - val_loss: 0.2185 - val_acc: 0.8630\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.90811\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3164 - acc: 0.8595 - val_loss: 0.2286 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.90811\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3258 - acc: 0.8565 - val_loss: 0.2036 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.90811\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3163 - acc: 0.8572 - val_loss: 0.1903 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.90811\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 0.3108 - acc: 0.8654 - val_loss: 0.1801 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.90811\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.3059 - acc: 0.8660 - val_loss: 0.1872 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.90811 to 0.93361, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-075-0.9336.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.3152 - acc: 0.8595 - val_loss: 0.2692 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.93361\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.3095 - acc: 0.8551 - val_loss: 0.1970 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.93361\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.3141 - acc: 0.8606 - val_loss: 0.2142 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.93361\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.3069 - acc: 0.8635 - val_loss: 0.2311 - val_acc: 0.8819\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.93361\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2921 - acc: 0.8704 - val_loss: 0.2070 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.93361\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2994 - acc: 0.8633 - val_loss: 0.2239 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.93361\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.3203 - acc: 0.8607 - val_loss: 0.1860 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.93361\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.3035 - acc: 0.8617 - val_loss: 0.2067 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.93361\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2959 - acc: 0.8671 - val_loss: 0.2016 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.93361\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.3089 - acc: 0.8648 - val_loss: 0.1817 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00085: val_acc improved from 0.93361 to 0.93711, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-085-0.9371.hdf5\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2973 - acc: 0.8724 - val_loss: 0.1894 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.93711\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2875 - acc: 0.8730 - val_loss: 0.1757 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.93711\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2952 - acc: 0.8714 - val_loss: 0.1650 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.93711\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2941 - acc: 0.8682 - val_loss: 0.2241 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.93711\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2871 - acc: 0.8717 - val_loss: 0.1876 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.93711\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2906 - acc: 0.8727 - val_loss: 0.1670 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.93711\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2858 - acc: 0.8724 - val_loss: 0.2132 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.93711\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2866 - acc: 0.8721 - val_loss: 0.1561 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.93711\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2868 - acc: 0.8693 - val_loss: 0.1820 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.93711\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2928 - acc: 0.8662 - val_loss: 0.1738 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.93711\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2822 - acc: 0.8707 - val_loss: 0.1960 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.93711\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2862 - acc: 0.8690 - val_loss: 0.1922 - val_acc: 0.8910\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93711\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2865 - acc: 0.8671 - val_loss: 0.1911 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93711\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2833 - acc: 0.8698 - val_loss: 0.1644 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93711\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2776 - acc: 0.8718 - val_loss: 0.1541 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93711\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2774 - acc: 0.8748 - val_loss: 0.1998 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.93711\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2861 - acc: 0.8769 - val_loss: 0.2010 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.93711\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2692 - acc: 0.8775 - val_loss: 0.1908 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.93711\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2861 - acc: 0.8674 - val_loss: 0.1562 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.93711\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2719 - acc: 0.8749 - val_loss: 0.1797 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93711\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2767 - acc: 0.8715 - val_loss: 0.1695 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.93711\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2691 - acc: 0.8789 - val_loss: 0.1502 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93711\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2628 - acc: 0.8820 - val_loss: 0.1607 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93711\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2705 - acc: 0.8759 - val_loss: 0.1558 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93711\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2740 - acc: 0.8764 - val_loss: 0.1324 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00110: val_acc improved from 0.93711 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-110-0.9507.hdf5\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2670 - acc: 0.8735 - val_loss: 0.1668 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.95073\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2622 - acc: 0.8797 - val_loss: 0.1719 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.95073\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2667 - acc: 0.8762 - val_loss: 0.1715 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.95073\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2538 - acc: 0.8857 - val_loss: 0.1633 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.95073\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2603 - acc: 0.8794 - val_loss: 0.1477 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.95073\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2588 - acc: 0.8817 - val_loss: 0.2027 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.95073\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2805 - acc: 0.8664 - val_loss: 0.1517 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.95073\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2663 - acc: 0.8746 - val_loss: 0.1474 - val_acc: 0.9413\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.95073\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2675 - acc: 0.8817 - val_loss: 0.1805 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.95073\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2646 - acc: 0.8797 - val_loss: 0.1930 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.95073\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2648 - acc: 0.8796 - val_loss: 0.1687 - val_acc: 0.9259\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.95073\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2648 - acc: 0.8772 - val_loss: 0.1633 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.95073\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2537 - acc: 0.8825 - val_loss: 0.1330 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.95073 to 0.95178, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-123-0.9518.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2603 - acc: 0.8776 - val_loss: 0.2049 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.95178\n",
      "Epoch 125/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2670 - acc: 0.8781 - val_loss: 0.1622 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.95178\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2650 - acc: 0.8789 - val_loss: 0.1382 - val_acc: 0.9333\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.95178\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2476 - acc: 0.8877 - val_loss: 0.1341 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95178\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2501 - acc: 0.8896 - val_loss: 0.1980 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.95178\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2681 - acc: 0.8730 - val_loss: 0.1432 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.95178\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2604 - acc: 0.8787 - val_loss: 0.1389 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95178\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2495 - acc: 0.8853 - val_loss: 0.1402 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.95178\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2668 - acc: 0.8764 - val_loss: 0.1484 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95178\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2574 - acc: 0.8833 - val_loss: 0.2003 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95178\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2545 - acc: 0.8800 - val_loss: 0.1553 - val_acc: 0.9280\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.95178\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2500 - acc: 0.8833 - val_loss: 0.1385 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.95178\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2458 - acc: 0.8896 - val_loss: 0.1387 - val_acc: 0.9326\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.95178\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2457 - acc: 0.8890 - val_loss: 0.1470 - val_acc: 0.9228\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.95178\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2556 - acc: 0.8815 - val_loss: 0.1820 - val_acc: 0.9022\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.95178\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2553 - acc: 0.8827 - val_loss: 0.1459 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.95178\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2375 - acc: 0.8910 - val_loss: 0.1515 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95178\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2556 - acc: 0.8856 - val_loss: 0.1605 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.95178\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2620 - acc: 0.8766 - val_loss: 0.1570 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.95178\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2450 - acc: 0.8871 - val_loss: 0.1380 - val_acc: 0.9340\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.95178\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2551 - acc: 0.8859 - val_loss: 0.1316 - val_acc: 0.9406\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.95178\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2397 - acc: 0.8867 - val_loss: 0.1467 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.95178\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2336 - acc: 0.8964 - val_loss: 0.1293 - val_acc: 0.9479\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.95178\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2449 - acc: 0.8923 - val_loss: 0.1525 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.95178\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2384 - acc: 0.8921 - val_loss: 0.1511 - val_acc: 0.9371\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.95178\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2502 - acc: 0.8848 - val_loss: 0.1276 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00149: val_acc improved from 0.95178 to 0.95842, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-149-0.9584.hdf5\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2442 - acc: 0.8865 - val_loss: 0.1235 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.95842\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2476 - acc: 0.8898 - val_loss: 0.1233 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.95842\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2361 - acc: 0.8892 - val_loss: 0.1052 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.95842\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2483 - acc: 0.8898 - val_loss: 0.1197 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.95842\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2468 - acc: 0.8876 - val_loss: 0.1146 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00154: val_acc improved from 0.95842 to 0.96191, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-154-0.9619.hdf5\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2425 - acc: 0.8882 - val_loss: 0.1213 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.96191\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2530 - acc: 0.8846 - val_loss: 0.1280 - val_acc: 0.9511\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.96191\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2366 - acc: 0.8912 - val_loss: 0.1426 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.96191\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2392 - acc: 0.8898 - val_loss: 0.1012 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.96191 to 0.96576, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-158-0.9658.hdf5\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2423 - acc: 0.8848 - val_loss: 0.1315 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.96576\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2404 - acc: 0.8913 - val_loss: 0.1376 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.96576\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2458 - acc: 0.8854 - val_loss: 0.1265 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.96576\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2417 - acc: 0.8866 - val_loss: 0.1152 - val_acc: 0.9469\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.96576\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2428 - acc: 0.8895 - val_loss: 0.0869 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00163: val_acc improved from 0.96576 to 0.96611, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-163-0.9661.hdf5\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2438 - acc: 0.8905 - val_loss: 0.1445 - val_acc: 0.9357\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.96611\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2361 - acc: 0.8898 - val_loss: 0.1135 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.96611\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2378 - acc: 0.8917 - val_loss: 0.1071 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.96611\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2418 - acc: 0.8862 - val_loss: 0.1446 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.96611\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2284 - acc: 0.8918 - val_loss: 0.0908 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.96611\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2378 - acc: 0.8926 - val_loss: 0.0999 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00169: val_acc improved from 0.96611 to 0.96716, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-169-0.9672.hdf5\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2308 - acc: 0.8968 - val_loss: 0.1074 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.96716\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2280 - acc: 0.8969 - val_loss: 0.0832 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00171: val_acc improved from 0.96716 to 0.97240, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-171-0.9724.hdf5\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2337 - acc: 0.8941 - val_loss: 0.1020 - val_acc: 0.9343\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.97240\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2198 - acc: 0.8973 - val_loss: 0.1021 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.97240\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2261 - acc: 0.8990 - val_loss: 0.1175 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.97240\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2344 - acc: 0.8938 - val_loss: 0.1138 - val_acc: 0.9350\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.97240\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2276 - acc: 0.8928 - val_loss: 0.1031 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.97240\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2304 - acc: 0.8912 - val_loss: 0.1021 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.97240\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2323 - acc: 0.8926 - val_loss: 0.1129 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.97240\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2334 - acc: 0.8918 - val_loss: 0.0904 - val_acc: 0.9609\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.97240\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2291 - acc: 0.8932 - val_loss: 0.1347 - val_acc: 0.9287\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.97240\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2327 - acc: 0.8929 - val_loss: 0.1112 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.97240\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2263 - acc: 0.8958 - val_loss: 0.0873 - val_acc: 0.9612\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.97240\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2255 - acc: 0.8940 - val_loss: 0.1071 - val_acc: 0.9472\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.97240\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2225 - acc: 0.8983 - val_loss: 0.0821 - val_acc: 0.9654\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.97240\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2384 - acc: 0.8926 - val_loss: 0.0874 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.97240\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2209 - acc: 0.9002 - val_loss: 0.0954 - val_acc: 0.9623\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.97240\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2256 - acc: 0.8942 - val_loss: 0.1155 - val_acc: 0.9451\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.97240\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2243 - acc: 0.8959 - val_loss: 0.0857 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.97240\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2339 - acc: 0.8882 - val_loss: 0.1196 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.97240\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2167 - acc: 0.8988 - val_loss: 0.1098 - val_acc: 0.9430\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.97240\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2429 - acc: 0.8893 - val_loss: 0.1274 - val_acc: 0.9403\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.97240\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2467 - acc: 0.8939 - val_loss: 0.0954 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.97240\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2211 - acc: 0.8991 - val_loss: 0.1051 - val_acc: 0.9396\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.97240\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2251 - acc: 0.8940 - val_loss: 0.1149 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.97240\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2219 - acc: 0.8950 - val_loss: 0.1082 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.97240\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2174 - acc: 0.8988 - val_loss: 0.0726 - val_acc: 0.9727\n",
      "\n",
      "Epoch 00196: val_acc improved from 0.97240 to 0.97275, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/1/weights-improvement-196-0.9727.hdf5\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2190 - acc: 0.8974 - val_loss: 0.0861 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.97275\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2160 - acc: 0.9003 - val_loss: 0.0976 - val_acc: 0.9588\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.97275\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2257 - acc: 0.8954 - val_loss: 0.0978 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.97275\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2214 - acc: 0.8957 - val_loss: 0.0962 - val_acc: 0.9563\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.97275\n",
      "It has been  1:26:14.588643\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 26000)             0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 314)               8164314   \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 314)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 77)                24255     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 8)                 624       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 8,189,211\n",
      "Trainable params: 8,189,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 0.7523 - acc: 0.5847 - val_loss: 0.7089 - val_acc: 0.3036\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30363, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-001-0.3036.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.6818 - acc: 0.5745 - val_loss: 0.6688 - val_acc: 0.7788\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.30363 to 0.77883, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-002-0.7788.hdf5\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.6624 - acc: 0.6079 - val_loss: 0.6232 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77883\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6626 - acc: 0.5969 - val_loss: 0.6710 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77883\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.6451 - acc: 0.6140 - val_loss: 0.6562 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.77883 to 0.80643, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-005-0.8064.hdf5\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6482 - acc: 0.6186 - val_loss: 0.5846 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80643\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.6613 - acc: 0.6047 - val_loss: 0.6529 - val_acc: 0.8057\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80643\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.6439 - acc: 0.6258 - val_loss: 0.5942 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80643\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6448 - acc: 0.6355 - val_loss: 0.5883 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80643\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6458 - acc: 0.6387 - val_loss: 0.6036 - val_acc: 0.8173\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.80643 to 0.81726, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-010-0.8173.hdf5\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6335 - acc: 0.6430 - val_loss: 0.5858 - val_acc: 0.7306\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81726\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6182 - acc: 0.6504 - val_loss: 0.5950 - val_acc: 0.7163\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.81726\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6075 - acc: 0.6533 - val_loss: 0.5460 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.81726\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6103 - acc: 0.6668 - val_loss: 0.5979 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.81726\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6045 - acc: 0.6732 - val_loss: 0.5906 - val_acc: 0.7068\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.81726\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.6016 - acc: 0.6787 - val_loss: 0.6315 - val_acc: 0.7198\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.81726\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5771 - acc: 0.6737 - val_loss: 0.5541 - val_acc: 0.7110\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.81726\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5692 - acc: 0.6957 - val_loss: 0.5567 - val_acc: 0.7145\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.81726\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5612 - acc: 0.6979 - val_loss: 0.5552 - val_acc: 0.7369\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.81726\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5535 - acc: 0.7047 - val_loss: 0.5634 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.81726\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5486 - acc: 0.6888 - val_loss: 0.5388 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.81726\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5580 - acc: 0.6976 - val_loss: 0.5533 - val_acc: 0.7208\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.81726\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5645 - acc: 0.6748 - val_loss: 0.6268 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.81726 to 0.86408, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-023-0.8641.hdf5\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5473 - acc: 0.7079 - val_loss: 0.5482 - val_acc: 0.7226\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.86408\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5352 - acc: 0.7283 - val_loss: 0.4850 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.86408\n",
      "Epoch 26/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5317 - acc: 0.7404 - val_loss: 0.4864 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.86408\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5410 - acc: 0.7237 - val_loss: 0.5120 - val_acc: 0.7222\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.86408\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 27s 110ms/step - loss: 0.5306 - acc: 0.7317 - val_loss: 0.4532 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.86408\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5065 - acc: 0.7546 - val_loss: 0.4516 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.86408\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.5045 - acc: 0.7684 - val_loss: 0.4689 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.86408\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.5003 - acc: 0.7585 - val_loss: 0.4650 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.86408\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4962 - acc: 0.7700 - val_loss: 0.5032 - val_acc: 0.7271\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.86408\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4881 - acc: 0.7628 - val_loss: 0.4252 - val_acc: 0.7617\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.86408\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.4816 - acc: 0.7703 - val_loss: 0.4098 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.86408\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.4715 - acc: 0.7832 - val_loss: 0.4794 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.86408\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4751 - acc: 0.7827 - val_loss: 0.4444 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.86408\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4544 - acc: 0.7855 - val_loss: 0.3753 - val_acc: 0.8379\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.86408\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4478 - acc: 0.7970 - val_loss: 0.3244 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.86408\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4377 - acc: 0.8015 - val_loss: 0.3484 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.86408\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4318 - acc: 0.8071 - val_loss: 0.3116 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.86408\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 27s 110ms/step - loss: 0.4419 - acc: 0.8175 - val_loss: 0.3743 - val_acc: 0.7869\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.86408\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4257 - acc: 0.8143 - val_loss: 0.3207 - val_acc: 0.8047\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.86408\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.4255 - acc: 0.8205 - val_loss: 0.3067 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.86408\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4181 - acc: 0.8243 - val_loss: 0.3184 - val_acc: 0.7942\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.86408\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3977 - acc: 0.8265 - val_loss: 0.2737 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.86408\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3982 - acc: 0.8370 - val_loss: 0.3079 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86408\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4095 - acc: 0.8305 - val_loss: 0.2801 - val_acc: 0.8435\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86408\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.4078 - acc: 0.8381 - val_loss: 0.2734 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86408\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3975 - acc: 0.8381 - val_loss: 0.2790 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.86408\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3926 - acc: 0.8425 - val_loss: 0.2830 - val_acc: 0.8386\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.86408\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3811 - acc: 0.8466 - val_loss: 0.2528 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86408\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3943 - acc: 0.8491 - val_loss: 0.2395 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00052: val_acc improved from 0.86408 to 0.88085, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-052-0.8809.hdf5\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3625 - acc: 0.8582 - val_loss: 0.2415 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.88085\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3586 - acc: 0.8582 - val_loss: 0.2582 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.88085\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3635 - acc: 0.8558 - val_loss: 0.2172 - val_acc: 0.8784\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.88085\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3703 - acc: 0.8459 - val_loss: 0.2397 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.88085\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3565 - acc: 0.8594 - val_loss: 0.2399 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.88085\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 28s 110ms/step - loss: 0.3534 - acc: 0.8594 - val_loss: 0.2269 - val_acc: 0.8774\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.88085\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3491 - acc: 0.8614 - val_loss: 0.2141 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.88085\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 27s 109ms/step - loss: 0.3501 - acc: 0.8618 - val_loss: 0.2285 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.88085 to 0.89308, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-060-0.8931.hdf5\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3453 - acc: 0.8643 - val_loss: 0.2122 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.89308\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3430 - acc: 0.8603 - val_loss: 0.1892 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.89308 to 0.90077, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-062-0.9008.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3529 - acc: 0.8581 - val_loss: 0.1872 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.90077\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3286 - acc: 0.8709 - val_loss: 0.2067 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.90077\n",
      "Epoch 65/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3356 - acc: 0.8690 - val_loss: 0.2302 - val_acc: 0.8857\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.90077\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3387 - acc: 0.8675 - val_loss: 0.2732 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.90077\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3565 - acc: 0.8589 - val_loss: 0.1847 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.90077 to 0.91195, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-067-0.9119.hdf5\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3286 - acc: 0.8737 - val_loss: 0.2113 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.91195\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3141 - acc: 0.8791 - val_loss: 0.1734 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.91195\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3114 - acc: 0.8778 - val_loss: 0.1723 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00070: val_acc improved from 0.91195 to 0.91649, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-070-0.9165.hdf5\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3062 - acc: 0.8829 - val_loss: 0.1804 - val_acc: 0.9133\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.91649\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3143 - acc: 0.8775 - val_loss: 0.1807 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.91649\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3231 - acc: 0.8687 - val_loss: 0.2516 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.91649\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3293 - acc: 0.8695 - val_loss: 0.1867 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.91649\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3138 - acc: 0.8756 - val_loss: 0.2066 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.91649\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.3085 - acc: 0.8797 - val_loss: 0.1699 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.91649\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3050 - acc: 0.8825 - val_loss: 0.1936 - val_acc: 0.8980\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.91649\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3025 - acc: 0.8775 - val_loss: 0.1537 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.91649\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.2959 - acc: 0.8824 - val_loss: 0.1641 - val_acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00079: val_acc did not improve from 0.91649\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3067 - acc: 0.8808 - val_loss: 0.2214 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.91649\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2967 - acc: 0.8831 - val_loss: 0.1611 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00081: val_acc improved from 0.91649 to 0.91929, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-081-0.9193.hdf5\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3027 - acc: 0.8785 - val_loss: 0.1850 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.91929\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2950 - acc: 0.8777 - val_loss: 0.1758 - val_acc: 0.8924\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.91929\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2813 - acc: 0.8898 - val_loss: 0.1590 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.91929\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2873 - acc: 0.8857 - val_loss: 0.1706 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.91929\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3026 - acc: 0.8792 - val_loss: 0.1651 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.91929\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.2840 - acc: 0.8852 - val_loss: 0.1694 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.91929\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2746 - acc: 0.8887 - val_loss: 0.1419 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00088: val_acc improved from 0.91929 to 0.92208, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-088-0.9221.hdf5\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2778 - acc: 0.8886 - val_loss: 0.1605 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.92208\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2590 - acc: 0.8963 - val_loss: 0.1475 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.92208 to 0.92208, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-090-0.9221.hdf5\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.2800 - acc: 0.8904 - val_loss: 0.1801 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.92208\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.2847 - acc: 0.8889 - val_loss: 0.2287 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.92208\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3276 - acc: 0.8706 - val_loss: 0.1850 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.92208\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 27s 108ms/step - loss: 0.2701 - acc: 0.8934 - val_loss: 0.1566 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00094: val_acc improved from 0.92208 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-094-0.9235.hdf5\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2566 - acc: 0.9012 - val_loss: 0.1299 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00095: val_acc improved from 0.92348 to 0.93920, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-095-0.9392.hdf5\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2578 - acc: 0.9005 - val_loss: 0.1866 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.93920\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2861 - acc: 0.8872 - val_loss: 0.1599 - val_acc: 0.9126\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.93920\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2530 - acc: 0.8996 - val_loss: 0.1767 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.93920\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2877 - acc: 0.8804 - val_loss: 0.1451 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.93920\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2649 - acc: 0.8928 - val_loss: 0.1462 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.93920\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2641 - acc: 0.8990 - val_loss: 0.1617 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.93920\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2673 - acc: 0.8960 - val_loss: 0.1416 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.93920\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2457 - acc: 0.9039 - val_loss: 0.1629 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.93920\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2440 - acc: 0.9076 - val_loss: 0.1881 - val_acc: 0.8994\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.93920\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2535 - acc: 0.8968 - val_loss: 0.1519 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.93920\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2608 - acc: 0.8968 - val_loss: 0.1592 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.93920\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2594 - acc: 0.8934 - val_loss: 0.1327 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.93920\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2475 - acc: 0.9043 - val_loss: 0.1450 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.93920\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2535 - acc: 0.8938 - val_loss: 0.1554 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.93920\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2459 - acc: 0.8989 - val_loss: 0.1615 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.93920\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2517 - acc: 0.8994 - val_loss: 0.1545 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.93920\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2663 - acc: 0.8967 - val_loss: 0.1468 - val_acc: 0.9273\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.93920\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2669 - acc: 0.8922 - val_loss: 0.1322 - val_acc: 0.9336\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.93920\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2490 - acc: 0.8950 - val_loss: 0.2069 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.93920\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2562 - acc: 0.8957 - val_loss: 0.1205 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.93920\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2458 - acc: 0.9008 - val_loss: 0.1502 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.93920\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2564 - acc: 0.8943 - val_loss: 0.1671 - val_acc: 0.9088\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.93920\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2408 - acc: 0.9068 - val_loss: 0.1549 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.93920\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2603 - acc: 0.8943 - val_loss: 0.1550 - val_acc: 0.9060\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.93920\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2490 - acc: 0.9014 - val_loss: 0.1395 - val_acc: 0.9263\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.93920\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2510 - acc: 0.8938 - val_loss: 0.1623 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.93920\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2425 - acc: 0.9081 - val_loss: 0.1084 - val_acc: 0.9392\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.93920\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2327 - acc: 0.9066 - val_loss: 0.2062 - val_acc: 0.9008\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.93920\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2600 - acc: 0.8907 - val_loss: 0.1415 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.93920\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2435 - acc: 0.9028 - val_loss: 0.1492 - val_acc: 0.9277\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.93920\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2409 - acc: 0.9050 - val_loss: 0.1098 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00126: val_acc improved from 0.93920 to 0.95073, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-126-0.9507.hdf5\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 19s 78ms/step - loss: 0.2343 - acc: 0.9053 - val_loss: 0.1488 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.95073\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.2379 - acc: 0.9064 - val_loss: 0.1552 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.95073\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.2540 - acc: 0.8949 - val_loss: 0.1603 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.95073\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 21s 82ms/step - loss: 0.2415 - acc: 0.9026 - val_loss: 0.1407 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.95073\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 21s 84ms/step - loss: 0.2569 - acc: 0.8944 - val_loss: 0.1108 - val_acc: 0.9434\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.95073\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 22s 86ms/step - loss: 0.2328 - acc: 0.9067 - val_loss: 0.0933 - val_acc: 0.9504\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.95073\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.2471 - acc: 0.8993 - val_loss: 0.1602 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.95073\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 21s 86ms/step - loss: 0.2395 - acc: 0.8994 - val_loss: 0.1028 - val_acc: 0.9514\n",
      "\n",
      "Epoch 00134: val_acc improved from 0.95073 to 0.95143, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-134-0.9514.hdf5\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 0.2554 - acc: 0.8896 - val_loss: 0.1085 - val_acc: 0.9476\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.95143\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.2268 - acc: 0.9053 - val_loss: 0.1102 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.95143\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 0.2345 - acc: 0.9041 - val_loss: 0.0986 - val_acc: 0.9539\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.95143 to 0.95388, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-137-0.9539.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.2211 - acc: 0.9093 - val_loss: 0.1094 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00138: val_acc improved from 0.95388 to 0.95563, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-138-0.9556.hdf5\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2360 - acc: 0.9056 - val_loss: 0.1085 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00139: val_acc improved from 0.95563 to 0.95947, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-139-0.9595.hdf5\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2259 - acc: 0.9086 - val_loss: 0.1156 - val_acc: 0.9483\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.95947\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2298 - acc: 0.9070 - val_loss: 0.0815 - val_acc: 0.9731\n",
      "\n",
      "Epoch 00141: val_acc improved from 0.95947 to 0.97310, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-141-0.9731.hdf5\n",
      "Epoch 142/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2210 - acc: 0.9111 - val_loss: 0.1098 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.97310\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2436 - acc: 0.8966 - val_loss: 0.0906 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.97310\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2267 - acc: 0.9065 - val_loss: 0.1327 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.97310\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2297 - acc: 0.9054 - val_loss: 0.0931 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.97310\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2333 - acc: 0.9023 - val_loss: 0.1019 - val_acc: 0.9532\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.97310\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 18s 73ms/step - loss: 0.2269 - acc: 0.9094 - val_loss: 0.0856 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.97310\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2165 - acc: 0.9105 - val_loss: 0.1043 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.97310\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2244 - acc: 0.9073 - val_loss: 0.1527 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.97310\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2222 - acc: 0.9127 - val_loss: 0.0927 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.97310\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2278 - acc: 0.9095 - val_loss: 0.1741 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.97310\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2333 - acc: 0.9021 - val_loss: 0.0918 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.97310\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2217 - acc: 0.9096 - val_loss: 0.1064 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.97310\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2300 - acc: 0.9050 - val_loss: 0.0959 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.97310\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2148 - acc: 0.9115 - val_loss: 0.1084 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.97310\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2304 - acc: 0.9025 - val_loss: 0.0897 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.97310\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 18s 71ms/step - loss: 0.2299 - acc: 0.9089 - val_loss: 0.0975 - val_acc: 0.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00157: val_acc did not improve from 0.97310\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 18s 72ms/step - loss: 0.2331 - acc: 0.9056 - val_loss: 0.0781 - val_acc: 0.9776\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.97310 to 0.97764, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-158-0.9776.hdf5\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2135 - acc: 0.9133 - val_loss: 0.0706 - val_acc: 0.9811\n",
      "\n",
      "Epoch 00159: val_acc improved from 0.97764 to 0.98113, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-159-0.9811.hdf5\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2167 - acc: 0.9153 - val_loss: 0.1305 - val_acc: 0.9354\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.98113\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2122 - acc: 0.9153 - val_loss: 0.0788 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.98113\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2094 - acc: 0.9183 - val_loss: 0.0822 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.98113\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2071 - acc: 0.9186 - val_loss: 0.0780 - val_acc: 0.9780\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.98113\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2222 - acc: 0.9117 - val_loss: 0.0831 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.98113\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2069 - acc: 0.9186 - val_loss: 0.0908 - val_acc: 0.9658\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.98113\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2233 - acc: 0.9090 - val_loss: 0.0973 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.98113\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2265 - acc: 0.9070 - val_loss: 0.0736 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00167: val_acc improved from 0.98113 to 0.98637, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-167-0.9864.hdf5\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2080 - acc: 0.9170 - val_loss: 0.0731 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.98637\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2085 - acc: 0.9152 - val_loss: 0.0914 - val_acc: 0.9738\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.98637\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2275 - acc: 0.9039 - val_loss: 0.0867 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.98637\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2085 - acc: 0.9152 - val_loss: 0.0876 - val_acc: 0.9720\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.98637\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2067 - acc: 0.9162 - val_loss: 0.1130 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.98637\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2176 - acc: 0.9104 - val_loss: 0.0820 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.98637\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2021 - acc: 0.9190 - val_loss: 0.0760 - val_acc: 0.9734\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.98637\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2121 - acc: 0.9144 - val_loss: 0.0810 - val_acc: 0.9724\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.98637\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2157 - acc: 0.9146 - val_loss: 0.0562 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00176: val_acc improved from 0.98637 to 0.98847, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-176-0.9885.hdf5\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 17s 70ms/step - loss: 0.2073 - acc: 0.9168 - val_loss: 0.0808 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.98847\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2246 - acc: 0.9077 - val_loss: 0.0717 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00178: val_acc did not improve from 0.98847\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2049 - acc: 0.9176 - val_loss: 0.0886 - val_acc: 0.9637\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.98847\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2063 - acc: 0.9187 - val_loss: 0.0882 - val_acc: 0.9581\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.98847\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2081 - acc: 0.9157 - val_loss: 0.0772 - val_acc: 0.9783\n",
      "\n",
      "Epoch 00181: val_acc did not improve from 0.98847\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1977 - acc: 0.9223 - val_loss: 0.0721 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.98847\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2213 - acc: 0.9070 - val_loss: 0.0705 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.98847\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2044 - acc: 0.9175 - val_loss: 0.0767 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.98847\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1962 - acc: 0.9203 - val_loss: 0.0635 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00185: val_acc did not improve from 0.98847\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1888 - acc: 0.9261 - val_loss: 0.0620 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.98847\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2044 - acc: 0.9183 - val_loss: 0.0739 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.98847\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2199 - acc: 0.9090 - val_loss: 0.0758 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.98847\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2004 - acc: 0.9167 - val_loss: 0.0804 - val_acc: 0.9713\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.98847\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2240 - acc: 0.9088 - val_loss: 0.0844 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00190: val_acc did not improve from 0.98847\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2052 - acc: 0.9139 - val_loss: 0.0617 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.98847\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2145 - acc: 0.9139 - val_loss: 0.0652 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.98847\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 17s 70ms/step - loss: 0.1946 - acc: 0.9224 - val_loss: 0.0583 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.98847\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1946 - acc: 0.9239 - val_loss: 0.0495 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00194: val_acc improved from 0.98847 to 0.99266, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/2/weights-improvement-194-0.9927.hdf5\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2071 - acc: 0.9143 - val_loss: 0.0602 - val_acc: 0.9839\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.99266\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.2020 - acc: 0.9198 - val_loss: 0.0560 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.99266\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1997 - acc: 0.9197 - val_loss: 0.0829 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.99266\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1925 - acc: 0.9242 - val_loss: 0.0656 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00198: val_acc did not improve from 0.99266\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1878 - acc: 0.9252 - val_loss: 0.0531 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.99266\n",
      "Epoch 200/200\n",
      "251/251 [==============================] - 18s 70ms/step - loss: 0.1949 - acc: 0.9239 - val_loss: 0.0596 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00200: val_acc did not improve from 0.99266\n",
      "It has been  1:17:49.078613\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 1000, 26)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 26000)             0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 314)               8164314   \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 314)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 77)                24255     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 8)                 624       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 8,189,211\n",
      "Trainable params: 8,189,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.7469 - acc: 0.5877 - val_loss: 0.7134 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.30398, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-001-0.3040.hdf5\n",
      "Epoch 2/200\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 0.6904 - acc: 0.5709 - val_loss: 0.7215 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.30398\n",
      "Epoch 3/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.6916 - acc: 0.5691 - val_loss: 0.6976 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.30398\n",
      "Epoch 4/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6807 - acc: 0.6062 - val_loss: 0.7121 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.30398\n",
      "Epoch 5/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.6703 - acc: 0.6038 - val_loss: 0.6479 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.30398 to 0.77254, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-005-0.7725.hdf5\n",
      "Epoch 6/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6632 - acc: 0.6184 - val_loss: 0.7198 - val_acc: 0.3026\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77254\n",
      "Epoch 7/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6713 - acc: 0.5846 - val_loss: 0.7119 - val_acc: 0.3040\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77254\n",
      "Epoch 8/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.6601 - acc: 0.6176 - val_loss: 0.6118 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.77254 to 0.80643, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-008-0.8064.hdf5\n",
      "Epoch 9/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6581 - acc: 0.6243 - val_loss: 0.5418 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.80643 to 0.81202, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-009-0.8120.hdf5\n",
      "Epoch 10/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6427 - acc: 0.6387 - val_loss: 0.6903 - val_acc: 0.4322\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81202\n",
      "Epoch 11/200\n",
      "251/251 [==============================] - 24s 98ms/step - loss: 0.6429 - acc: 0.6538 - val_loss: 0.5336 - val_acc: 0.8103\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.81202\n",
      "Epoch 12/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.6258 - acc: 0.6635 - val_loss: 0.5525 - val_acc: 0.8340\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.81202 to 0.83403, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-012-0.8340.hdf5\n",
      "Epoch 13/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.6182 - acc: 0.6744 - val_loss: 0.6565 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.83403\n",
      "Epoch 14/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.6234 - acc: 0.6495 - val_loss: 0.6341 - val_acc: 0.8061\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.83403\n",
      "Epoch 15/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.6042 - acc: 0.6868 - val_loss: 0.5670 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.83403 to 0.83927, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-015-0.8393.hdf5\n",
      "Epoch 16/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5994 - acc: 0.6844 - val_loss: 0.6425 - val_acc: 0.8452\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.83927 to 0.84521, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-016-0.8452.hdf5\n",
      "Epoch 17/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5891 - acc: 0.6868 - val_loss: 0.6276 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84521\n",
      "Epoch 18/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.5776 - acc: 0.6996 - val_loss: 0.6162 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.84521\n",
      "Epoch 19/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.5655 - acc: 0.7122 - val_loss: 0.5890 - val_acc: 0.7774\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.84521\n",
      "Epoch 20/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.5632 - acc: 0.7113 - val_loss: 0.6386 - val_acc: 0.7362\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84521\n",
      "Epoch 21/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5618 - acc: 0.7310 - val_loss: 0.5990 - val_acc: 0.7827\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84521\n",
      "Epoch 22/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.5466 - acc: 0.7371 - val_loss: 0.5767 - val_acc: 0.7683\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.84521\n",
      "Epoch 23/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5352 - acc: 0.7430 - val_loss: 0.6061 - val_acc: 0.7862\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.84521\n",
      "Epoch 24/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5262 - acc: 0.7478 - val_loss: 0.5656 - val_acc: 0.7757\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.84521\n",
      "Epoch 25/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5069 - acc: 0.7573 - val_loss: 0.5134 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.84521 to 0.85115, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-025-0.8512.hdf5\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 24s 96ms/step - loss: 0.5118 - acc: 0.7413 - val_loss: 0.5186 - val_acc: 0.7907\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.85115\n",
      "Epoch 27/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.4923 - acc: 0.7564 - val_loss: 0.5209 - val_acc: 0.8033\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.85115\n",
      "Epoch 28/200\n",
      "251/251 [==============================] - 24s 98ms/step - loss: 0.4897 - acc: 0.7779 - val_loss: 0.5162 - val_acc: 0.7631\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.85115\n",
      "Epoch 29/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.4939 - acc: 0.7475 - val_loss: 0.4728 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.85115\n",
      "Epoch 30/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.5021 - acc: 0.7528 - val_loss: 0.4966 - val_acc: 0.7732\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.85115\n",
      "Epoch 31/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.4958 - acc: 0.7556 - val_loss: 0.4855 - val_acc: 0.7666\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.85115\n",
      "Epoch 32/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.4737 - acc: 0.7702 - val_loss: 0.4963 - val_acc: 0.7813\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.85115\n",
      "Epoch 33/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.4658 - acc: 0.7848 - val_loss: 0.4648 - val_acc: 0.8050\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.85115\n",
      "Epoch 34/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.4553 - acc: 0.8064 - val_loss: 0.4093 - val_acc: 0.8117\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.85115\n",
      "Epoch 35/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.4512 - acc: 0.8250 - val_loss: 0.4227 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.85115\n",
      "Epoch 36/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.4485 - acc: 0.8178 - val_loss: 0.4220 - val_acc: 0.8194\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.85115\n",
      "Epoch 37/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.4395 - acc: 0.8173 - val_loss: 0.4141 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.85115\n",
      "Epoch 38/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.4340 - acc: 0.8234 - val_loss: 0.3717 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.85115 to 0.85115, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-038-0.8512.hdf5\n",
      "Epoch 39/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4366 - acc: 0.8147 - val_loss: 0.3882 - val_acc: 0.8382\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.85115\n",
      "Epoch 40/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4281 - acc: 0.8206 - val_loss: 0.4130 - val_acc: 0.8337\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.85115\n",
      "Epoch 41/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4184 - acc: 0.8367 - val_loss: 0.3374 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.85115\n",
      "Epoch 42/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4385 - acc: 0.8086 - val_loss: 0.3480 - val_acc: 0.8267\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.85115\n",
      "Epoch 43/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4231 - acc: 0.8170 - val_loss: 0.3042 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.85115 to 0.86688, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-043-0.8669.hdf5\n",
      "Epoch 44/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.3930 - acc: 0.8335 - val_loss: 0.2832 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.86688\n",
      "Epoch 45/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.4014 - acc: 0.8264 - val_loss: 0.2563 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.86688 to 0.86932, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-045-0.8693.hdf5\n",
      "Epoch 46/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3929 - acc: 0.8261 - val_loss: 0.2544 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86932\n",
      "Epoch 47/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3898 - acc: 0.8206 - val_loss: 0.2290 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.86932 to 0.88435, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-047-0.8843.hdf5\n",
      "Epoch 48/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3813 - acc: 0.8277 - val_loss: 0.2451 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.88435\n",
      "Epoch 49/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3846 - acc: 0.8202 - val_loss: 0.2372 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.88435\n",
      "Epoch 50/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3603 - acc: 0.8415 - val_loss: 0.2177 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.88435\n",
      "Epoch 51/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.3579 - acc: 0.8417 - val_loss: 0.2248 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.88435\n",
      "Epoch 52/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3724 - acc: 0.8316 - val_loss: 0.2147 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.88435\n",
      "Epoch 53/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.3632 - acc: 0.8338 - val_loss: 0.2202 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.88435\n",
      "Epoch 54/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3715 - acc: 0.8253 - val_loss: 0.2921 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.88435\n",
      "Epoch 55/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3789 - acc: 0.8182 - val_loss: 0.2158 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.88435\n",
      "Epoch 56/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.3648 - acc: 0.8305 - val_loss: 0.2052 - val_acc: 0.8826\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.88435\n",
      "Epoch 57/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.3689 - acc: 0.8271 - val_loss: 0.2278 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.88435\n",
      "Epoch 58/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.3662 - acc: 0.8310 - val_loss: 0.2204 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.88435\n",
      "Epoch 59/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.3636 - acc: 0.8299 - val_loss: 0.2390 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.88435\n",
      "Epoch 60/200\n",
      "251/251 [==============================] - 20s 81ms/step - loss: 0.3465 - acc: 0.8422 - val_loss: 0.2150 - val_acc: 0.8711\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.88435\n",
      "Epoch 61/200\n",
      "251/251 [==============================] - 22s 87ms/step - loss: 0.3642 - acc: 0.8248 - val_loss: 0.1997 - val_acc: 0.8854\n",
      "\n",
      "Epoch 00061: val_acc improved from 0.88435 to 0.88539, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-061-0.8854.hdf5\n",
      "Epoch 62/200\n",
      "251/251 [==============================] - 21s 84ms/step - loss: 0.3539 - acc: 0.8327 - val_loss: 0.1880 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00062: val_acc improved from 0.88539 to 0.89902, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-062-0.8990.hdf5\n",
      "Epoch 63/200\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 0.3457 - acc: 0.8427 - val_loss: 0.2006 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.89902\n",
      "Epoch 64/200\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.3390 - acc: 0.8475 - val_loss: 0.1920 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.89902\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 22s 88ms/step - loss: 0.3465 - acc: 0.8368 - val_loss: 0.1953 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.89902\n",
      "Epoch 66/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3574 - acc: 0.8381 - val_loss: 0.1840 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.89902\n",
      "Epoch 67/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3498 - acc: 0.8468 - val_loss: 0.2085 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.89902\n",
      "Epoch 68/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3396 - acc: 0.8517 - val_loss: 0.1845 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.89902\n",
      "Epoch 69/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3254 - acc: 0.8529 - val_loss: 0.2043 - val_acc: 0.8823\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.89902\n",
      "Epoch 70/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3607 - acc: 0.8215 - val_loss: 0.1556 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.89902\n",
      "Epoch 71/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.3655 - acc: 0.8310 - val_loss: 0.1945 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.89902\n",
      "Epoch 72/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.3443 - acc: 0.8473 - val_loss: 0.3546 - val_acc: 0.8868\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.89902\n",
      "Epoch 73/200\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 0.3612 - acc: 0.8380 - val_loss: 0.1878 - val_acc: 0.8927\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.89902\n",
      "Epoch 74/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.3444 - acc: 0.8507 - val_loss: 0.2040 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.89902\n",
      "Epoch 75/200\n",
      "251/251 [==============================] - 23s 90ms/step - loss: 0.3345 - acc: 0.8523 - val_loss: 0.2024 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00075: val_acc improved from 0.89902 to 0.90287, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-075-0.9029.hdf5\n",
      "Epoch 76/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.3468 - acc: 0.8355 - val_loss: 0.1626 - val_acc: 0.8959\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.90287\n",
      "Epoch 77/200\n",
      "251/251 [==============================] - 23s 91ms/step - loss: 0.3264 - acc: 0.8503 - val_loss: 0.1664 - val_acc: 0.8973\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.90287\n",
      "Epoch 78/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.3408 - acc: 0.8387 - val_loss: 0.1644 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.90287\n",
      "Epoch 79/200\n",
      "251/251 [==============================] - 23s 93ms/step - loss: 0.3271 - acc: 0.8529 - val_loss: 0.1670 - val_acc: 0.8899\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.90287\n",
      "Epoch 80/200\n",
      "251/251 [==============================] - 24s 94ms/step - loss: 0.3356 - acc: 0.8378 - val_loss: 0.1581 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.90287\n",
      "Epoch 81/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3259 - acc: 0.8440 - val_loss: 0.1553 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.90287\n",
      "Epoch 82/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3354 - acc: 0.8462 - val_loss: 0.1630 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00082: val_acc improved from 0.90287 to 0.90531, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-082-0.9053.hdf5\n",
      "Epoch 83/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.3289 - acc: 0.8514 - val_loss: 0.1559 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.90531\n",
      "Epoch 84/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.3264 - acc: 0.8552 - val_loss: 0.1316 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00084: val_acc improved from 0.90531 to 0.91020, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-084-0.9102.hdf5\n",
      "Epoch 85/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3217 - acc: 0.8524 - val_loss: 0.1572 - val_acc: 0.9001\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.91020\n",
      "Epoch 86/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3179 - acc: 0.8576 - val_loss: 0.1651 - val_acc: 0.9057\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.91020\n",
      "Epoch 87/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3291 - acc: 0.8407 - val_loss: 0.1492 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.91020\n",
      "Epoch 88/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.3159 - acc: 0.8538 - val_loss: 0.1508 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.91020\n",
      "Epoch 89/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.3152 - acc: 0.8596 - val_loss: 0.1537 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.91020\n",
      "Epoch 90/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3085 - acc: 0.8605 - val_loss: 0.1429 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.91020\n",
      "Epoch 91/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.3139 - acc: 0.8562 - val_loss: 0.1403 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.91020\n",
      "Epoch 92/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.3096 - acc: 0.8532 - val_loss: 0.1629 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.91020\n",
      "Epoch 93/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3188 - acc: 0.8454 - val_loss: 0.1370 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.91020 to 0.91230, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-093-0.9123.hdf5\n",
      "Epoch 94/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3192 - acc: 0.8443 - val_loss: 0.1295 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.91230\n",
      "Epoch 95/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3201 - acc: 0.8496 - val_loss: 0.1384 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.91230\n",
      "Epoch 96/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.3202 - acc: 0.8447 - val_loss: 0.1192 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.91230\n",
      "Epoch 97/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.3108 - acc: 0.8578 - val_loss: 0.1349 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.91230\n",
      "Epoch 98/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.3013 - acc: 0.8596 - val_loss: 0.1324 - val_acc: 0.9099\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.91230\n",
      "Epoch 99/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.2907 - acc: 0.8704 - val_loss: 0.1488 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.91230\n",
      "Epoch 100/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.3261 - acc: 0.8620 - val_loss: 0.1416 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.91230\n",
      "Epoch 101/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3084 - acc: 0.8631 - val_loss: 0.1381 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.91230\n",
      "Epoch 102/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3145 - acc: 0.8605 - val_loss: 0.1881 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.91230\n",
      "Epoch 103/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3078 - acc: 0.8644 - val_loss: 0.1792 - val_acc: 0.9067\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.91230\n",
      "Epoch 104/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3299 - acc: 0.8400 - val_loss: 0.1321 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.91230\n",
      "Epoch 105/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3123 - acc: 0.8566 - val_loss: 0.1417 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00105: val_acc improved from 0.91230 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-105-0.9151.hdf5\n",
      "Epoch 106/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3039 - acc: 0.8609 - val_loss: 0.1385 - val_acc: 0.9078\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.91509\n",
      "Epoch 107/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3009 - acc: 0.8623 - val_loss: 0.1320 - val_acc: 0.9113\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.91509\n",
      "Epoch 108/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3069 - acc: 0.8621 - val_loss: 0.1300 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.91509\n",
      "Epoch 109/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2971 - acc: 0.8692 - val_loss: 0.1370 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.91509\n",
      "Epoch 110/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3166 - acc: 0.8625 - val_loss: 0.2160 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.91509\n",
      "Epoch 111/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3145 - acc: 0.8502 - val_loss: 0.1292 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.91509\n",
      "Epoch 112/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3042 - acc: 0.8593 - val_loss: 0.1342 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.91509\n",
      "Epoch 113/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3125 - acc: 0.8519 - val_loss: 0.1362 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00113: val_acc improved from 0.91509 to 0.91509, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-113-0.9151.hdf5\n",
      "Epoch 114/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2953 - acc: 0.8671 - val_loss: 0.2201 - val_acc: 0.9106\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.91509\n",
      "Epoch 115/200\n",
      "251/251 [==============================] - 27s 107ms/step - loss: 0.3014 - acc: 0.8726 - val_loss: 0.1406 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.91509\n",
      "Epoch 116/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3039 - acc: 0.8620 - val_loss: 0.1270 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00116: val_acc improved from 0.91509 to 0.91544, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-116-0.9154.hdf5\n",
      "Epoch 117/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2937 - acc: 0.8605 - val_loss: 0.1239 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.91544\n",
      "Epoch 118/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.3108 - acc: 0.8537 - val_loss: 0.1249 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.91544\n",
      "Epoch 119/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3017 - acc: 0.8571 - val_loss: 0.1296 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.91544\n",
      "Epoch 120/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2884 - acc: 0.8692 - val_loss: 0.1237 - val_acc: 0.9140\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.91544\n",
      "Epoch 121/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2947 - acc: 0.8631 - val_loss: 0.1304 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.91544\n",
      "Epoch 122/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2860 - acc: 0.8716 - val_loss: 0.1264 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.91544\n",
      "Epoch 123/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2876 - acc: 0.8641 - val_loss: 0.1201 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00123: val_acc improved from 0.91544 to 0.91544, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-123-0.9154.hdf5\n",
      "Epoch 124/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2973 - acc: 0.8632 - val_loss: 0.1165 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00124: val_acc improved from 0.91544 to 0.91684, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-124-0.9168.hdf5\n",
      "Epoch 125/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2919 - acc: 0.8640 - val_loss: 0.1380 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.91684\n",
      "Epoch 126/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2899 - acc: 0.8631 - val_loss: 0.1242 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.91684\n",
      "Epoch 127/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2908 - acc: 0.8609 - val_loss: 0.1201 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.91684\n",
      "Epoch 128/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2840 - acc: 0.8739 - val_loss: 0.1232 - val_acc: 0.9151\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.91684\n",
      "Epoch 129/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2824 - acc: 0.8717 - val_loss: 0.1250 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00129: val_acc improved from 0.91684 to 0.91719, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-129-0.9172.hdf5\n",
      "Epoch 130/200\n",
      "251/251 [==============================] - 25s 100ms/step - loss: 0.2920 - acc: 0.8707 - val_loss: 0.1238 - val_acc: 0.9147\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.91719\n",
      "Epoch 131/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.3014 - acc: 0.8569 - val_loss: 0.1206 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.91719\n",
      "Epoch 132/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2927 - acc: 0.8611 - val_loss: 0.1261 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.91719\n",
      "Epoch 133/200\n",
      "251/251 [==============================] - 25s 102ms/step - loss: 0.2845 - acc: 0.8750 - val_loss: 0.1242 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.91719\n",
      "Epoch 134/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2863 - acc: 0.8686 - val_loss: 0.1332 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.91719\n",
      "Epoch 135/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.2945 - acc: 0.8548 - val_loss: 0.1133 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.91719\n",
      "Epoch 136/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.2878 - acc: 0.8603 - val_loss: 0.1341 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00136: val_acc improved from 0.91719 to 0.91754, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-136-0.9175.hdf5\n",
      "Epoch 137/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.2805 - acc: 0.8664 - val_loss: 0.1144 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00137: val_acc improved from 0.91754 to 0.91824, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-137-0.9182.hdf5\n",
      "Epoch 138/200\n",
      "251/251 [==============================] - 26s 102ms/step - loss: 0.2783 - acc: 0.8780 - val_loss: 0.1247 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.91824\n",
      "Epoch 139/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.2842 - acc: 0.8755 - val_loss: 0.1190 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.91824\n",
      "Epoch 140/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.2780 - acc: 0.8755 - val_loss: 0.1183 - val_acc: 0.9154\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.91824\n",
      "Epoch 141/200\n",
      "251/251 [==============================] - 26s 103ms/step - loss: 0.2778 - acc: 0.8810 - val_loss: 0.1417 - val_acc: 0.9168\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.91824\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2709 - acc: 0.8823 - val_loss: 0.1212 - val_acc: 0.9158\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.91824\n",
      "Epoch 143/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2806 - acc: 0.8766 - val_loss: 0.1151 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.91824\n",
      "Epoch 144/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2837 - acc: 0.8676 - val_loss: 0.1352 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00144: val_acc improved from 0.91824 to 0.91859, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-144-0.9186.hdf5\n",
      "Epoch 145/200\n",
      "251/251 [==============================] - 26s 104ms/step - loss: 0.2898 - acc: 0.8612 - val_loss: 0.1101 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.91859\n",
      "Epoch 146/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2772 - acc: 0.8680 - val_loss: 0.1146 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00146: val_acc improved from 0.91859 to 0.91859, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-146-0.9186.hdf5\n",
      "Epoch 147/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2866 - acc: 0.8715 - val_loss: 0.1162 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00147: val_acc improved from 0.91859 to 0.91999, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-147-0.9200.hdf5\n",
      "Epoch 148/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2890 - acc: 0.8685 - val_loss: 0.1197 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.91999\n",
      "Epoch 149/200\n",
      "251/251 [==============================] - 26s 105ms/step - loss: 0.2899 - acc: 0.8580 - val_loss: 0.1487 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.91999\n",
      "Epoch 150/200\n",
      "251/251 [==============================] - 26s 106ms/step - loss: 0.2802 - acc: 0.8660 - val_loss: 0.1072 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.91999\n",
      "Epoch 151/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2775 - acc: 0.8678 - val_loss: 0.1205 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00151: val_acc did not improve from 0.91999\n",
      "Epoch 152/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.3051 - acc: 0.8749 - val_loss: 0.1059 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00152: val_acc did not improve from 0.91999\n",
      "Epoch 153/200\n",
      "251/251 [==============================] - 27s 106ms/step - loss: 0.2695 - acc: 0.8787 - val_loss: 0.1164 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00153: val_acc did not improve from 0.91999\n",
      "Epoch 154/200\n",
      "251/251 [==============================] - 21s 85ms/step - loss: 0.2830 - acc: 0.8752 - val_loss: 0.1252 - val_acc: 0.9109\n",
      "\n",
      "Epoch 00154: val_acc did not improve from 0.91999\n",
      "Epoch 155/200\n",
      "251/251 [==============================] - 20s 78ms/step - loss: 0.2731 - acc: 0.8715 - val_loss: 0.1277 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00155: val_acc did not improve from 0.91999\n",
      "Epoch 156/200\n",
      "251/251 [==============================] - 20s 79ms/step - loss: 0.2689 - acc: 0.8810 - val_loss: 0.1180 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00156: val_acc did not improve from 0.91999\n",
      "Epoch 157/200\n",
      "251/251 [==============================] - 20s 80ms/step - loss: 0.2721 - acc: 0.8865 - val_loss: 0.1138 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00157: val_acc did not improve from 0.91999\n",
      "Epoch 158/200\n",
      "251/251 [==============================] - 21s 83ms/step - loss: 0.3034 - acc: 0.8671 - val_loss: 0.1108 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00158: val_acc improved from 0.91999 to 0.92138, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-158-0.9214.hdf5\n",
      "Epoch 159/200\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.2743 - acc: 0.8744 - val_loss: 0.1086 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00159: val_acc did not improve from 0.92138\n",
      "Epoch 160/200\n",
      "251/251 [==============================] - 22s 88ms/step - loss: 0.2674 - acc: 0.8769 - val_loss: 0.1123 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00160: val_acc did not improve from 0.92138\n",
      "Epoch 161/200\n",
      "251/251 [==============================] - 23s 92ms/step - loss: 0.2724 - acc: 0.8734 - val_loss: 0.1275 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00161: val_acc did not improve from 0.92138\n",
      "Epoch 162/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2742 - acc: 0.8762 - val_loss: 0.1340 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00162: val_acc did not improve from 0.92138\n",
      "Epoch 163/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2799 - acc: 0.8764 - val_loss: 0.1227 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00163: val_acc did not improve from 0.92138\n",
      "Epoch 164/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2779 - acc: 0.8656 - val_loss: 0.1134 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00164: val_acc did not improve from 0.92138\n",
      "Epoch 165/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2779 - acc: 0.8754 - val_loss: 0.2091 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00165: val_acc did not improve from 0.92138\n",
      "Epoch 166/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2879 - acc: 0.8764 - val_loss: 0.1176 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00166: val_acc did not improve from 0.92138\n",
      "Epoch 167/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2718 - acc: 0.8732 - val_loss: 0.1144 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00167: val_acc did not improve from 0.92138\n",
      "Epoch 168/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2731 - acc: 0.8707 - val_loss: 0.1085 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00168: val_acc did not improve from 0.92138\n",
      "Epoch 169/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2700 - acc: 0.8726 - val_loss: 0.1386 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00169: val_acc did not improve from 0.92138\n",
      "Epoch 170/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2801 - acc: 0.8659 - val_loss: 0.1041 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00170: val_acc did not improve from 0.92138\n",
      "Epoch 171/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2851 - acc: 0.8623 - val_loss: 0.1433 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00171: val_acc did not improve from 0.92138\n",
      "Epoch 172/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.2791 - acc: 0.8687 - val_loss: 0.1081 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00172: val_acc did not improve from 0.92138\n",
      "Epoch 173/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2650 - acc: 0.8758 - val_loss: 0.1141 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00173: val_acc did not improve from 0.92138\n",
      "Epoch 174/200\n",
      "251/251 [==============================] - 24s 95ms/step - loss: 0.2708 - acc: 0.8718 - val_loss: 0.1512 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00174: val_acc did not improve from 0.92138\n",
      "Epoch 175/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2696 - acc: 0.8722 - val_loss: 0.1106 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00175: val_acc did not improve from 0.92138\n",
      "Epoch 176/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2676 - acc: 0.8749 - val_loss: 0.1490 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00176: val_acc did not improve from 0.92138\n",
      "Epoch 177/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2692 - acc: 0.8722 - val_loss: 0.1121 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00177: val_acc did not improve from 0.92138\n",
      "Epoch 178/200\n",
      "251/251 [==============================] - 24s 96ms/step - loss: 0.2663 - acc: 0.8735 - val_loss: 0.1186 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00178: val_acc improved from 0.92138 to 0.92138, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-178-0.9214.hdf5\n",
      "Epoch 179/200\n",
      "251/251 [==============================] - 24s 97ms/step - loss: 0.2709 - acc: 0.8758 - val_loss: 0.1209 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00179: val_acc did not improve from 0.92138\n",
      "Epoch 180/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2663 - acc: 0.8757 - val_loss: 0.1086 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00180: val_acc did not improve from 0.92138\n",
      "Epoch 181/200\n",
      "251/251 [==============================] - 24s 98ms/step - loss: 0.2607 - acc: 0.8774 - val_loss: 0.1025 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00181: val_acc improved from 0.92138 to 0.92208, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-181-0.9221.hdf5\n",
      "Epoch 182/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2821 - acc: 0.8717 - val_loss: 0.1101 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00182: val_acc did not improve from 0.92208\n",
      "Epoch 183/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2706 - acc: 0.8741 - val_loss: 0.1116 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00183: val_acc did not improve from 0.92208\n",
      "Epoch 184/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2685 - acc: 0.8810 - val_loss: 0.1511 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00184: val_acc did not improve from 0.92208\n",
      "Epoch 185/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2665 - acc: 0.8856 - val_loss: 0.1208 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00185: val_acc improved from 0.92208 to 0.92208, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-185-0.9221.hdf5\n",
      "Epoch 186/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2679 - acc: 0.8761 - val_loss: 0.1097 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00186: val_acc did not improve from 0.92208\n",
      "Epoch 187/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2749 - acc: 0.8701 - val_loss: 0.1213 - val_acc: 0.9200\n",
      "\n",
      "Epoch 00187: val_acc did not improve from 0.92208\n",
      "Epoch 188/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2657 - acc: 0.8732 - val_loss: 0.1106 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00188: val_acc did not improve from 0.92208\n",
      "Epoch 189/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2657 - acc: 0.8732 - val_loss: 0.1095 - val_acc: 0.9210\n",
      "\n",
      "Epoch 00189: val_acc did not improve from 0.92208\n",
      "Epoch 190/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2627 - acc: 0.8726 - val_loss: 0.0991 - val_acc: 0.9235\n",
      "\n",
      "Epoch 00190: val_acc improved from 0.92208 to 0.92348, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-190-0.9235.hdf5\n",
      "Epoch 191/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2578 - acc: 0.8770 - val_loss: 0.1058 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00191: val_acc did not improve from 0.92348\n",
      "Epoch 192/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2625 - acc: 0.8729 - val_loss: 0.1060 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00192: val_acc did not improve from 0.92348\n",
      "Epoch 193/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2624 - acc: 0.8758 - val_loss: 0.1249 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00193: val_acc did not improve from 0.92348\n",
      "Epoch 194/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2622 - acc: 0.8722 - val_loss: 0.1064 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00194: val_acc did not improve from 0.92348\n",
      "Epoch 195/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2730 - acc: 0.8652 - val_loss: 0.1292 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00195: val_acc did not improve from 0.92348\n",
      "Epoch 196/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2614 - acc: 0.8809 - val_loss: 0.1215 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00196: val_acc did not improve from 0.92348\n",
      "Epoch 197/200\n",
      "251/251 [==============================] - 25s 99ms/step - loss: 0.2595 - acc: 0.8774 - val_loss: 0.1367 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00197: val_acc did not improve from 0.92348\n",
      "Epoch 198/200\n",
      "251/251 [==============================] - 25s 98ms/step - loss: 0.2771 - acc: 0.8790 - val_loss: 0.1084 - val_acc: 0.9238\n",
      "\n",
      "Epoch 00198: val_acc improved from 0.92348 to 0.92383, saving model to /home/angela/padding_EBI/data/checkpoint/EC_number/archaea/3denses/bio_neurons/task1/pre_padding/3/weights-improvement-198-0.9238.hdf5\n",
      "Epoch 199/200\n",
      "251/251 [==============================] - 25s 101ms/step - loss: 0.2520 - acc: 0.8835 - val_loss: 0.1080 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00199: val_acc did not improve from 0.92383\n",
      "Epoch 200/200\n",
      "  3/251 [..............................] - ETA: 24s - loss: 0.2135 - acc: 0.9074"
     ]
    }
   ],
   "source": [
    "task = \"task1/\"\n",
    "for model_type in list_paddings:\n",
    "    generators = generators_dict[model_type]\n",
    "    for idx,i in enumerate(generators):\n",
    "        if model_type == \"aug_padding\":\n",
    "            i_train, i_val, i_test = k_aug_indices[idx]\n",
    "        else:\n",
    "            i_train, i_val, i_test = splitting_sets[idx]\n",
    "        len_train, len_val, len_test = len(i_train), len(i_val), len(i_test)\n",
    "        train_generator, val_generator = i\n",
    "        folder_cp = ''.join(string for string in [folder, task, model_type, '/', str(idx)]) \n",
    "        #print(folder_cp)\n",
    "        if not os.path.exists(os.path.join(absPath, 'data/checkpoint/', folder_cp)):\n",
    "            os.makedirs(''.join(string for string in [absPath, 'data/checkpoint/', folder_cp]))\n",
    "\n",
    "        callbacks_list = calling_callbacks(folder_cp, folder, model_type, None, None, None, \n",
    "                                   None, False, False, False, False)\n",
    "        folder_task1 =  ''.join(string for string in [folder, task])\n",
    "        model = building_2dense_model_task2(max_lenn, dict_size, n_neur, n_class, drop_per, drop_hid, 'softmax', folder)\n",
    "        #writing log file \n",
    "        log_file = ''.join(string for string in [absPath, 'data/checkpoint/', folder, task, 'log_file.txt' ]) \n",
    "        f = open(log_file, 'a+')\n",
    "        print('Model type: %s \\n' % model_type, file=f)\n",
    "        print('Fold: %i \\n' % idx, file=f)\n",
    " \n",
    "        start = time.time()\n",
    "        formatted_time = datetime.datetime.now()\n",
    "        print('Starting time: %s \\n' % formatted_time, file=f)\n",
    "        history = model.fit_generator(generator=train_generator, \n",
    "                              validation_data=val_generator,\n",
    "                             steps_per_epoch= int(len_train/batch_size),\n",
    "                              validation_steps=int(len_val/batch_size),\n",
    "                             epochs=epochss,\n",
    "                             callbacks=callbacks_list,\n",
    "                             verbose=1)\n",
    "        end = time.time()\n",
    "        formatted_endtime = datetime.datetime.now()\n",
    "        print('Finishing time: %s \\n' % formatted_endtime, file=f)\n",
    "        count_time(start, end, folder, model_type)\n",
    "        saving_results(history, model_type, folder, idx, True)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generators[1][0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
