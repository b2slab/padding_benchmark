{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import choice\n",
    "from string import ascii_lowercase\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM, Bidirectional, Input, concatenate, Reshape, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.backend.tensorflow_backend import set_session \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "#root\n",
    "absPath = '/home/angela/padding_uniprot/'\n",
    "sys.path.insert(0, absPath)\n",
    "\n",
    "from src.Target import Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "tf.set_random_seed(22)\n",
    "config = tf.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of amino acids\n",
    "list_aas = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', \n",
    "            'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "#length of sequences\n",
    "m = 500\n",
    "#sample size (number of sequences)\n",
    "n=20000\n",
    "#creating random sequences\n",
    "rdm_seqs = []\n",
    "for i in range(n):\n",
    "    rdm_seqs.append(\"\".join(choice(list_aas) for j in range(m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20000 sequences\n",
      "Example of first sequence:  LFFPPVOYMUUXDTCQQMAVCXIKTLSWISPWGGKLEWMOQLBZEWSKKAWHLEHHUVIPXZCIZXFHDIPIGWQLIWWCHAZTLRNTLFEIVOIDPARYHIHSATBXZRUEEKTETXAOKNCETBMTGNUSEMQTKRMIPGAKKEIUXAEWSLOPIEMPNCWVNQHUSYVNEXANBDILFHWYCNSSYXKKHGFYAPBFTZZIFUOSDUBTBOYBHATQXRSNMIQXBBIHFDYHLBHAOWHDFUXBWNZTCHQYBXTTLDTEWTSVFLXEYBZGOVAXIFMLBCXXGUPQRNUCDEZBIBEZVMTITILDSWAGCODSLYIKXCMZHCGEDKSHXAIQOVSOWQYWLEYCARZXUFWENVTWZLKEVPIBOBUZOQWXWBHUZBTNFRXVTLPBFZYVIKVSPWCKOTZGDRWPPUYFQXQVPHATTYAEXFISFMKYBNNGNPWBEVHIYECAQFYZRMIDMSXXQXFAASETIQRWDEOCAELXNWTODNKCELLO\n",
      "Example of second sequence:  QUFEGRNGMDARHHBGPMSIQNYFXQAZXBLMSFBPKSUTPUPCNSWNTLDVUPGWYCOLPHNNBIFAWLMARNHVDPRFZPUDMAHHUGAOOXWIOQBTWXXZPQBNZZUBSVWZXHOKTUYSUIGBQOHGWCFYOBQCDBXWYVIMTERBWBEETMMMMDTKKXAEHMRHVQEWXNGCDIVCBDHMGNZIXHKSMLQBZQLMWGTDQBUNHMISYKELWBKOZCXLSFNQTECHNXXCLTGPYFAMMPVYERMQRMIQTMGWPAZNNTICUOXPGSBDGFVTRTFPMXVKQWXWPTGCANVMWHRGVTCUNNGCNOICYOHDTXBWQQMERZQYQVVIZHOZMFQIZIHDKWMCOGCSAILETVQMYNOZXPPOGFXYVOZCKXAMQEDCFIAUSGCQITMHZBETYQLTKRPMRCRCHRYVTPXGDIFTPFKYHARAAPYUTKHTWNBXQPGQHHWNYWFEMONFFZPGLSLDMMCSIKSPHNCIDHBGNUSAMPIE\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(rdm_seqs), \"sequences\")\n",
    "print(\"Example of first sequence: \", rdm_seqs[0])\n",
    "print(\"Example of second sequence: \", rdm_seqs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In half of them we will introduce a very obvious motif\n",
    "syn_motif = 'A'*50\n",
    "#we take the first half of the sequences...\n",
    "seqs2motif = rdm_seqs[:int(n/2)]\n",
    "#...and we add the motif in a random position\n",
    "motif_seqs = []\n",
    "for i in seqs2motif:\n",
    "    pos = random.randint(0, m-len(syn_motif)-1)\n",
    "    motif_seqs.append(i[:pos-1] +syn_motif + i[pos+(len(syn_motif)-1):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe for data\n",
    "df_seqs = pd.DataFrame(columns=['sequence', 'label'])\n",
    "df_seqs2 = pd.DataFrame(columns=['sequence', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding sequences with motifs and labelling them as \"2.0\" (for BigDL)\n",
    "df_seqs['sequence'] = motif_seqs\n",
    "df_seqs['label'] = '2.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding sequences with no motifs and labelling them as \"1.0\" (for BigDL)\n",
    "df_seqs2['sequence'] = rdm_seqs[int(n/2):]\n",
    "df_seqs2['label'] = '1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining both dataframes\n",
    "df_seqs = pd.concat([df_seqs, df_seqs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 9999\n",
      "Data columns (total 2 columns):\n",
      "sequence    20000 non-null object\n",
      "label       20000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 468.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_seqs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling rows\n",
    "df_seqs = df_seqs.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGDCODAOLRPUZXSWDPRGVXAYTQFWBWATUTCOGSRNZGOMAZ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MMNYHQWANCSPAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LERVLFPPWCYCWBCLALBHVFNDKKUOCLOREGOZNFZQRYTGFV...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUILREERQPZVDNNUCKOLKTIYZAYYBUXCMAXLLEAFVUHDDP...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EFPKKDZBAPINAQIYFISIULXLWHARFGCIARSUYECLHKFYVB...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence label\n",
       "0  CGDCODAOLRPUZXSWDPRGVXAYTQFWBWATUTCOGSRNZGOMAZ...   1.0\n",
       "1  MMNYHQWANCSPAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA...   2.0\n",
       "2  LERVLFPPWCYCWBCLALBHVFNDKKUOCLOREGOZNFZQRYTGFV...   1.0\n",
       "3  MUILREERQPZVDNNUCKOLKTIYZAYYBUXCMAXLLEAFVUHDDP...   1.0\n",
       "4  EFPKKDZBAPINAQIYFISIULXLWHARFGCIARSUYECLHKFYVB...   1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_seqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs['label'] = df_seqs['label'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      "sequence    20000 non-null object\n",
      "label       20000 non-null float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_seqs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs.to_csv('/home/angela/padding_uniprot/data/syn_sequences.csv', \n",
    "              header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Adam optimizer\n",
    "epochss = 100\n",
    "#learning_rate = 5e-6\n",
    "#learning_rate = 0.01\n",
    "#decay_rate = learning_rate/epochss\n",
    "#adamm = Adam(lr=learning_rate, beta_1=0.1, beta_2=0.001, epsilon=1e-08, decay=decay_rate)\n",
    "adamm = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "n_hid = 256 #number of hidden neurons\n",
    "n_class = 2 #number of classes to output\n",
    "drop_per = 0.2 #Input dropout \n",
    "drop_hid = 0.5 #hidden neurons dropout\n",
    "n_filt = 10 # number of filter in the first convolutional layer\n",
    "n_filt2 = 64\n",
    "lng_inp = m #length of the input, which is the max length of targets\n",
    "dict_size = len(list_aas)\n",
    "\n",
    "#### CNN  filters ####\n",
    "f_size_a = 1\n",
    "f_size_b = 3\n",
    "f_size_c = 5\n",
    "f_size_d = 9\n",
    "f_size_e = 15\n",
    "f_size_f = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = Input(shape=(lng_inp, dict_size), dtype='float32')\n",
    "dropout_seq = Dropout(drop_per)(input_seq)\n",
    "\n",
    "#Second convolutional layer\n",
    "conv_seq = Conv1D(filters=n_filt2, padding='same', strides=1, kernel_size=f_size_b, activation='relu')(dropout_seq)\n",
    "\n",
    "#Another dropout\n",
    "dropout_seq2 = Dropout(drop_hid)(conv_seq)\n",
    "\n",
    "#Bidirectional LSTM\n",
    "#bilstm_seq = Bidirectional(LSTM(n_hid, dropout=drop_hid, recurrent_dropout=drop_hid, activation='tanh'), merge_mode='concat')(dropout_seq2)\n",
    "reshape_seq = Flatten()(dropout_seq2)\n",
    "\n",
    "#Dense\n",
    "dense_seq1 = Dense(n_hid*2, activation='relu', input_dim=n_hid)(reshape_seq)\n",
    "dropout_seq3 = Dropout(drop_hid)(dense_seq1)\n",
    "\n",
    "main_dense = Dense(n_class, activation='softmax')(dropout_seq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and compile model\n",
    "model = Model(inputs=[input_seq], outputs=[main_dense])\n",
    "model.compile(loss='categorical_crossentropy', optimizer = adamm, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 500, 25)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500, 25)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 500, 64)           4864      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 16,390,402\n",
      "Trainable params: 16,390,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking data from dataframe\n",
    "seqs = df_seqs['sequence'].values\n",
    "labels = df_seqs['label'].values\n",
    "\n",
    "labels_replaced = [0.0 if i == 1.0 else 1.0 for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  1.  1.  1.  2.  1.  1.  2.  1.]\n",
      "[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[:10])\n",
    "print(labels_replaced[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting amino acids dictionary\n",
    "nums = list(range(0, len(list_aas)))\n",
    "aa_to_int = dict(zip(list_aas, nums))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 500, 25)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Processing data\n",
    "def target_to_int(seq, dictionary):\n",
    "    \"\"\"Translate a sequence of amino acids to a list of integers, given a dictionary\"\"\"\n",
    "    target_int = []\n",
    "    aminoacids = list(seq)\n",
    "    for i in aminoacids:\n",
    "        target_int.append(dictionary[i])\n",
    "    return target_int\n",
    "    \n",
    "def int_to_onehot(x_int, num_classes):\n",
    "    \"\"\"Translate a list of integers to one hot encoding\"\"\"\n",
    "    onehot = np_utils.to_categorical(x_int, num_classes=num_classes)\n",
    "    return onehot\n",
    "\n",
    "# 2nd: we convert amino acid sequences to integer sequences\n",
    "seqs_int = [target_to_int(x, aa_to_int) for x in seqs]\n",
    "seqs_int_array = sequence.pad_sequences(sequences=seqs_int, maxlen=m)\n",
    "\n",
    "# 3rd: we convert integer sequences to one hot\n",
    "seqs_onehot = int_to_onehot(list(seqs_int_array), len(aa_to_int))\n",
    "seqs_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode labels\n",
    "\n",
    "labels_onehot = [np_utils.to_categorical(x, num_classes=2) for x in labels_replaced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_split = 0.8\n",
    "val_split = 0.5\n",
    "indices = list(np.arange(len(seqs_onehot)))\n",
    "\n",
    "x_train, x_valtest, y_train, y_valtest, idx_train, idx_valtest = train_test_split(\n",
    "    seqs_onehot, labels_onehot, indices, test_size=(1-training_split))\n",
    "\n",
    "x_val, x_test, y_val, y_test, idx_val, idx_test = train_test_split(\n",
    "    x_valtest, y_valtest, idx_valtest, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "16000/16000 [==============================] - 26s 2ms/step - loss: 0.0867 - acc: 0.9762 - val_loss: 1.0573e-04 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 4.8661e-04 - acc: 1.0000 - val_loss: 2.6441e-05 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.7698e-04 - acc: 1.0000 - val_loss: 5.5479e-06 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 8.0733e-04 - acc: 0.9999 - val_loss: 1.2762e-05 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "16000/16000 [==============================] - 14s 891us/step - loss: 1.0714e-04 - acc: 1.0000 - val_loss: 1.3915e-06 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 4.3468e-05 - acc: 1.0000 - val_loss: 4.4990e-07 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 0.0016 - acc: 0.9994 - val_loss: 3.8901e-06 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.2607e-05 - acc: 1.0000 - val_loss: 3.3865e-07 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2517e-05 - acc: 1.0000 - val_loss: 2.5192e-07 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1406e-05 - acc: 1.0000 - val_loss: 1.9512e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.9992e-05 - acc: 1.0000 - val_loss: 1.6794e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 6.5342e-06 - acc: 1.0000 - val_loss: 1.5199e-07 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 5.8089e-06 - acc: 1.0000 - val_loss: 1.2219e-07 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 6.4113e-04 - acc: 0.9998 - val_loss: 1.2222e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 3.5505e-05 - acc: 1.0000 - val_loss: 1.2171e-07 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 3.1647e-06 - acc: 1.0000 - val_loss: 1.1927e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.0429e-06 - acc: 1.0000 - val_loss: 1.1936e-07 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 3.8531e-06 - acc: 1.0000 - val_loss: 1.1933e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 8.6614e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.6005e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.0866e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 9.5739e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 4.7925e-07 - acc: 1.0000 - val_loss: 1.1948e-07 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 6.8532e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 4.1267e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 7.2227e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 3.2033e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.0279e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 1.6817e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "16000/16000 [==============================] - 14s 887us/step - loss: 1.8195e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "16000/16000 [==============================] - 24s 1ms/step - loss: 6.6205e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.9025e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 3.2179e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.0740e-04 - acc: 0.9999 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 4.6819e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "16000/16000 [==============================] - 24s 1ms/step - loss: 1.1959e-05 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 2.8976e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.4937e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.6275e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.3264e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "16000/16000 [==============================] - 24s 1ms/step - loss: 1.3699e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.5730e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.3688e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 4.5881e-04 - acc: 0.9999 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 3.1450e-05 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.4223e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2991e-06 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2817e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2288e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.9247e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.5045e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2552e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2359e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "16000/16000 [==============================] - 21s 1ms/step - loss: 1.3059e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "16000/16000 [==============================] - 11s 706us/step - loss: 1.3838e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2471e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 2.1526e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.4723e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2190e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2371e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.5332e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2676e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1982e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2171e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.5719e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "16000/16000 [==============================] - 24s 1ms/step - loss: 1.5356e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.1986e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2185e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1944e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2152e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1980e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2088e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1923e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2111e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2719e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.1938e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 9.7695e-05 - acc: 0.9999 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.3212e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "16000/16000 [==============================] - 22s 1ms/step - loss: 1.2551e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "16000/16000 [==============================] - 11s 704us/step - loss: 9.3429e-04 - acc: 0.9997 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "16000/16000 [==============================] - 23s 1ms/step - loss: 4.1801e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.6334e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2629e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.3598e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.3646e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.3266e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2741e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 6.0297e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 2.9341e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.3483e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2071e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 8.0773e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2134e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.5403e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2171e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "16000/16000 [==============================] - 24s 2ms/step - loss: 1.2507e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2034e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2252e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 1.2146e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "16000/16000 [==============================] - 25s 2ms/step - loss: 2.4059e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=x_train, y=np.asarray(y_train), \n",
    "                    validation_data=(x_val, np.asarray(y_val)), \n",
    "                    epochs=epochss, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50b1af4550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f50b1aa77b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = history.history\n",
    "\n",
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predprob = model.predict(x_test)\n",
    "y_pred = y_predprob.argmax(axis=-1)\n",
    "y_test_scalar = np.asarray(y_test).argmax(axis=-1)\n",
    "y_prob = y_predprob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1012, 1: 988})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.05198597e-12],\n",
       "       [  1.36373876e-38,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   1.11907738e-12],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   5.32107670e-13],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00],\n",
       "       [  1.00000000e+00,   7.30977887e-13],\n",
       "       [  0.00000000e+00,   1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predprob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy (test set): 1\n",
      "Confusion matrix:\n",
      "[[1012    0]\n",
      " [   0  988]]\n",
      "Detailed classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1012\n",
      "          1       1.00      1.00      1.00       988\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model report\n",
    "print (\"\\nModel Report\")\n",
    "print (\"Accuracy (test set): %.4g\" % metrics.accuracy_score(y_test_scalar, y_pred))\n",
    "print(\"Confusion matrix:\")\n",
    "print (metrics.confusion_matrix(y_test_scalar, y_pred))\n",
    "print(\"Detailed classification report:\")\n",
    "print (metrics.classification_report(y_test_scalar, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
